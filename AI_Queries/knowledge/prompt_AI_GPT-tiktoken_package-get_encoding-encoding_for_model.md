# üìå **Gu√≠a Completa del Paquete `tiktoken`**  

`tiktoken` es una biblioteca de OpenAI dise√±ada para la **tokenizaci√≥n eficiente** de texto, utilizada en modelos como **GPT-3.5** y **GPT-4**. Su principal ventaja es que es mucho m√°s r√°pida que m√©todos tradicionales como `GPT-2 BPE`.

---

## üîπ **1. Instalaci√≥n**
Si a√∫n no tienes instalado `tiktoken`, puedes hacerlo con:
```bash
pip install tiktoken
```

---

## üîπ **2. Principales Funciones y M√©todos**
A continuaci√≥n, se detallan las funciones m√°s importantes de `tiktoken`:

| **Funci√≥n** | **Descripci√≥n** |
|------------|---------------|
| `tiktoken.get_encoding(encoding_name)` | Obtiene un esquema de codificaci√≥n espec√≠fico. |
| `tiktoken.encoding_for_model(model_name)` | Obtiene la codificaci√≥n recomendada para un modelo de OpenAI. |
| `encoding.encode(texto, allowed_special=set())` | Convierte un texto en una lista de tokens. |
| `encoding.decode(lista_tokens)` | Convierte una lista de tokens en texto. |
| `encoding.encode_ordinary(texto)` | Similar a `encode()`, pero ignora tokens especiales. |
| `encoding.encode_with_special_tokens(texto)` | Tokeniza el texto incluyendo tokens especiales. |
| `encoding.n_vocab` | Obtiene el n√∫mero total de tokens en el vocabulario de la codificaci√≥n. |
| `encoding.special_tokens_set` | Devuelve un conjunto con los tokens especiales definidos en la codificaci√≥n. |

---

## üîπ **3. Explicaci√≥n con Ejemplos**
### üè∑ **(1) Obtener una codificaci√≥n espec√≠fica**
Si ya conoces el nombre de la codificaci√≥n, puedes usar:
```python
import tiktoken

encoding = tiktoken.get_encoding("cl100k_base")  # Codificaci√≥n usada en GPT-4 y GPT-3.5-turbo
print(encoding.n_vocab)  # N√∫mero total de tokens en el vocabulario
```
---

### üè∑ **(2) Obtener la codificaci√≥n adecuada para un modelo**
Si no conoces la codificaci√≥n, pero s√≠ el modelo de OpenAI:
```python
encoding = tiktoken.encoding_for_model("gpt-4")
print(encoding.n_vocab)  # N√∫mero de tokens en el vocabulario
```
---

### üè∑ **(3) Tokenizar texto**
```python
text = "Hola, ¬øc√≥mo est√°s?"
tokens = encoding.encode(text)
print(tokens)  # [9906, 11, 64, 1050, 239, 34]
```
---

### üè∑ **(4) Convertir tokens en texto**
```python
decoded_text = encoding.decode(tokens)
print(decoded_text)  # "Hola, ¬øc√≥mo est√°s?"
```
---

### üè∑ **(5) Ignorar tokens especiales**
Si quieres ignorar tokens especiales durante la tokenizaci√≥n:
```python
tokens = encoding.encode_ordinary("¬°Hola! <|endoftext|>")
print(tokens)  # No incluir√° <|endoftext|> como token
```
---

### üè∑ **(6) Incluir tokens especiales**
Si necesitas incluir tokens especiales en la tokenizaci√≥n:
```python
tokens = encoding.encode_with_special_tokens("¬°Hola! <|endoftext|>")
print(tokens)  # Incluir√° <|endoftext|> como token especial
```
---

## üîπ **4. Codificaciones Disponibles**
Algunos esquemas de codificaci√≥n en `tiktoken` son:

| **Codificaci√≥n** | **Modelos que la usan** |
|-----------------|-------------------------|
| `cl100k_base` | GPT-4, GPT-3.5-turbo |
| `p50k_base` | Codificaci√≥n similar a GPT-3 |
| `r50k_base` | Usada en GPT-3 antiguo |

Si tienes dudas sobre qu√© codificaci√≥n usar, **siempre usa `encoding_for_model()`**.

---

## ‚úÖ **Conclusi√≥n**
`tiktoken` es una herramienta fundamental para trabajar con modelos de OpenAI, optimizando la tokenizaci√≥n de texto. Sus dos funciones m√°s importantes son:
1. `get_encoding()`: Para obtener una codificaci√≥n espec√≠fica.
2. `encoding_for_model()`: Para obtener la codificaci√≥n adecuada para un modelo.

Si necesitas manipular tokens, decodificar texto o trabajar con vocabularios, `tiktoken` te ofrece una API r√°pida y eficiente. üöÄ


[How to count tokens with Tiktoken](https://cookbook.openai.com/examples/how_to_count_tokens_with_tiktoken)