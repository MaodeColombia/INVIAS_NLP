{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X11QtSmiMV9e"
   },
   "source": [
    "# LangChain para INVIAS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "drFyYyIWMavB"
   },
   "source": [
    "## üîí 1. Instalaci√≥n de librer√≠as"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîì  Solo ejecutar este script si no se han instalado los paquetes para desarrollar el c√≥digo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5901,
     "status": "ok",
     "timestamp": 1688165628049,
     "user": {
      "displayName": "Omar Espejel",
      "userId": "05134704829153205181"
     },
     "user_tz": 360
    },
    "id": "LofnVb23dSxe"
   },
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Lista de los paquetes a instalar:\n",
    "\n",
    "    upgrade:\n",
    "        pip\n",
    "        setuptools\n",
    "        wheel\n",
    "    Packages:\n",
    "        langchain \n",
    "        pypdf \n",
    "        openai \n",
    "        chromadb \n",
    "        tiktoken\n",
    "        langchain-community\n",
    "\"\"\"\n",
    "import subprocess\n",
    "\n",
    "comandos = [\n",
    "    [\"pip\", \"install\", \"--upgrade\", \"pip\", \"setuptools\", \"wheel\"],\n",
    "    [\"pip\", \"install\", \"langchain\", \"pypdf\", \"openai\", \"chromadb\", \"tiktoken\"],\n",
    "    [\"pip\", \"install\", \"-U\", \"langchain-community\"],\n",
    "    [\"python\", \"-m\", \"pip\", \"install\", \"--upgrade\", \"pip\"]\n",
    "]\n",
    "\n",
    "log_path = \"instalacion_log.txt\"\n",
    "\n",
    "with open(log_path, \"w\", encoding=\"utf-8\") as log_file:\n",
    "    for i, cmd in enumerate(comandos, start=1):\n",
    "        log_file.write(f\"\\nüîß Ejecutando comando {i}: {' '.join(cmd)}\\n\")\n",
    "        result = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "        \n",
    "        log_file.write(\"‚úÖ STDOUT:\\n\")\n",
    "        log_file.write(result.stdout + \"\\n\")\n",
    "        \n",
    "        if result.stderr:\n",
    "            log_file.write(\"‚ö†Ô∏è STDERR:\\n\")\n",
    "            log_file.write(result.stderr + \"\\n\")\n",
    "\n",
    "print(f\"‚úÖ Resultado guardado en {log_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üü¢ 2. Configuraci√≥n de API Key de OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8057,
     "status": "ok",
     "timestamp": 1688165818015,
     "user": {
      "displayName": "Omar Espejel",
      "userId": "05134704829153205181"
     },
     "user_tz": 360
    },
    "id": "dHG9AVJkh3Dz",
    "outputId": "616af93a-257b-4cba-81d9-2d2797414792"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¬°Cliente de OpenAI inicializado correctamente!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "# Recuperar la clave API de la variable de entorno\n",
    "api_key_environ = os.environ.get(\"OPENAI_API_KEY\")\n",
    " \n",
    "# Verificar que la clave API est√© disponible\n",
    "if not api_key_environ:\n",
    "    raise ValueError(\"La variable de entorno OPENAI_API_KEY no est√° configurada o est√° vac√≠a.\")\n",
    " \n",
    "# Inicializar el cliente de OpenAI con la clave API\n",
    "client = OpenAI(api_key=api_key_environ)\n",
    " \n",
    "# Usar el cliente para tus tareas\n",
    "print(\"¬°Cliente de OpenAI inicializado correctamente!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Z_Xi-GvMf8E"
   },
   "source": [
    "## üîí 3. Carga de documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîì  Solo ejecutar este script si no se ha hecho el proceso de embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 57463,
     "status": "ok",
     "timestamp": 1688165880499,
     "user": {
      "displayName": "Omar Espejel",
      "userId": "05134704829153205181"
     },
     "user_tz": 360
    },
    "id": "W_6B2k3Vcfxt",
    "outputId": "862c3d28-9656-41cc-ecde-31daec5f7a6e"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "import os\n",
    "\n",
    "relative_pdf_path = \"../../../assets/DG_docs/PDFs_test/\"\n",
    "\n",
    "ml_papers = []\n",
    "\n",
    "for i, file_name in enumerate(os.listdir(relative_pdf_path)):\n",
    "    if file_name.lower().endswith(\".pdf\"):\n",
    "        full_pdf_path = os.path.join(relative_pdf_path,file_name)\n",
    "        print(f\"üìÑ Cargando {file_name}\")\n",
    "\n",
    "        loader = PyPDFLoader(full_pdf_path)\n",
    "        data = loader.load() # AI_Queries\\code_explanation\\ai_query-langc_v01-PyPDFLoader(filename).loader.load()_usage.md\n",
    "        ml_papers.extend(data) # AI_Queries\\code_explanation\\ai_query-langc_v01-.extend_usage.md\n",
    "        # print (ml_papers) # AI_Queries/code_explanation/ai_query-langc_v01-list_start_end_usage.md\n",
    "# Utiliza la lista ml_papers para acceder a los elementos de todos los documentos descargados\n",
    "print('Esto es todo el contenido de `ml_papers:`')\n",
    "print(f\"\"\"\n",
    "üÜó Todos los documentos estan cargados en ml_papers.\n",
    "‚ûñ Total de fragmentos: {len(ml_papers)}\n",
    "‚ûñ Los fragmentos son cada una de las hojas de cada uno de los {len(os.listdir(relative_pdf_path))} archivos en la carpeta {relative_pdf_path}\n",
    "‚ûñ Este script se ejecuta desde {os.getcwd()}\n",
    "‚ûñ Este es el contenido de la √∫ltima hoja cargada {ml_papers[-1]}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WJYjDA_GMi0Z"
   },
   "source": [
    "## üîí 4. Split de documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîì Solo ejecutar este script para desarrollar el proceso de embedding; este script depende del script anterior "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1688165880500,
     "user": {
      "displayName": "Omar Espejel",
      "userId": "05134704829153205181"
     },
     "user_tz": 360
    },
    "id": "4caTdNe-hk7w"
   },
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1500, \n",
    "    # AI_Queries\\code_explanation\\ai_query-langc_v01-chunk_usage.md \n",
    "    # AI_Queries\\code_explanation\\ai_query-langc_v01-max_tokens_Chatgptmodels.md \n",
    "    # AI_Queries\\code_explanation\\ai_query-langc_v01-meaning_inputpromptandanswer.md \n",
    "    # AI_Queries\\code_explanation\\ai_query-langc_v01-retrieval_meaning.md\n",
    "    \n",
    "    chunk_overlap=200,\n",
    "    length_function=len\n",
    "    )\n",
    "\n",
    "documents = text_splitter.split_documents(ml_papers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1688165880500,
     "user": {
      "displayName": "Omar Espejel",
      "userId": "05134704829153205181"
     },
     "user_tz": 360
    },
    "id": "koi4gwzthsGh",
    "outputId": "6ed35c64-9026-4222-b86a-379809bfb6dc"
   },
   "outputs": [],
   "source": [
    "len(documents), documents[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîí 5. Embeddings e ingesta a base de datos vectorial \n",
    "\n",
    "‚ö†Ô∏è advertencia de uso de esta secci√≥n ‚ö†Ô∏è"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîì 5.1. Solo ejecutar este script para desarrolla el proceso de embedding; este script depende del script anterior\n",
    "\n",
    "**Aqu√≠ se consume recurso de la API de OpenAI**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6756,
     "status": "ok",
     "timestamp": 1688165966034,
     "user": {
      "displayName": "Omar Espejel",
      "userId": "05134704829153205181"
     },
     "user_tz": 360
    },
    "id": "iZ-ZFWgRh9aV"
   },
   "outputs": [],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "# AI_Queries\\code_explanation\\ai_query-langc_v01-Embeddings_and_Vector_Store_Ingestion.md\n",
    "\n",
    "# 1. Crear embeddings con el modelo oficial de OpenAI\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\") # ‚ö†Ô∏è cambiar a \"text-embedding-3-small\"\n",
    "\n",
    "# 2. Definir carpeta para almacenar la base de datos vectorial\n",
    "persist_directory = \"chroma_db\" #\n",
    "\n",
    "# 3. Crear la base desde documentos y embeddings\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=documents,\n",
    "    embedding=embeddings,\n",
    "    persist_directory=persist_directory\n",
    ")\n",
    "\n",
    "# 4. Guardar la base en disco\n",
    "vectorstore.persist()\n",
    "print(\"‚úÖ Base de datos Chroma guardada en:\", persist_directory)\n",
    "\n",
    "\n",
    "# 5. Cargar la base vectorial guardada en disco\n",
    "vectorstore = Chroma(\n",
    "    embedding_function=embeddings,\n",
    "    persist_directory=\"chroma_db\"\n",
    ")\n",
    "\n",
    "# 6. Usar como retriever\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_kwargs={\"k\": 3}\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2. üü¢\n",
    "\n",
    "Fue necesario crear copia de las lineas \"*# 1. Crear embeddings con el modelo oficial de OpenAI*\", \"*# 5. Cargar la base vectorial guardada en disco*\" y \"*# 6. Usar como retriever*\" para **solamente hacer uso de la Based de Datos de embeddings `chroma_db` ya creada y evitar recalcularla**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mmartinezo\\AppData\\Local\\Temp\\ipykernel_19756\\1269346108.py:5: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
      "  embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")  # ‚ö†Ô∏è cambiar a \"text-embedding-3-small\"\n",
      "C:\\Users\\mmartinezo\\AppData\\Local\\Temp\\ipykernel_19756\\1269346108.py:8: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  vectorstore = Chroma(\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "# 1. Modelo de embeddings (debe ser el mismo usado al crear la base)\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")  # ‚ö†Ô∏è cambiar a \"text-embedding-3-small\"\n",
    "\n",
    "# 5. Cargar la base vectorial guardada en disco\n",
    "vectorstore = Chroma(\n",
    "    embedding_function=embeddings,\n",
    "    persist_directory=\"chroma_db\"\n",
    ")\n",
    "\n",
    "# 6. Usar como retriever\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_kwargs={\"k\": 5}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sBbAhkFKMrDC"
   },
   "source": [
    "## 6. Modelos de chat y cadenas para consulta de informaci√≥n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üö© 6.1. Recuperaci√≥n sin trazabilidad ‚Äì Primer acercamiento con LangChain; ~~No cita las fuentes de donde extrae la informaci√≥n~~."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AI_Queries/code_explanation/ai_query-langc_v01-Chat_Models_and_Retrieval_Chains_for_Information_Querying.md\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    openai_api_key=api_key_environ,\n",
    "    model_name='gpt-3.5-turbo',\n",
    "    temperature=0.0\n",
    ")\n",
    "\n",
    "# AI_Queries/code_explanation/ai_query-langc_v01-RetrievalQA.from_chain_type_usage.md\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=chat,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AI_Queries/code_explanation/ai_query-langc_v01-qa_chain.run()_usage.md\n",
    "\n",
    "query = \"qu√© es CCPT?\"\n",
    "qa_chain.run(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üß† Comparaci√≥n entre Script 1 y Script 2\n",
    "\n",
    "| Aspecto                           | **Script anterior**                                 | **Script siguiente**                                                       |\n",
    "| --------------------------------- | --------------------------------------------------- | -------------------------------------------------------------------------- |\n",
    "| **Importaci√≥n del modelo**        | `from langchain.chat_models` (obsoleto)             | `from langchain_openai` (recomendado)                                      |\n",
    "| **Versi√≥n del API**               | Antiguo LangChain monol√≠tico                        | Nuevo ecosistema modular `langchain-openai`                                |\n",
    "| **M√©todo de ejecuci√≥n**           | `qa_chain.run(query)` (‚ö†Ô∏è obsoleto)                 | `qa_chain.invoke({\"query\": query})` (‚úÖ recomendado)                        |\n",
    "| **Fuentes del resultado**         | ‚ùå No devuelve los documentos fuente                 | ‚úÖ Incluye los documentos fuente con `return_source_documents=True`         |\n",
    "| **Retorno estructurado**          | S√≥lo devuelve texto plano                           | Devuelve un diccionario con respuesta y `source_documents`                 |\n",
    "| **Transparencia institucional**   | Baja (no se puede verificar origen de la respuesta) | Alta (permite validar en qu√© parte de los documentos se basa la respuesta) |\n",
    "| **Uso pedag√≥gico recomendado**    | Para introducir conceptos b√°sicos de `RetrievalQA`  | Para ense√±ar buenas pr√°cticas actuales en trazabilidad y uso del LLM       |\n",
    "| **Estabilidad futura del c√≥digo** | Baja (usa m√≥dulos y m√©todos deprecados)             | Alta (adaptado a la versi√≥n estable y mantenida de LangChain)              |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (üö©Revisar por qu√© no est√° gerendo resultadosüö©) 6.2. Con recuperaci√≥n b√°sica ‚Äì El sistema responde y cita fuentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1688165966035,
     "user": {
      "displayName": "Omar Espejel",
      "userId": "05134704829153205181"
     },
     "user_tz": 360
    },
    "id": "fxjg2e6RiTqO"
   },
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "# Inicializa el modelo de lenguaje\n",
    "chat = ChatOpenAI(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    temperature=0.0,\n",
    "    openai_api_key=api_key_environ\n",
    ")\n",
    "\n",
    "# Crear la cadena de preguntas y respuestas con fuentes\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=chat,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True  # ‚úÖ Para obtener las fuentes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "executionInfo": {
     "elapsed": 6199,
     "status": "ok",
     "timestamp": 1688165977030,
     "user": {
      "displayName": "Omar Espejel",
      "userId": "05134704829153205181"
     },
     "user_tz": 360
    },
    "id": "qgDyf-lOimCT",
    "outputId": "18f9ce42-2c78-4540-e6d3-ec5f01223cbb"
   },
   "outputs": [],
   "source": [
    "query = \" que pasa en Oca√±a?\"\n",
    "result = qa_chain.invoke({\"query\": query})\n",
    "\n",
    "# Imprimir respuesta\n",
    "print(\"üß† Respuesta:\")\n",
    "print(result['result'])\n",
    "\n",
    "# Imprimir fuentes\n",
    "print(\"\\nüìö Fuentes:\")\n",
    "for i, doc in enumerate(result['source_documents']):\n",
    "    print(f\"\\nFuente {i+1}:\")\n",
    "    print(\"Archivo:\", doc.metadata.get(\"source\", \"desconocido\"))\n",
    "    print(\"Contenido:\", doc.page_content[:400])  # Muestra primeros 400 caracteres\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üß† Comparaci√≥n entre Script 1 y Script 2\n",
    "\n",
    "| Aspecto                           | **Script anterior**                                 | **Script actual**                                                       |\n",
    "| --------------------------------- | --------------------------------------------------- | -------------------------------------------------------------------------- |\n",
    "| **Importaci√≥n del modelo**        | `from langchain.chat_models` (obsoleto)             | `from langchain_openai` (recomendado)                                      |\n",
    "| **Versi√≥n del API**               | Antiguo LangChain monol√≠tico                        | Nuevo ecosistema modular `langchain-openai`                                |\n",
    "| **M√©todo de ejecuci√≥n**           | `qa_chain.run(query)` (‚ö†Ô∏è obsoleto)                 | `qa_chain.invoke({\"query\": query})` (‚úÖ recomendado)                        |\n",
    "| **Fuentes del resultado**         | ‚ùå No devuelve los documentos fuente                 | ‚úÖ Incluye los documentos fuente con `return_source_documents=True`         |\n",
    "| **Retorno estructurado**          | S√≥lo devuelve texto plano                           | Devuelve un diccionario con respuesta y `source_documents`                 |\n",
    "| **Transparencia institucional**   | Baja (no se puede verificar origen de la respuesta) | Alta (permite validar en qu√© parte de los documentos se basa la respuesta) |\n",
    "| **Uso pedag√≥gico recomendado**    | Para introducir conceptos b√°sicos de `RetrievalQA`  | Para ense√±ar buenas pr√°cticas actuales en trazabilidad y uso del LLM       |\n",
    "| **Estabilidad futura del c√≥digo** | Baja (usa m√≥dulos y m√©todos deprecados)             | Alta (adaptado a la versi√≥n estable y mantenida de LangChain)              |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üß† Diferencias clave entre ambos scripts\n",
    "\n",
    "| Caracter√≠stica       | Script con `create_retrieval_chain` (moderno, script siguiente)            | Script con `RetrievalQA.from_chain_type` (cl√°sico, script anterior) |\n",
    "| -------------------- | -------------------------------------------------------- | -------------------------------------------------- |\n",
    "| API utilizada        | Moderna (modular, flexible)                              | Cl√°sica (m√°s sencilla, menos control)              |\n",
    "| Cadena usada         | `create_retrieval_chain` + `combine_docs_chain`          | `RetrievalQA.from_chain_type`                      |\n",
    "| Prompt               | Totalmente personalizado con `PromptTemplate`            | Interno, no configurable por defecto               |\n",
    "| Control de flujo     | Separaci√≥n clara de pasos (`retriever`, `prompt`, `LLM`) | Todo en una sola l√≠nea                             |\n",
    "| Adaptabilidad futura | Alta (recomendado en versiones recientes)                | Limitada (deprecated en versiones nuevas)          |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3. Con recuperaci√≥n moderna ‚Äì El sistema responde y muestra fuentes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üü¢ 6.3.0. Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains.retrieval import create_retrieval_chain\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 1. LLM moderno\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.0, api_key=api_key_environ)\n",
    "\n",
    "# 2. Prompt simple para combinar documentos\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"Usa los siguientes documentos para responder la pregunta.\\n\\n{context}\\n\\nPregunta: {input}\"\n",
    ")\n",
    "\n",
    "# 3. Cadena para combinar documentos (tipo \"stuff\")\n",
    "combine_docs_chain = create_stuff_documents_chain(\n",
    "    llm=llm,\n",
    "    prompt=prompt\n",
    ")\n",
    "\n",
    "# 4. Cadena de recuperaci√≥n completa con el retriever\n",
    "qa_chain = create_retrieval_chain(\n",
    "    retriever=retriever,\n",
    "    combine_docs_chain=combine_docs_chain\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß† Respuesta:\n",
      "1. Convenios-Contratos suscritos CCPT\n",
      "2. Anexo No. 1 - Convenios-Contratos suscritos CCPT\n",
      "3. Consolidado CCPT Detallado\n",
      "4. Convenios CCPT.xlsx\n",
      "\n",
      "üìö Documentos usados:\n",
      "\n",
      "Fuente 1: ../../../assets/DG_docs/PDF_test_gradio/2025S-VBOG-005929.pdf\n",
      "que en el documento adjunto mencionado en la respuesta al numeral 1¬∫ de la petici√≥n y que se denomina ‚ÄúConvenios-Contratos suscritos CCPT‚Äù , se relaciona la totalidad de los convenios y contratos suscritos en el marco del programa Caminos Comunitarios de la Paz Total, especificando los convenios cel\n",
      "\n",
      "Fuente 2: ../../../assets/DG_docs/PDF_test_gradio/2025S-VBOG-020627.pdf\n",
      "En la parte final de la presente respuesta usted encontrar√° un enlace donde podr√° evidenciar un archivo denominado ‚ÄúAnexo No. 1 - Convenios-Contratos suscritos CCPT‚Äù all√≠ encontrar√° la relaci√≥n de convenios y contratos suscritos en las vigencias 2023 ‚Äì 2024 con la informaci√≥n del departamento, munic\n",
      "\n",
      "Fuente 3: ../../../assets/DG_docs/PDF_test_gradio/2025S-VBOG-020627 - caminos - oscar ocampo.pdf\n",
      "En la parte final de la presente respuesta usted encontrar√° un enlace donde podr√° evidenciar un archivo denominado ‚ÄúAnexo No. 1 - Convenios-Contratos suscritos CCPT‚Äù all√≠ encontrar√° la relaci√≥n de convenios y contratos suscritos en las vigencias 2023 ‚Äì 2024 con la informaci√≥n del departamento, munic\n",
      "\n",
      "Fuente 4: ../../../assets/DG_docs/PDF_test_gradio/2025S-VBOG-018101 -  Proposici√≥n # 34 de 2025.pdf\n",
      "los 505.000 millones de pesos que se ten√≠an presupuestados durante el a√±o 2023 en el programa \"Caminos Comunitarios para la Paz\". Atendiendo al alto grado de similitud, o inclusive, repetici√≥n de la pregunta, se remite a la respuesta entregada al numeral 3 del T√≠tulo II de este cuestionario. 8. Teni\n",
      "\n",
      "Fuente 5: ../../../assets/DG_docs/PDF_test_gradio/2024S-VBOG-063933.pdf\n",
      "se tiene priorizados un total de 1.100 convenios solidarios m√°s. En el siguiente enlace se presenta el listado de los convenios suscritos durante las vigencias 2023 y 2024. Convenios CCPT.xlsx De acuerdo con lo anterior, damos por contestado el requerimiento del asunto. Atentamente, JUAN CARLOS MONT\n"
     ]
    }
   ],
   "source": [
    "response = qa_chain.invoke({\"input\": \" deme un listado de los documentos donde se menciona CCPT?\"})\n",
    "\n",
    "print(\"üß† Respuesta:\")\n",
    "print(response[\"answer\"])\n",
    "\n",
    "print(\"\\nüìö Documentos usados:\")\n",
    "for i, doc in enumerate(response[\"context\"]):\n",
    "    print(f\"\\nFuente {i+1}:\", doc.metadata.get(\"source\", \"desconocido\"))\n",
    "    print(doc.page_content[:300])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üß† Diferencias clave entre ambos scripts\n",
    "\n",
    "| Caracter√≠stica       | Script con `create_retrieval_chain` (moderno)            | Script con `RetrievalQA.from_chain_type` (cl√°sico) |\n",
    "| -------------------- | -------------------------------------------------------- | -------------------------------------------------- |\n",
    "| API utilizada        | Moderna (modular, flexible)                              | Cl√°sica (m√°s sencilla, menos control)              |\n",
    "| Cadena usada         | `create_retrieval_chain` + `combine_docs_chain`          | `RetrievalQA.from_chain_type`                      |\n",
    "| Prompt               | Totalmente personalizado con `PromptTemplate`            | Interno, no configurable por defecto               |\n",
    "| Control de flujo     | Separaci√≥n clara de pasos (`retriever`, `prompt`, `LLM`) | Todo en una sola l√≠nea                             |\n",
    "| Adaptabilidad futura | Alta (recomendado en versiones recientes)                | Limitada (deprecated en versiones nuevas)          |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üü¢ 6.3.1 Gradio para seccion 6.3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "# Funci√≥n para manejar la entrada y salida de QA Chain\n",
    "def ask_question(question: str):\n",
    "    # Invoca la cadena con la pregunta del usuario\n",
    "    response = qa_chain.invoke({\"input\": question})\n",
    "    # Extrae la respuesta\n",
    "    answer = response.get(\"answer\", \"\")\n",
    "    # Construye la lista de fuentes y fragmentos\n",
    "    context_snippets = []\n",
    "    for i, doc in enumerate(response.get(\"context\", [])):\n",
    "        source = doc.metadata.get(\"source\", \"desconocido\")\n",
    "        snippet = doc.page_content[:300].replace(\"\\n\", \" \")  # primeras 300 chars\n",
    "        context_snippets.append(f\"Fuente {i+1}: {source}\\n{snippet}\")\n",
    "    context_text = \"\\n\\n\".join(context_snippets)\n",
    "    return answer, context_text\n",
    "\n",
    "# Definici√≥n de la interfaz de Gradio\n",
    "iface = gr.Interface(\n",
    "    fn=ask_question,\n",
    "    inputs=gr.Textbox(lines=2, placeholder=\"Ingrese su pregunta aqu√≠‚Ä¶\"),\n",
    "    outputs=[\n",
    "        gr.Textbox(label=\"Respuesta\"),\n",
    "        gr.Textbox(label=\"Documentos usados\")\n",
    "    ],\n",
    "    title=\"Interfaz QA con LangChain\",\n",
    "    description=\"Ingrese una consulta y obtenga la respuesta junto con las fuentes utilizadas.\"\n",
    ")\n",
    "\n",
    "# Lanzar la aplicaci√≥n (en local o con share=True para exponerla)\n",
    "iface.launch()\n",
    "#iface.launch(share=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.3.2 ‚ùå Fall√≥ la busqueda ‚ùå"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entendido. Tu sospecha es excelente y es el camino correcto para diagnosticar el problema en un sistema RAG (B√∫squeda y Generaci√≥n Aumentada). Si el sistema no encuentra la informaci√≥n correcta, el problema casi siempre est√° en la etapa de **recuperaci√≥n (*retrieval*)**, no en el modelo de lenguaje que genera la respuesta final.\n",
    "\n",
    "Vamos a crear un \"test de recuperaci√≥n\" para verificar exactamente qu√© informaci√≥n est√° encontrando el sistema antes de intentar responder. Este test nos permitir√° aislar el problema.\n",
    "\n",
    "##### Objetivo del Test: Evaluar al `Retriever`\n",
    "\n",
    "El `retriever` es el componente encargado de buscar en tu base de datos vectorial (ChromaDB) los fragmentos de texto m√°s relevantes para la pregunta que haces. Si no le entrega los fragmentos correctos al modelo de lenguaje (LLM), es imposible que el LLM genere una buena respuesta.\n",
    "\n",
    "Vamos a ejecutar el `retriever` de forma aislada para inspeccionar su \"trabajo\".\n",
    "\n",
    "---\n",
    "\n",
    "##### Paso 1: Escoge un Caso de Prueba Espec√≠fico\n",
    "\n",
    "Primero, necesitas un \"caso de oro\" que puedas verificar manualmente.\n",
    "\n",
    "1.  **Busca en tus PDFs:** Abre uno de los documentos PDF que usaste para crear la base de datos. Encuentra un dato muy espec√≠fico y √∫nico. Por ejemplo, el nombre de un proyecto, un n√∫mero de contrato, una fecha clave o una frase t√©cnica.\n",
    "2.  **Define tu \"Golden Pair\":**\n",
    "    * **Pregunta de prueba:** Formula una pregunta que *deber√≠a* encontrar ese dato. Ejemplo: `\"¬øCu√°l es el n√∫mero del contrato para el mantenimiento de la v√≠a Oca√±a-C√∫cuta?\"`\n",
    "    * **Contenido esperado:** Anota la frase o las palabras clave que *obligatoriamente* deben estar en los fragmentos recuperados para poder responder la pregunta. Ejemplo: `\"contrato de obra p√∫blica No. 2345-2023\"`.\n",
    "\n",
    "##### Paso 2: C√≥digo para Ejecutar el Test\n",
    "\n",
    "He preparado una versi√≥n simplificada de tu script que se enfoca **√∫nicamente en realizar este test**. No utilizaremos el LLM para generar respuestas, solo para cargar los embeddings y usar el `retriever`.\n",
    "\n",
    "Copia y ejecuta el siguiente c√≥digo. Aseg√∫rate de modificar las variables de la secci√≥n \"CONFIGURACI√ìN DEL TEST\".\n",
    "\n",
    "```python\n",
    "import os\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "# --- CONFIGURACI√ìN DEL TEST ---\n",
    "# 1. Aseg√∫rate de que tu clave de API est√© configurada como variable de entorno\n",
    "#    os.environ[\"OPENAI_API_KEY\"] = \"tu_clave_aqui\"\n",
    "\n",
    "# 2. Define la pregunta y el contenido que esperas encontrar\n",
    "TEST_QUERY = \"que pasa en Oca√±a?\"  # <--- CAMBIA ESTO por tu pregunta de prueba\n",
    "EXPECTED_KEYWORDS = [\"Oca√±a\", \"emergencia\", \"deslizamiento\"] # <--- CAMBIA ESTO por las palabras clave que deben aparecer\n",
    "\n",
    "# 3. Define la ruta a tu base de datos vectorial\n",
    "PERSIST_DIRECTORY = \"chroma_db\"\n",
    "EMBEDDING_MODEL = \"text-embedding-3-small\" # Usa el mismo modelo con el que creaste la base\n",
    "\n",
    "# --- L√ìGICA DEL TEST ---\n",
    "\n",
    "print(\"üß™ Iniciando el Test de Recuperaci√≥n de Contexto...\")\n",
    "\n",
    "# 1. Validar configuraci√≥n\n",
    "api_key_environ = os.environ.get(\"OPENAI_API_KEY\")\n",
    "if not api_key_environ:\n",
    "    raise ValueError(\"La variable de entorno OPENAI_API_KEY no est√° configurada.\")\n",
    "\n",
    "if not os.path.exists(PERSIST_DIRECTORY):\n",
    "    raise FileNotFoundError(f\"El directorio de la base de datos '{PERSIST_DIRECTORY}' no existe. Aseg√∫rate de haber ejecutado el script principal primero.\")\n",
    "\n",
    "print(f\"Buscando en la base de datos en: '{PERSIST_DIRECTORY}'\")\n",
    "\n",
    "# 2. Cargar el retriever\n",
    "print(f\"Cargando embeddings con el modelo: '{EMBEDDING_MODEL}'...\")\n",
    "embeddings = OpenAIEmbeddings(model=EMBEDDING_MODEL)\n",
    "vectorstore = Chroma(\n",
    "    persist_directory=PERSIST_DIRECTORY,\n",
    "    embedding_function=embeddings\n",
    ")\n",
    "# Aumentamos 'k' para tener m√°s contexto que inspeccionar\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 5})\n",
    "\n",
    "# 3. Ejecutar el retriever de forma aislada\n",
    "print(f\"\\nüîç Ejecutando retriever con la pregunta: '{TEST_QUERY}'\")\n",
    "retrieved_docs = retriever.invoke(TEST_QUERY)\n",
    "\n",
    "# 4. Analizar los resultados\n",
    "print(\"\\nüìÑ --- Fragmentos Recuperados --- üìÑ\")\n",
    "if not retrieved_docs:\n",
    "    print(\"‚ùå ¬°ERROR! El retriever no devolvi√≥ ning√∫n documento.\")\n",
    "else:\n",
    "    for i, doc in enumerate(retrieved_docs):\n",
    "        source = doc.metadata.get(\"source\", \"desconocido\")\n",
    "        content = doc.page_content\n",
    "        print(f\"\\n--- Documento {i+1} (Fuente: {source}) ---\\n\")\n",
    "        print(content)\n",
    "        print(\"-\" * 40)\n",
    "\n",
    "# 5. Verificaci√≥n autom√°tica\n",
    "print(\"\\nüèÅ --- Verificaci√≥n de Palabras Clave --- üèÅ\")\n",
    "found_keywords_count = 0\n",
    "for doc in retrieved_docs:\n",
    "    for keyword in EXPECTED_KEYWORDS:\n",
    "        if keyword.lower() in doc.page_content.lower():\n",
    "            print(f\"‚úÖ Palabra clave encontrada: '{keyword}' en Fuente: {doc.metadata.get('source', 'N/A')}\")\n",
    "            found_keywords_count += 1\n",
    "\n",
    "print(\"\\n--- Veredicto del Test ---\")\n",
    "if found_keywords_count > 0:\n",
    "    print(\"‚úÖ √âXITO PARCIAL/TOTAL: Se encontraron uno o m√°s de los contenidos esperados en los fragmentos recuperados.\")\n",
    "else:\n",
    "    print(\"‚ùå FALLO: Ninguna de las palabras clave esperadas fue encontrada. El contexto relevante no se est√° recuperando.\")\n",
    "\n",
    "```\n",
    "\n",
    "##### ¬øC√≥mo Interpretar los Resultados?\n",
    "\n",
    "1.  **Si el veredicto es \"√âXITO\"**: Significa que tu base de datos y tu `retriever` funcionan correctamente. El problema podr√≠a estar en el `prompt` que le das al LLM o en el propio LLM (aunque es menos probable).\n",
    "2.  **Si el veredicto es \"FALLO\"**: Confirma tu sospecha. El problema est√° en la base de conocimiento. El sistema no es capaz de encontrar los fragmentos de texto relevantes.\n",
    "\n",
    "##### ¬øQu√© Hacer si el Test Falla?\n",
    "\n",
    "Si el test falla, aqu√≠ tienes las causas m√°s probables y c√≥mo solucionarlas:\n",
    "\n",
    "1.  **Problema con la Divisi√≥n de Texto (`chunking`)**:\n",
    "    * **Causa**: El `chunk_size=1500` puede ser muy grande, y la informaci√≥n clave se \"diluye\" con texto irrelevante en el mismo fragmento. O puede ser muy peque√±o y parte una frase importante.\n",
    "    * **Soluci√≥n**: Prueba a regenerar tu base de datos con un `chunk_size` m√°s peque√±o (ej. 1000) y un `chunk_overlap` mayor (ej. 250). Esto crea m√°s fragmentos, pero m√°s enfocados.\n",
    "\n",
    "2.  **Problema con la Extracci√≥n de Texto del PDF**:\n",
    "    * **Causa**: Algunos PDFs son en realidad im√°genes de texto (escaneados). `PyPDFLoader` no puede leer texto de im√°genes.\n",
    "    * **Soluci√≥n**: Verifica el contenido de tus documentos justo despu√©s de cargarlos (la variable `ml_papers` en tu script original). Si ves caracteres extra√±os o texto sin sentido, necesitas usar una herramienta de **OCR (Reconocimiento √ìptico de Caracteres)** para extraer el texto de esos PDFs antes de pasarlos a LangChain.\n",
    "\n",
    "3.  **Problema con el Modelo de Embeddings**:\n",
    "    * **Causa**: `text-embedding-ada-002` es un modelo m√°s antiguo. Puede que no est√© capturando el significado sem√°ntico de tu pregunta con la suficiente precisi√≥n.\n",
    "    * **Soluci√≥n**: Regenera tu base de datos usando un modelo m√°s moderno y potente como `\"text-embedding-3-small\"` (m√°s barato y eficiente) o `\"text-embedding-3-large\"` (m√°xima calidad). Tu propio c√≥digo ya tiene un comentario sugiriendo este cambio.\n",
    "\n",
    "Ejecuta este test y, seg√∫n el resultado, podremos enfocarnos en la soluci√≥n correcta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6.3.2.1. Analisis del documento 73SentenciaTutela.pdf by GEMINI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excelente. He analizado el documento `73SentenciaTutela.pdf` y he extra√≠do varios datos espec√≠ficos y √∫nicos que nos servir√°n perfectamente para crear los \"casos de oro\" y probar la eficacia de tu sistema de recuperaci√≥n de informaci√≥n.\n",
    "\n",
    "A continuaci√≥n, te presento 3 casos de prueba con diferentes niveles de especificidad. Podemos usar uno o todos para diagnosticar tu sistema.\n",
    "\n",
    "---\n",
    "\n",
    "###### Caso de Prueba 1: **N√∫mero de Radicaci√≥n (Dato √önico)**\n",
    "\n",
    "Este es el dato m√°s espec√≠fico y f√°cil de verificar. Es ideal para una primera prueba.\n",
    "\n",
    "* [cite_start]**Dato espec√≠fico encontrado:** El n√∫mero de radicaci√≥n del proceso de tutela es `080013187005202500020-00`[cite: 1, 7, 15, 23, 29, 37, 47, 55, 64, 74, 86, 94, 101, 110, 116, 125, 132, 140, 145, 149, 154, 163, 171, 180, 187, 195, 206, 222, 231, 239, 255, 262, 269, 276, 286, 297, 305, 313, 323, 329].\n",
    "* **Pregunta de prueba sugerida:** `¬øCu√°l es el n√∫mero de radicaci√≥n de la acci√≥n de tutela de Gersel Luis P√©rez Altamiranda?`\n",
    "* **Contenido esperado (palabras clave):** El `retriever` debe devolver fragmentos que contengan obligatoriamente la cadena `080013187005202500020-00`.\n",
    "\n",
    "###### Caso de Prueba 2: **Nombre de Resoluci√≥n (Dato Espec√≠fico)**\n",
    "\n",
    "Este caso prueba si el sistema puede asociar una acci√≥n (distribuir un cobro) con un acto administrativo concreto.\n",
    "\n",
    "* [cite_start]**Dato espec√≠fico encontrado:** La `Resoluci√≥n No. 3856 de 26 de agosto de 2024` es la que distribuye el cobro de la Contribuci√≥n Nacional de Valorizaci√≥n[cite: 9, 11].\n",
    "* **Pregunta de prueba sugerida:** `¬øQu√© resoluci√≥n distribuye el cobro de la Contribuci√≥n Nacional de Valorizaci√≥n para el proyecto Circunvalar de la Prosperidad?`\n",
    "* **Contenido esperado (palabras clave):** El `retriever` deber√≠a encontrar fragmentos que incluyan `Resoluci√≥n No. 3856` y `distribuye el cobro`.\n",
    "\n",
    "###### Caso de Prueba 3: **Concepto Jur√≠dico y Condici√≥n (Dato Complejo)**\n",
    "\n",
    "Este caso es m√°s avanzado. Eval√∫a si el sistema puede encontrar informaci√≥n conceptual y sus condiciones, no solo datos literales.\n",
    "\n",
    "* [cite_start]**Dato espec√≠fico encontrado:** La Ley 1819 de 2016, en su art√≠culo 253, excluye del cobro de valorizaci√≥n a \"las tierras comunales de grupos √©tnicos, las tierras de resguardo y el patrimonio arqueol√≥gico y cultural de la naci√≥n, cuando su titularidad radique en una entidad de derecho p√∫blico\"[cite: 112, 127, 166, 235].\n",
    "* **Pregunta de prueba sugerida:** `¬øBajo qu√© condici√≥n est√°n excluidas del cobro de valorizaci√≥n las tierras de grupos √©tnicos?`\n",
    "* **Contenido esperado (palabras clave):** El `retriever` debe recuperar fragmentos que contengan `excluidos`, `tierras comunales`, `grupos √©tnicos` y, crucialmente, `titularidad radique en una entidad de derecho p√∫blico`.\n",
    "\n",
    "---\n",
    "\n",
    "**Siguiente Paso Sugerido:**\n",
    "\n",
    "Ahora que tenemos estos casos, te propongo que elijas uno de ellos (recomiendo empezar por el **Caso de Prueba 1** por su simplicidad) y lo usemos en el script de test que te proporcion√© anteriormente.\n",
    "\n",
    "Solo necesitas actualizar la secci√≥n `CONFIGURACI√ìN DEL TEST` en ese c√≥digo con la \"Pregunta de prueba\" y el \"Contenido esperado\" del caso que elijas. Al ejecutarlo, veremos inmediatamente si tu sistema puede encontrar esta informaci√≥n b√°sica en el PDF."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### ü™õ PREGUNTA 1: ¬øCu√°l es el n√∫mero de radicaci√≥n de la acci√≥n de tutela de Gersel Luis P√©rez Altamiranda?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "# --- CONFIGURACI√ìN DEL TEST ---\n",
    "# 1. Aseg√∫rate de que tu clave de API est√© configurada como variable de entorno\n",
    "#    os.environ[\"OPENAI_API_KEY\"] = \"tu_clave_aqui\"\n",
    "\n",
    "# 2. Define la pregunta y el contenido que esperas encontrar\n",
    "TEST_QUERY = \"¬øCu√°l es el n√∫mero de radicaci√≥n de la acci√≥n de tutela de Gersel Luis P√©rez Altamiranda?\"  # <--- CAMBIA ESTO por tu pregunta de prueba\n",
    "EXPECTED_KEYWORDS = [\"080013187005202500020-00\"] # <--- CAMBIA ESTO por las palabras clave que deben aparecer\n",
    "\n",
    "# 3. Define la ruta a tu base de datos vectorial\n",
    "PERSIST_DIRECTORY = \"chroma_db\"\n",
    "EMBEDDING_MODEL = \"text-embedding-3-small\" # Usa el mismo modelo con el que creaste la base\n",
    "\n",
    "# --- L√ìGICA DEL TEST ---\n",
    "\n",
    "print(\"üß™ Iniciando el Test de Recuperaci√≥n de Contexto...\")\n",
    "\n",
    "# 1. Validar configuraci√≥n\n",
    "api_key_environ = os.environ.get(\"OPENAI_API_KEY\")\n",
    "if not api_key_environ:\n",
    "    raise ValueError(\"La variable de entorno OPENAI_API_KEY no est√° configurada.\")\n",
    "\n",
    "if not os.path.exists(PERSIST_DIRECTORY):\n",
    "    raise FileNotFoundError(f\"El directorio de la base de datos '{PERSIST_DIRECTORY}' no existe. Aseg√∫rate de haber ejecutado el script principal primero.\")\n",
    "\n",
    "print(f\"Buscando en la base de datos en: '{PERSIST_DIRECTORY}'\")\n",
    "\n",
    "# 2. Cargar el retriever\n",
    "print(f\"Cargando embeddings con el modelo: '{EMBEDDING_MODEL}'...\")\n",
    "embeddings = OpenAIEmbeddings(model=EMBEDDING_MODEL)\n",
    "vectorstore = Chroma(\n",
    "    persist_directory=PERSIST_DIRECTORY,\n",
    "    embedding_function=embeddings\n",
    ")\n",
    "# Aumentamos 'k' para tener m√°s contexto que inspeccionar\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 5})\n",
    "\n",
    "# 3. Ejecutar el retriever de forma aislada\n",
    "print(f\"\\nüîç Ejecutando retriever con la pregunta: '{TEST_QUERY}'\")\n",
    "retrieved_docs = retriever.invoke(TEST_QUERY)\n",
    "\n",
    "# 4. Analizar los resultados\n",
    "print(\"\\nüìÑ --- Fragmentos Recuperados --- üìÑ\")\n",
    "if not retrieved_docs:\n",
    "    print(\"‚ùå ¬°ERROR! El retriever no devolvi√≥ ning√∫n documento.\")\n",
    "else:\n",
    "    for i, doc in enumerate(retrieved_docs):\n",
    "        source = doc.metadata.get(\"source\", \"desconocido\")\n",
    "        content = doc.page_content\n",
    "        print(f\"\\n--- Documento {i+1} (Fuente: {source}) ---\\n\")\n",
    "        print(content)\n",
    "        print(\"-\" * 40)\n",
    "\n",
    "# 5. Verificaci√≥n autom√°tica\n",
    "print(\"\\nüèÅ --- Verificaci√≥n de Palabras Clave --- üèÅ\")\n",
    "found_keywords_count = 0\n",
    "for doc in retrieved_docs:\n",
    "    for keyword in EXPECTED_KEYWORDS:\n",
    "        if keyword.lower() in doc.page_content.lower():\n",
    "            print(f\"‚úÖ Palabra clave encontrada: '{keyword}' en Fuente: {doc.metadata.get('source', 'N/A')}\")\n",
    "            found_keywords_count += 1\n",
    "\n",
    "print(\"\\n--- Veredicto del Test ---\")\n",
    "if found_keywords_count > 0:\n",
    "    print(\"‚úÖ √âXITO PARCIAL/TOTAL: Se encontraron uno o m√°s de los contenidos esperados en los fragmentos recuperados.\")\n",
    "else:\n",
    "    print(\"‚ùå FALLO: Ninguna de las palabras clave esperadas fue encontrada. El contexto relevante no se est√° recuperando.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### ü™õ PREGUNTA 2: ¬øQu√© resoluci√≥n distribuye el cobro de la Contribuci√≥n Nacional de Valorizaci√≥n para el proyecto Circunvalar de la Prosperidad?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "# --- CONFIGURACI√ìN DEL TEST ---\n",
    "# 1. Aseg√∫rate de que tu clave de API est√© configurada como variable de entorno\n",
    "#    os.environ[\"OPENAI_API_KEY\"] = \"tu_clave_aqui\"\n",
    "\n",
    "# 2. Define la pregunta y el contenido que esperas encontrar\n",
    "TEST_QUERY = \"¬øQu√© resoluci√≥n distribuye el cobro de la Contribuci√≥n Nacional de Valorizaci√≥n para el proyecto Circunvalar de la Prosperidad?\"  # <--- CAMBIA ESTO por tu pregunta de prueba\n",
    "EXPECTED_KEYWORDS = [\"Resoluci√≥n No. 3856\", \"distribuye el cobro\"] # <--- CAMBIA ESTO por las palabras clave que deben aparecer\n",
    "\n",
    "# 3. Define la ruta a tu base de datos vectorial\n",
    "PERSIST_DIRECTORY = \"chroma_db\"\n",
    "EMBEDDING_MODEL = \"text-embedding-3-small\" # Usa el mismo modelo con el que creaste la base\n",
    "\n",
    "# --- L√ìGICA DEL TEST ---\n",
    "\n",
    "print(\"üß™ Iniciando el Test de Recuperaci√≥n de Contexto...\")\n",
    "\n",
    "# 1. Validar configuraci√≥n\n",
    "api_key_environ = os.environ.get(\"OPENAI_API_KEY\")\n",
    "if not api_key_environ:\n",
    "    raise ValueError(\"La variable de entorno OPENAI_API_KEY no est√° configurada.\")\n",
    "\n",
    "if not os.path.exists(PERSIST_DIRECTORY):\n",
    "    raise FileNotFoundError(f\"El directorio de la base de datos '{PERSIST_DIRECTORY}' no existe. Aseg√∫rate de haber ejecutado el script principal primero.\")\n",
    "\n",
    "print(f\"Buscando en la base de datos en: '{PERSIST_DIRECTORY}'\")\n",
    "\n",
    "# 2. Cargar el retriever\n",
    "print(f\"Cargando embeddings con el modelo: '{EMBEDDING_MODEL}'...\")\n",
    "embeddings = OpenAIEmbeddings(model=EMBEDDING_MODEL)\n",
    "vectorstore = Chroma(\n",
    "    persist_directory=PERSIST_DIRECTORY,\n",
    "    embedding_function=embeddings\n",
    ")\n",
    "# Aumentamos 'k' para tener m√°s contexto que inspeccionar\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 5})\n",
    "\n",
    "# 3. Ejecutar el retriever de forma aislada\n",
    "print(f\"\\nüîç Ejecutando retriever con la pregunta: '{TEST_QUERY}'\")\n",
    "retrieved_docs = retriever.invoke(TEST_QUERY)\n",
    "\n",
    "# 4. Analizar los resultados\n",
    "print(\"\\nüìÑ --- Fragmentos Recuperados --- üìÑ\")\n",
    "if not retrieved_docs:\n",
    "    print(\"‚ùå ¬°ERROR! El retriever no devolvi√≥ ning√∫n documento.\")\n",
    "else:\n",
    "    for i, doc in enumerate(retrieved_docs):\n",
    "        source = doc.metadata.get(\"source\", \"desconocido\")\n",
    "        content = doc.page_content\n",
    "        print(f\"\\n--- Documento {i+1} (Fuente: {source}) ---\\n\")\n",
    "        print(content)\n",
    "        print(\"-\" * 40)\n",
    "\n",
    "# 5. Verificaci√≥n autom√°tica\n",
    "print(\"\\nüèÅ --- Verificaci√≥n de Palabras Clave --- üèÅ\")\n",
    "found_keywords_count = 0\n",
    "for doc in retrieved_docs:\n",
    "    for keyword in EXPECTED_KEYWORDS:\n",
    "        if keyword.lower() in doc.page_content.lower():\n",
    "            print(f\"‚úÖ Palabra clave encontrada: '{keyword}' en Fuente: {doc.metadata.get('source', 'N/A')}\")\n",
    "            found_keywords_count += 1\n",
    "\n",
    "print(\"\\n--- Veredicto del Test ---\")\n",
    "if found_keywords_count > 0:\n",
    "    print(\"‚úÖ √âXITO PARCIAL/TOTAL: Se encontraron uno o m√°s de los contenidos esperados en los fragmentos recuperados.\")\n",
    "else:\n",
    "    print(\"‚ùå FALLO: Ninguna de las palabras clave esperadas fue encontrada. El contexto relevante no se est√° recuperando.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### ü™õ PREGUNTA 3: ¬øBajo qu√© condici√≥n est√°n excluidas del cobro de valorizaci√≥n las tierras de grupos √©tnicos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "# --- CONFIGURACI√ìN DEL TEST ---\n",
    "# 1. Aseg√∫rate de que tu clave de API est√© configurada como variable de entorno\n",
    "#    os.environ[\"OPENAI_API_KEY\"] = \"tu_clave_aqui\"\n",
    "\n",
    "# 2. Define la pregunta y el contenido que esperas encontrar\n",
    "TEST_QUERY = \"¬øBajo qu√© condici√≥n est√°n excluidas del cobro de valorizaci√≥n las tierras de grupos √©tnicos?\"  # <--- CAMBIA ESTO por tu pregunta de prueba\n",
    "EXPECTED_KEYWORDS = [\"excluidos\", \"tierras comunales\", \"grupos √©tnicos\", \"titularidad radique en una entidad de derecho p√∫blico\"] # <--- CAMBIA ESTO por las palabras clave que deben aparecer\n",
    "\n",
    "# 3. Define la ruta a tu base de datos vectorial\n",
    "PERSIST_DIRECTORY = \"chroma_db\"\n",
    "EMBEDDING_MODEL = \"text-embedding-3-small\" # Usa el mismo modelo con el que creaste la base\n",
    "\n",
    "# --- L√ìGICA DEL TEST ---\n",
    "\n",
    "print(\"üß™ Iniciando el Test de Recuperaci√≥n de Contexto...\")\n",
    "\n",
    "# 1. Validar configuraci√≥n\n",
    "api_key_environ = os.environ.get(\"OPENAI_API_KEY\")\n",
    "if not api_key_environ:\n",
    "    raise ValueError(\"La variable de entorno OPENAI_API_KEY no est√° configurada.\")\n",
    "\n",
    "if not os.path.exists(PERSIST_DIRECTORY):\n",
    "    raise FileNotFoundError(f\"El directorio de la base de datos '{PERSIST_DIRECTORY}' no existe. Aseg√∫rate de haber ejecutado el script principal primero.\")\n",
    "\n",
    "print(f\"Buscando en la base de datos en: '{PERSIST_DIRECTORY}'\")\n",
    "\n",
    "# 2. Cargar el retriever\n",
    "print(f\"Cargando embeddings con el modelo: '{EMBEDDING_MODEL}'...\")\n",
    "embeddings = OpenAIEmbeddings(model=EMBEDDING_MODEL)\n",
    "vectorstore = Chroma(\n",
    "    persist_directory=PERSIST_DIRECTORY,\n",
    "    embedding_function=embeddings\n",
    ")\n",
    "# Aumentamos 'k' para tener m√°s contexto que inspeccionar\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 5})\n",
    "\n",
    "# 3. Ejecutar el retriever de forma aislada\n",
    "print(f\"\\nüîç Ejecutando retriever con la pregunta: '{TEST_QUERY}'\")\n",
    "retrieved_docs = retriever.invoke(TEST_QUERY)\n",
    "\n",
    "# 4. Analizar los resultados\n",
    "print(\"\\nüìÑ --- Fragmentos Recuperados --- üìÑ\")\n",
    "if not retrieved_docs:\n",
    "    print(\"‚ùå ¬°ERROR! El retriever no devolvi√≥ ning√∫n documento.\")\n",
    "else:\n",
    "    for i, doc in enumerate(retrieved_docs):\n",
    "        source = doc.metadata.get(\"source\", \"desconocido\")\n",
    "        content = doc.page_content\n",
    "        print(f\"\\n--- Documento {i+1} (Fuente: {source}) ---\\n\")\n",
    "        print(content)\n",
    "        print(\"-\" * 40)\n",
    "\n",
    "# 5. Verificaci√≥n autom√°tica\n",
    "print(\"\\nüèÅ --- Verificaci√≥n de Palabras Clave --- üèÅ\")\n",
    "found_keywords_count = 0\n",
    "for doc in retrieved_docs:\n",
    "    for keyword in EXPECTED_KEYWORDS:\n",
    "        if keyword.lower() in doc.page_content.lower():\n",
    "            print(f\"‚úÖ Palabra clave encontrada: '{keyword}' en Fuente: {doc.metadata.get('source', 'N/A')}\")\n",
    "            found_keywords_count += 1\n",
    "\n",
    "print(\"\\n--- Veredicto del Test ---\")\n",
    "if found_keywords_count > 0:\n",
    "    print(\"‚úÖ √âXITO PARCIAL/TOTAL: Se encontraron uno o m√°s de los contenidos esperados en los fragmentos recuperados.\")\n",
    "else:\n",
    "    print(\"‚ùå FALLO: Ninguna de las palabras clave esperadas fue encontrada. El contexto relevante no se est√° recuperando.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6.3.2.2. Diagn√≥stico Definitivo: Verifiquemos qu√© \"lee\" `PyPDFLoader`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, este resultado es la pieza de informaci√≥n m√°s importante que podr√≠amos haber obtenido y confirma nuestras sospechas de la manera m√°s clara posible.\n",
    "\n",
    "El hecho de que los tres tests hayan fallado, en especial el del **n√∫mero de radicaci√≥n** (que es un dato literal y √∫nico), nos dice con un 99% de certeza que el problema no est√° en la configuraci√≥n de la b√∫squeda (`chunk_size`), ni en el modelo de `embeddings`.\n",
    "\n",
    "**El problema fundamental est√° en la extracci√≥n del texto del propio archivo PDF.**\n",
    "\n",
    "Para usar una analog√≠a: le hemos pedido a nuestro sistema que busque una aguja en un pajar, pero al revisar el pajar, descubrimos que nunca metimos la aguja dentro. El \"texto\" que tu sistema tiene almacenado probablemente est√° corrupto, incompleto o es inexistente.\n",
    "\n",
    "###### Diagn√≥stico Definitivo: Verifiquemos qu√© \"lee\" `PyPDFLoader`\n",
    "\n",
    "La causa m√°s com√∫n de este fallo total es que el PDF (`73SentenciaTutela.pdf`) no es un documento de texto, sino un **conjunto de im√°genes escaneadas**. `PyPDFLoader` no puede leer texto de im√°genes, por lo que extrae caracteres sin sentido o simplemente cadenas vac√≠as.\n",
    "\n",
    "Vamos a hacer un √∫ltimo test, el m√°s simple y revelador de todos. Ejecutemos un c√≥digo que solo cargue el PDF y nos muestre exactamente qu√© texto est√° extrayendo.\n",
    "\n",
    "**C√≥digo de Diagn√≥stico de Extracci√≥n:**\n",
    "\n",
    "```python\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "import os\n",
    "\n",
    "# --- CONFIGURACI√ìN ---\n",
    "# Aseg√∫rate de que el PDF est√© en la misma carpeta que este script,\n",
    "# o proporciona la ruta completa.\n",
    "PDF_PATH = \"73SentenciaTutela.pdf\" \n",
    "\n",
    "# --- L√ìGICA DE DIAGN√ìSTICO ---\n",
    "\n",
    "print(f\"üìÑ Intentando cargar el archivo: {PDF_PATH}\")\n",
    "\n",
    "if not os.path.exists(PDF_PATH):\n",
    "    print(f\"‚ùå ERROR: No se encontr√≥ el archivo en la ruta especificada.\")\n",
    "else:\n",
    "    try:\n",
    "        loader = PyPDFLoader(PDF_PATH)\n",
    "        pages = loader.load()\n",
    "        \n",
    "        print(f\"\\n‚úÖ Archivo cargado. El PDF tiene {len(pages)} p√°ginas.\")\n",
    "        print(\"--- Mostrando el texto extra√≠do de las primeras 3 p√°ginas ---\")\n",
    "        \n",
    "        for i in range(min(3, len(pages))):\n",
    "            page_content = pages[i].page_content\n",
    "            print(f\"\\n\\n--- P√ÅGINA {i+1} ---\")\n",
    "            # Imprimimos solo los primeros 500 caracteres para no saturar la pantalla\n",
    "            print(page_content[:500])\n",
    "            if not page_content.strip():\n",
    "                print(\">>> ¬°ALERTA! El contenido de esta p√°gina est√° vac√≠o o solo contiene espacios.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Ocurri√≥ un error al cargar o procesar el PDF: {e}\")\n",
    "\n",
    "```\n",
    "\n",
    "###### ¬øQu√© Esperamos Ver?\n",
    "\n",
    "Ejecuta el c√≥digo anterior. El resultado nos dir√° todo:\n",
    "\n",
    "  * **Resultado Esperado (si todo estuviera bien):** Ver√≠as el texto real de la sentencia, claramente legible. Por ejemplo: `Rama Judicial Consejo Superior de la Judicatura...`.\n",
    "  * **Resultado Incorrecto (El m√°s probable):** Ver√°s una salida con texto sin sentido, s√≠mbolos extra√±os, o peor a√∫n, una salida completamente vac√≠a (`''`). **Esta es mi principal sospecha.**\n",
    "\n",
    "-----\n",
    "\n",
    "###### La Soluci√≥n: Usar OCR (Reconocimiento √ìptico de Caracteres)\n",
    "\n",
    "Si confirmamos que el texto extra√≠do es basura o est√° vac√≠o, la soluci√≥n es procesar el PDF con una herramienta de **OCR**. Esto convierte las im√°genes de texto en texto real que LangChain s√≠ puede entender.\n",
    "\n",
    "Aqu√≠ te explico c√≥mo modificar tu flujo de trabajo para incluir OCR.\n",
    "\n",
    "####### 1\\. Instalar las librer√≠as necesarias\n",
    "\n",
    "Necesitar√°s instalar `pytesseract`, una librer√≠a de Python que interact√∫a con el motor de OCR de Google (Tesseract), y `pdf2image` para convertir las p√°ginas del PDF en im√°genes.\n",
    "\n",
    "```bash\n",
    "pip install pytesseract pdf2image Pillow\n",
    "```\n",
    "\n",
    "Adem√°s, debes **instalar el motor Tesseract de Google** en tu sistema. Las instrucciones var√≠an seg√∫n tu sistema operativo:\n",
    "\n",
    "  * **Windows:** Descarga el instalador desde [este enlace oficial](https://www.google.com/search?q=https://github.com/UB-Mannheim/tesseract/wiki) y aseg√∫rate de a√±adir la ruta de instalaci√≥n al PATH de tu sistema.\n",
    "  * **macOS:** `brew install tesseract`\n",
    "  * **Linux (Debian/Ubuntu):** `sudo apt-get install tesseract-ocr`\n",
    "\n",
    "####### 2\\. Nuevo Proceso para Cargar Documentos con OCR\n",
    "\n",
    "Ahora, en lugar de usar `PyPDFLoader`, usar√≠as una funci√≥n personalizada que primero hace OCR y luego crea los objetos `Document` que LangChain necesita.\n",
    "\n",
    "Este ser√≠a el reemplazo para tu celda \"Carga de documents\":\n",
    "\n",
    "```python\n",
    "from pdf2image import convert_from_path\n",
    "import pytesseract\n",
    "from langchain.docstore.document import Document\n",
    "import os\n",
    "\n",
    "# --- CONFIGURACI√ìN ---\n",
    "PDF_PATH = \"73SentenciaTutela.pdf\" # Ruta a tu PDF\n",
    "\n",
    "# Si instalaste Tesseract en una ubicaci√≥n no est√°ndar (Windows),\n",
    "# podr√≠as necesitar especificar la ruta aqu√≠.\n",
    "# pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n",
    "\n",
    "\n",
    "# --- FUNCI√ìN DE CARGA CON OCR ---\n",
    "def load_pdf_with_ocr(file_path):\n",
    "    \"\"\"\n",
    "    Carga un PDF, extrae texto de cada p√°gina usando OCR y devuelve\n",
    "    una lista de objetos Document de LangChain.\n",
    "    \"\"\"\n",
    "    print(\"üîÑ Convirtiendo p√°ginas de PDF a im√°genes...\")\n",
    "    images = convert_from_path(file_path)\n",
    "    \n",
    "    documents_ocr = []\n",
    "    print(f\"üîç Procesando {len(images)} p√°ginas con OCR...\")\n",
    "    \n",
    "    for i, image in enumerate(images):\n",
    "        # Usar Tesseract para extraer texto de la imagen\n",
    "        # 'spa' es para espa√±ol\n",
    "        text = pytesseract.image_to_string(image, lang='spa')\n",
    "        \n",
    "        # Crear un documento de LangChain por cada p√°gina\n",
    "        doc = Document(\n",
    "            page_content=text,\n",
    "            metadata={\n",
    "                \"source\": os.path.basename(file_path),\n",
    "                \"page\": i + 1\n",
    "            }\n",
    "        )\n",
    "        documents_ocr.append(doc)\n",
    "    \n",
    "    print(\"‚úÖ Proceso de OCR completado.\")\n",
    "    return documents_ocr\n",
    "\n",
    "\n",
    "# --- EJECUCI√ìN ---\n",
    "# Reemplaza la carga original de PyPDFLoader con esta funci√≥n\n",
    "ml_papers = load_pdf_with_ocr(PDF_PATH)\n",
    "\n",
    "# A partir de aqu√≠, el resto de tu script sigue igual.\n",
    "# La variable `ml_papers` ahora contiene el texto extra√≠do correctamente.\n",
    "print(f\"\\nTotal de p√°ginas procesadas: {len(ml_papers)}\")\n",
    "print(\"\\nContenido de la primera p√°gina (extra√≠do con OCR):\")\n",
    "print(ml_papers[0].page_content[:500])\n",
    "\n",
    "# Ahora puedes pasar `ml_papers` al `text_splitter`\n",
    "# text_splitter = RecursiveCharacterTextSplitter(...)\n",
    "# documents = text_splitter.split_documents(ml_papers)\n",
    "# ...y continuar con el resto de tu script.\n",
    "```\n",
    "\n",
    "Te recomiendo primero ejecutar el **c√≥digo de diagn√≥stico**. Una vez que confirmes que la extracci√≥n de texto falla, implementa la **soluci√≥n con OCR**. Este es el camino correcto para resolver el problema de ra√≠z."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### ü™õ C√≥digo de Diagn√≥stico de Extracci√≥n:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "import os\n",
    "\n",
    "# --- CONFIGURACI√ìN ---\n",
    "# Aseg√∫rate de que el PDF est√© en la misma carpeta que este script,\n",
    "# o proporciona la ruta completa.\n",
    "PDF_PATH = \"../../../assets/DG_docs/PDF_test_gradio/73SentenciaTutela.pdf\" \n",
    "\n",
    "# --- L√ìGICA DE DIAGN√ìSTICO ---\n",
    "\n",
    "print(f\"üìÑ Intentando cargar el archivo: {PDF_PATH}\")\n",
    "\n",
    "if not os.path.exists(PDF_PATH):\n",
    "    print(f\"‚ùå ERROR: No se encontr√≥ el archivo en la ruta especificada.\")\n",
    "else:\n",
    "    try:\n",
    "        loader = PyPDFLoader(PDF_PATH)\n",
    "        pages = loader.load()\n",
    "        \n",
    "        print(f\"\\n‚úÖ Archivo cargado. El PDF tiene {len(pages)} p√°ginas.\")\n",
    "        print(\"--- Mostrando el texto extra√≠do de las primeras 3 p√°ginas ---\")\n",
    "        \n",
    "        for i in range(min(3, len(pages))):\n",
    "            page_content = pages[i].page_content\n",
    "            print(f\"\\n\\n--- P√ÅGINA {i+1} ---\")\n",
    "            # Imprimimos solo los primeros 500 caracteres para no saturar la pantalla\n",
    "            print(page_content[:500])\n",
    "            if not page_content.strip():\n",
    "                print(\">>> ¬°ALERTA! El contenido de esta p√°gina est√° vac√≠o o solo contiene espacios.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Ocurri√≥ un error al cargar o procesar el PDF: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6.3.2.3. Inspeccionar los \"Chunks\" o Fragmentos Finales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¬°Perfecto! Esta informaci√≥n que me has dado es incre√≠blemente √∫til y **cambia por completo el diagn√≥stico.**\n",
    "\n",
    "Tu resultado demuestra que mi sospecha anterior (que el PDF era una imagen) era incorrecta. **El `PyPDFLoader` S√ç est√° extrayendo el texto correctamente y de forma legible.** Esta es una excelente noticia, porque significa que no necesitamos la complejidad de usar OCR.\n",
    "\n",
    "Sin embargo, esto tambi√©n nos dice que, si el texto se carga bien pero la b√∫squeda sigue fallando, el problema debe ocurrir en uno de los pasos intermedios:\n",
    "\n",
    "1.  La **divisi√≥n del texto** (`RecursiveCharacterTextSplitter`).\n",
    "2.  La **creaci√≥n de los embeddings** y su almacenamiento en ChromaDB.\n",
    "\n",
    "###### Nueva Hip√≥tesis: \"Texto Sucio\" o Divisi√≥n Inesperada\n",
    "\n",
    "Aunque el texto es legible para nosotros, puede que contenga caracteres invisibles o un formato problem√°tico (como saltos de l√≠nea extra√±os o espacios no est√°ndar `¬†`) que confunden al `TextSplitter` o al modelo de `embeddings`.\n",
    "\n",
    "Es como darle a un chef ingredientes que parecen buenos, pero que no est√°n bien limpios. El resultado final (la b√∫squeda) sale mal.\n",
    "\n",
    "###### Nuevo Test: Inspeccionar los \"Chunks\" o Fragmentos Finales\n",
    "\n",
    "Vamos a realizar un nuevo diagn√≥stico para ver exactamente c√≥mo queda el texto *despu√©s* de ser dividido en fragmentos (`chunks`) y justo *antes* de ser enviado a OpenAI para crear los embeddings.\n",
    "\n",
    "**C√≥digo de Diagn√≥stico de Chunks:**\n",
    "\n",
    "Este c√≥digo cargar√° el PDF, lo limpiar√° (como buena pr√°ctica) y luego lo dividir√°, mostr√°ndonos los primeros 5 fragmentos resultantes.\n",
    "\n",
    "```python\n",
    "import os\n",
    "import re\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# --- CONFIGURACI√ìN ---\n",
    "PDF_PATH = \"../../../assets/DG_docs/PDF_test_gradio/73SentenciaTutela.pdf\"\n",
    "\n",
    "# --- 1. FUNCI√ìN DE LIMPIEZA DE TEXTO ---\n",
    "# Esta es una buena pr√°ctica para normalizar el texto antes de procesarlo.\n",
    "def clean_text(text: str) -> str:\n",
    "    # Reemplaza el espacio no separable (un car√°cter com√∫n en PDFs) por un espacio normal\n",
    "    text = text.replace('\\xa0', ' ')\n",
    "    # Reemplaza m√∫ltiples saltos de l√≠nea o espacios por un solo espacio\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return text.strip()\n",
    "\n",
    "# --- 2. CARGA Y LIMPIEZA DE DOCUMENTOS ---\n",
    "print(f\"üìÑ Cargando y limpiando el archivo: {PDF_PATH}\")\n",
    "loader = PyPDFLoader(PDF_PATH)\n",
    "pages = loader.load()\n",
    "\n",
    "# Aplicamos la limpieza a cada p√°gina\n",
    "for doc in pages:\n",
    "    doc.page_content = clean_text(doc.page_content)\n",
    "\n",
    "print(\"‚úÖ Texto limpiado.\")\n",
    "\n",
    "# --- 3. DIVISI√ìN DEL TEXTO ---\n",
    "# Usamos los mismos par√°metros de tu script original\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1500,\n",
    "    chunk_overlap=200,\n",
    "    length_function=len\n",
    ")\n",
    "documents = text_splitter.split_documents(pages)\n",
    "print(f\"‚úÖ Texto dividido en {len(documents)} fragmentos (chunks).\")\n",
    "\n",
    "# --- 4. INSPECCI√ìN DE LOS FRAGMENTOS ---\n",
    "print(\"\\nüîç --- Inspeccionando los primeros 5 fragmentos --- üîç\")\n",
    "for i in range(min(5, len(documents))):\n",
    "    print(f\"\\n--- FRAGMENTO {i+1} ---\\n\")\n",
    "    print(documents[i].page_content)\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "\n",
    "```\n",
    "\n",
    "###### ¬øQu√© Debemos Buscar en el Resultado?\n",
    "\n",
    "Ejecuta este nuevo script y presta atenci√≥n a la salida de los fragmentos:\n",
    "\n",
    "* **¬øSe ve el texto coherente?** ¬øO los fragmentos parecen cortados en lugares extra√±os?\n",
    "* **¬øAparece el n√∫mero de radicaci√≥n `080013187005202500020-00` en alguno de los primeros fragmentos?** Deber√≠a aparecer.\n",
    "* **¬øHay fragmentos muy cortos o casi vac√≠os?** Esto podr√≠a indicar un problema en la divisi√≥n.\n",
    "\n",
    "###### El Siguiente Paso L√≥gico\n",
    "\n",
    "El resultado de este script nos dar√° la respuesta definitiva.\n",
    "\n",
    "* **Si los fragmentos se ven bien y coherentes,** y contienen la informaci√≥n clave, entonces podemos concluir con alta seguridad que el problema est√° en el **almacenamiento o corrupci√≥n de la base de datos ChromaDB**. La soluci√≥n en ese caso ser√≠a simplemente borrar la carpeta `chroma_db` y volver a generar la base de datos desde cero con el texto ya limpio.\n",
    "* **Si los fragmentos se ven mal (cortados, extra√±os),** entonces el problema es el `TextSplitter` y debemos ajustar sus par√°metros (`chunk_size`, `chunk_overlap`, o incluso los separadores).\n",
    "\n",
    "Estoy casi seguro de que una simple limpieza del texto y la regeneraci√≥n de la base de datos resolver√° el fallo. Ejecuta el script de inspecci√≥n y mu√©strame el resultado para dar el paso final."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### ü™õ C√≥digo de Diagn√≥stico de Chunks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# --- CONFIGURACI√ìN ---\n",
    "PDF_PATH = \"../../../assets/DG_docs/PDF_test_gradio/73SentenciaTutela.pdf\"\n",
    "\n",
    "# --- 1. FUNCI√ìN DE LIMPIEZA DE TEXTO ---\n",
    "# Esta es una buena pr√°ctica para normalizar el texto antes de procesarlo.\n",
    "def clean_text(text: str) -> str:\n",
    "    # Reemplaza el espacio no separable (un car√°cter com√∫n en PDFs) por un espacio normal\n",
    "    text = text.replace('\\xa0', ' ')\n",
    "    # Reemplaza m√∫ltiples saltos de l√≠nea o espacios por un solo espacio\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return text.strip()\n",
    "\n",
    "# --- 2. CARGA Y LIMPIEZA DE DOCUMENTOS ---\n",
    "print(f\"üìÑ Cargando y limpiando el archivo: {PDF_PATH}\")\n",
    "loader = PyPDFLoader(PDF_PATH)\n",
    "pages = loader.load()\n",
    "\n",
    "# Aplicamos la limpieza a cada p√°gina\n",
    "for doc in pages:\n",
    "    doc.page_content = clean_text(doc.page_content)\n",
    "\n",
    "print(\"‚úÖ Texto limpiado.\")\n",
    "\n",
    "# --- 3. DIVISI√ìN DEL TEXTO ---\n",
    "# Usamos los mismos par√°metros de tu script original\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1500,\n",
    "    chunk_overlap=200,\n",
    "    length_function=len\n",
    ")\n",
    "documents = text_splitter.split_documents(pages)\n",
    "print(f\"‚úÖ Texto dividido en {len(documents)} fragmentos (chunks).\")\n",
    "\n",
    "# --- 4. INSPECCI√ìN DE LOS FRAGMENTOS ---\n",
    "print(\"\\nüîç --- Inspeccionando los primeros 5 fragmentos --- üîç\")\n",
    "for i in range(min(5, len(documents))):\n",
    "    print(f\"\\n--- FRAGMENTO {i+1} ---\\n\")\n",
    "    print(documents[i].page_content)\n",
    "    print(\"\\n\" + \"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6.3.2.4. El problema reside en la base de datos vectorial (chroma_db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¬°Excelente! Este resultado es exactamente lo que necesit√°bamos. Es el √∫ltimo paso del diagn√≥stico y nos lleva directamente a la causa ra√≠z y a la soluci√≥n final.\n",
    "\n",
    "###### An√°lisis Final del Diagn√≥stico\n",
    "\n",
    "1.  **Carga de PDF:** Confirmado, funciona.\n",
    "2.  **Extracci√≥n de Texto:** Confirmado, el texto es legible y correcto.\n",
    "3.  **Limpieza de Texto:** Confirmado, el texto se normaliza correctamente.\n",
    "4.  **Divisi√≥n en Chunks:** **Confirmado por tu √∫ltimo resultado.** Los fragmentos que me muestras son coherentes, limpios y, lo m√°s importante, **contienen la informaci√≥n que buscamos**. Por ejemplo, el `FRAGMENTO 1` incluye claramente el n√∫mero de Radicaci√≥n.\n",
    "\n",
    "Esto nos deja con una sola conclusi√≥n posible.\n",
    "\n",
    "###### Causa Definitiva del Problema\n",
    "\n",
    "El problema no est√° en c√≥mo cargas, limpias o divides el texto. El problema reside en la **base de datos vectorial (`chroma_db`) que est√°s utilizando**.\n",
    "\n",
    "Lo m√°s probable es que la base de datos que tienes en tu disco se gener√≥ en un intento anterior con el texto \"sucio\" o mal extra√≠do. Aunque hayas corregido el c√≥digo de carga, el `retriever` sigue consultando esa base de datos antigua y corrupta, y por eso nunca encuentra nada.\n",
    "\n",
    "###### La Soluci√≥n Final: Regenerar la Base de Datos\n",
    "\n",
    "La soluci√≥n es simple y directa: debemos **borrar la base de datos antigua y crear una completamente nueva** con el proceso de carga y limpieza que ya hemos validado.\n",
    "\n",
    "A continuaci√≥n, te proporciono el **script completo y definitivo**. Este c√≥digo integra todos los pasos que hemos confirmado que funcionan: la limpieza, la divisi√≥n y la creaci√≥n de la base de datos.\n",
    "\n",
    "**Instrucciones:**\n",
    "\n",
    "1.  **MUY IMPORTANTE:** Ve a la carpeta de tu proyecto y **elimina manualmente la carpeta `chroma_db`**.\n",
    "2.  Ejecuta el siguiente script. Este crear√° una nueva carpeta `chroma_db` poblada con la informaci√≥n limpia y correcta.\n",
    "\n",
    "####### Script Consolidado para Regenerar la Base de Datos\n",
    "\n",
    "```python\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "# --- CONFIGURACI√ìN ---\n",
    "PDF_DIRECTORY = \"../../../assets/DG_docs/PDF_test_gradio/\"\n",
    "PERSIST_DIRECTORY = \"chroma_db\"\n",
    "EMBEDDING_MODEL = \"text-embedding-3-small\"  # Usamos un modelo m√°s moderno y eficiente\n",
    "\n",
    "print(\"--- Iniciando el Proceso Completo de Creaci√≥n de la Base de Datos Vectorial ---\")\n",
    "\n",
    "# 1. Aseg√∫rate de que la clave API est√© configurada\n",
    "api_key_environ = os.environ.get(\"OPENAI_API_KEY\")\n",
    "if not api_key_environ:\n",
    "    raise ValueError(\"La variable de entorno OPENAI_API_KEY no est√° configurada.\")\n",
    "\n",
    "# 2. Eliminar la base de datos antigua si existe (por seguridad)\n",
    "if os.path.exists(PERSIST_DIRECTORY):\n",
    "    print(f\"üóëÔ∏è Eliminando la base de datos antigua en '{PERSIST_DIRECTORY}'...\")\n",
    "    shutil.rmtree(PERSIST_DIRECTORY)\n",
    "    print(\"‚úÖ Base de datos antigua eliminada.\")\n",
    "\n",
    "# 3. Funci√≥n de limpieza de texto\n",
    "def clean_text(text: str) -> str:\n",
    "    text = text.replace('\\xa0', ' ')\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return text.strip()\n",
    "\n",
    "# 4. Cargar y procesar todos los PDFs del directorio\n",
    "all_pages = []\n",
    "pdf_files = [f for f in os.listdir(PDF_DIRECTORY) if f.lower().endswith(\".pdf\")]\n",
    "\n",
    "print(f\"\\nüìÑ Encontrados {len(pdf_files)} archivos PDF para procesar...\")\n",
    "\n",
    "for pdf_file in pdf_files:\n",
    "    pdf_path = os.path.join(PDF_DIRECTORY, pdf_file)\n",
    "    print(f\"  -> Cargando y limpiando '{pdf_file}'...\")\n",
    "    loader = PyPDFLoader(pdf_path)\n",
    "    pages = loader.load()\n",
    "    for doc in pages:\n",
    "        doc.page_content = clean_text(doc.page_content)\n",
    "    all_pages.extend(pages)\n",
    "\n",
    "print(f\"\\n‚úÖ Total de p√°ginas cargadas y limpiadas: {len(all_pages)}\")\n",
    "\n",
    "# 5. Dividir los documentos en chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1500,\n",
    "    chunk_overlap=200,\n",
    "    length_function=len\n",
    ")\n",
    "documents = text_splitter.split_documents(all_pages)\n",
    "print(f\"‚úÖ Texto dividido en {len(documents)} fragmentos (chunks).\")\n",
    "\n",
    "\n",
    "# 6. Crear embeddings y la base de datos vectorial\n",
    "print(f\"\\nüß† Creando embeddings con el modelo '{EMBEDDING_MODEL}' y guardando en ChromaDB...\")\n",
    "print(\"(Esto puede tardar unos minutos y consumir tokens de OpenAI...)\")\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=EMBEDDING_MODEL, openai_api_key=api_key_environ)\n",
    "\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=documents,\n",
    "    embedding=embeddings,\n",
    "    persist_directory=PERSIST_DIRECTORY\n",
    ")\n",
    "\n",
    "print(\"\\nüéâ ¬°√âXITO! Tu nueva base de datos vectorial ha sido creada y guardada correctamente.\")\n",
    "print(f\"Ahora puedes usar el directorio '{PERSIST_DIRECTORY}' para tus consultas.\")\n",
    "\n",
    "```\n",
    "\n",
    "###### Siguientes Pasos\n",
    "\n",
    "Una vez que este script termine de ejecutarse, tu sistema estar√° listo.\n",
    "\n",
    "Vuelve a ejecutar el **primer script de test que te di** (el que ten√≠a los 3 casos de prueba). Ahora, el resultado deber√≠a ser:\n",
    "\n",
    "`‚úÖ √âXITO PARCIAL/TOTAL: Se encontraron uno o m√°s de los contenidos esperados en los fragmentos recuperados.`\n",
    "\n",
    "Cuando eso suceda, habremos solucionado el problema de ra√≠z y podr√°s conectar tu `retriever` al resto de tu aplicaci√≥n con la confianza de que est√° encontrando la informaci√≥n correcta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### ü™õ Script Consolidado para Regenerar la Base de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import shutil\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "# --- CONFIGURACI√ìN ---\n",
    "PDF_DIRECTORY = \"../../../assets/DG_docs/PDF_test_gradio/\"\n",
    "PERSIST_DIRECTORY = \"chroma_db\"\n",
    "EMBEDDING_MODEL = \"text-embedding-3-small\"\n",
    "\n",
    "print(\"--- Iniciando el Proceso Completo de Creaci√≥n de la Base de Datos Vectorial ---\")\n",
    "\n",
    "# 1. Aseg√∫rate de que la clave API est√© configurada\n",
    "api_key_environ = os.environ.get(\"OPENAI_API_KEY\")\n",
    "if not api_key_environ:\n",
    "    raise ValueError(\"La variable de entorno OPENAI_API_KEY no est√° configurada.\")\n",
    "\n",
    "# 2. Eliminar la base de datos antigua si existe\n",
    "if os.path.exists(PERSIST_DIRECTORY):\n",
    "    print(f\"üóëÔ∏è Eliminando la base de datos antigua en '{PERSIST_DIRECTORY}'...\")\n",
    "    shutil.rmtree(PERSIST_DIRECTORY)\n",
    "    print(\"‚úÖ Base de datos antigua eliminada.\")\n",
    "\n",
    "# 3. Funci√≥n de limpieza de texto\n",
    "def clean_text(text: str) -> str:\n",
    "    text = text.replace('\\xa0', ' ')\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return text.strip()\n",
    "\n",
    "# 4. Cargar y procesar todos los PDFs\n",
    "all_pages = []\n",
    "pdf_files = [f for f in os.listdir(PDF_DIRECTORY) if f.lower().endswith(\".pdf\")]\n",
    "print(f\"\\nüìÑ Encontrados {len(pdf_files)} archivos PDF para procesar...\")\n",
    "for pdf_file in pdf_files:\n",
    "    pdf_path = os.path.join(PDF_DIRECTORY, pdf_file)\n",
    "    try:\n",
    "        print(f\"  -> Cargando y limpiando '{pdf_file}'...\")\n",
    "        loader = PyPDFLoader(pdf_path)\n",
    "        pages = loader.load()\n",
    "        for doc in pages:\n",
    "            doc.page_content = clean_text(doc.page_content)\n",
    "            # Filtramos p√°ginas que quedaron vac√≠as despu√©s de limpiar\n",
    "            if doc.page_content:\n",
    "                all_pages.append(doc)\n",
    "    except Exception as e:\n",
    "        print(f\"  ‚ö†Ô∏è Error al procesar el archivo {pdf_file}: {e}. Omitiendo.\")\n",
    "\n",
    "print(f\"\\n‚úÖ Total de p√°ginas cargadas y limpiadas: {len(all_pages)}\")\n",
    "\n",
    "# 5. Dividir los documentos en chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1500,\n",
    "    chunk_overlap=200,\n",
    "    length_function=len\n",
    ")\n",
    "documents = text_splitter.split_documents(all_pages)\n",
    "print(f\"‚úÖ Texto dividido en {len(documents)} fragmentos (chunks).\")\n",
    "\n",
    "\n",
    "# --- 6. (MODIFICADO) Crear embeddings y la base de datos POR LOTES ---\n",
    "print(f\"\\nüß† Creando embeddings con el modelo '{EMBEDDING_MODEL}'...\")\n",
    "embeddings = OpenAIEmbeddings(model=EMBEDDING_MODEL, openai_api_key=api_key_environ)\n",
    "\n",
    "print(f\"‚úÖ Inicializando base de datos vac√≠a en '{PERSIST_DIRECTORY}'...\")\n",
    "# Inicializamos la base de datos vac√≠a\n",
    "vectorstore = Chroma(\n",
    "    persist_directory=PERSIST_DIRECTORY, \n",
    "    embedding_function=embeddings\n",
    ")\n",
    "\n",
    "# Definimos el tama√±o del lote (un n√∫mero seguro para no exceder los l√≠mites)\n",
    "batch_size = 200\n",
    "total_docs = len(documents)\n",
    "print(f\"\\n‚ûï A√±adiendo {total_docs} documentos a la base de datos en lotes de {batch_size}...\")\n",
    "\n",
    "for i in range(0, total_docs, batch_size):\n",
    "    # Obtenemos el lote actual de documentos\n",
    "    batch = documents[i:i + batch_size]\n",
    "    \n",
    "    # Calculamos el n√∫mero de lote actual para mostrar el progreso\n",
    "    batch_number = (i // batch_size) + 1\n",
    "    total_batches = (total_docs + batch_size - 1) // batch_size\n",
    "    \n",
    "    print(f\"  -> Procesando lote {batch_number}/{total_batches} (documentos {i+1} a {min(i + batch_size, total_docs)})...\")\n",
    "    \n",
    "    # A√±adimos el lote a la base de datos. La llamada a la API de OpenAI ocurre aqu√≠.\n",
    "    vectorstore.add_documents(batch)\n",
    "\n",
    "print(\"\\nüéâ ¬°√âXITO! Tu nueva base de datos vectorial ha sido creada y guardada correctamente.\")\n",
    "print(f\"Ahora puedes usar el directorio '{PERSIST_DIRECTORY}' para tus consultas.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6.3.2.5. Objetivo del Test: Evaluar `de nuevo` al Retriever. Tres preguntas del PDF \"73SentenciaTutela.pdf\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Objetivo del Test: Evaluar al `Retriever`\n",
    "\n",
    "El `retriever` es el componente encargado de buscar en tu base de datos vectorial (ChromaDB) los fragmentos de texto m√°s relevantes para la pregunta que haces. Si no le entrega los fragmentos correctos al modelo de lenguaje (LLM), es imposible que el LLM genere una buena respuesta.\n",
    "\n",
    "Vamos a ejecutar el `retriever` de forma aislada para inspeccionar su \"trabajo\".\n",
    "\n",
    "---\n",
    "\n",
    "###### Paso 1: Escoge un Caso de Prueba Espec√≠fico\n",
    "\n",
    "Primero, necesitas un \"caso de oro\" que puedas verificar manualmente.\n",
    "\n",
    "1.  **Busca en tus PDFs:** Abre uno de los documentos PDF que usaste para crear la base de datos. Encuentra un dato muy espec√≠fico y √∫nico. Por ejemplo, el nombre de un proyecto, un n√∫mero de contrato, una fecha clave o una frase t√©cnica.\n",
    "2.  **Define tu \"Golden Pair\":**\n",
    "    * **Pregunta de prueba:** Formula una pregunta que *deber√≠a* encontrar ese dato. Ejemplo: `\"¬øCu√°l es el n√∫mero del contrato para el mantenimiento de la v√≠a Oca√±a-C√∫cuta?\"`\n",
    "    * **Contenido esperado:** Anota la frase o las palabras clave que *obligatoriamente* deben estar en los fragmentos recuperados para poder responder la pregunta. Ejemplo: `\"contrato de obra p√∫blica No. 2345-2023\"`.\n",
    "\n",
    "###### Paso 2: C√≥digo para Ejecutar el Test\n",
    "\n",
    "He preparado una versi√≥n simplificada de tu script que se enfoca **√∫nicamente en realizar este test**. No utilizaremos el LLM para generar respuestas, solo para cargar los embeddings y usar el `retriever`.\n",
    "\n",
    "Copia y ejecuta el siguiente c√≥digo. Aseg√∫rate de modificar las variables de la secci√≥n \"CONFIGURACI√ìN DEL TEST\".\n",
    "\n",
    "```python\n",
    "import os\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "# --- CONFIGURACI√ìN DEL TEST ---\n",
    "# 1. Aseg√∫rate de que tu clave de API est√© configurada como variable de entorno\n",
    "#    os.environ[\"OPENAI_API_KEY\"] = \"tu_clave_aqui\"\n",
    "\n",
    "# 2. Define la pregunta y el contenido que esperas encontrar\n",
    "TEST_QUERY = \"que pasa en Oca√±a?\"  # <--- CAMBIA ESTO por tu pregunta de prueba\n",
    "EXPECTED_KEYWORDS = [\"Oca√±a\", \"emergencia\", \"deslizamiento\"] # <--- CAMBIA ESTO por las palabras clave que deben aparecer\n",
    "\n",
    "# 3. Define la ruta a tu base de datos vectorial\n",
    "PERSIST_DIRECTORY = \"chroma_db\"\n",
    "EMBEDDING_MODEL = \"text-embedding-3-small\" # Usa el mismo modelo con el que creaste la base\n",
    "\n",
    "# --- L√ìGICA DEL TEST ---\n",
    "\n",
    "print(\"üß™ Iniciando el Test de Recuperaci√≥n de Contexto...\")\n",
    "\n",
    "# 1. Validar configuraci√≥n\n",
    "api_key_environ = os.environ.get(\"OPENAI_API_KEY\")\n",
    "if not api_key_environ:\n",
    "    raise ValueError(\"La variable de entorno OPENAI_API_KEY no est√° configurada.\")\n",
    "\n",
    "if not os.path.exists(PERSIST_DIRECTORY):\n",
    "    raise FileNotFoundError(f\"El directorio de la base de datos '{PERSIST_DIRECTORY}' no existe. Aseg√∫rate de haber ejecutado el script principal primero.\")\n",
    "\n",
    "print(f\"Buscando en la base de datos en: '{PERSIST_DIRECTORY}'\")\n",
    "\n",
    "# 2. Cargar el retriever\n",
    "print(f\"Cargando embeddings con el modelo: '{EMBEDDING_MODEL}'...\")\n",
    "embeddings = OpenAIEmbeddings(model=EMBEDDING_MODEL)\n",
    "vectorstore = Chroma(\n",
    "    persist_directory=PERSIST_DIRECTORY,\n",
    "    embedding_function=embeddings\n",
    ")\n",
    "# Aumentamos 'k' para tener m√°s contexto que inspeccionar\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 5})\n",
    "\n",
    "# 3. Ejecutar el retriever de forma aislada\n",
    "print(f\"\\nüîç Ejecutando retriever con la pregunta: '{TEST_QUERY}'\")\n",
    "retrieved_docs = retriever.invoke(TEST_QUERY)\n",
    "\n",
    "# 4. Analizar los resultados\n",
    "print(\"\\nüìÑ --- Fragmentos Recuperados --- üìÑ\")\n",
    "if not retrieved_docs:\n",
    "    print(\"‚ùå ¬°ERROR! El retriever no devolvi√≥ ning√∫n documento.\")\n",
    "else:\n",
    "    for i, doc in enumerate(retrieved_docs):\n",
    "        source = doc.metadata.get(\"source\", \"desconocido\")\n",
    "        content = doc.page_content\n",
    "        print(f\"\\n--- Documento {i+1} (Fuente: {source}) ---\\n\")\n",
    "        print(content)\n",
    "        print(\"-\" * 40)\n",
    "\n",
    "# 5. Verificaci√≥n autom√°tica\n",
    "print(\"\\nüèÅ --- Verificaci√≥n de Palabras Clave --- üèÅ\")\n",
    "found_keywords_count = 0\n",
    "for doc in retrieved_docs:\n",
    "    for keyword in EXPECTED_KEYWORDS:\n",
    "        if keyword.lower() in doc.page_content.lower():\n",
    "            print(f\"‚úÖ Palabra clave encontrada: '{keyword}' en Fuente: {doc.metadata.get('source', 'N/A')}\")\n",
    "            found_keywords_count += 1\n",
    "\n",
    "print(\"\\n--- Veredicto del Test ---\")\n",
    "if found_keywords_count > 0:\n",
    "    print(\"‚úÖ √âXITO PARCIAL/TOTAL: Se encontraron uno o m√°s de los contenidos esperados en los fragmentos recuperados.\")\n",
    "else:\n",
    "    print(\"‚ùå FALLO: Ninguna de las palabras clave esperadas fue encontrada. El contexto relevante no se est√° recuperando.\")\n",
    "\n",
    "```\n",
    "\n",
    "###### ¬øC√≥mo Interpretar los Resultados?\n",
    "\n",
    "1.  **Si el veredicto es \"√âXITO\"**: Significa que tu base de datos y tu `retriever` funcionan correctamente. El problema podr√≠a estar en el `prompt` que le das al LLM o en el propio LLM (aunque es menos probable).\n",
    "2.  **Si el veredicto es \"FALLO\"**: Confirma tu sospecha. El problema est√° en la base de conocimiento. El sistema no es capaz de encontrar los fragmentos de texto relevantes.\n",
    "\n",
    "###### ¬øQu√© Hacer si el Test Falla?\n",
    "\n",
    "Si el test falla, aqu√≠ tienes las causas m√°s probables y c√≥mo solucionarlas:\n",
    "\n",
    "1.  **Problema con la Divisi√≥n de Texto (`chunking`)**:\n",
    "    * **Causa**: El `chunk_size=1500` puede ser muy grande, y la informaci√≥n clave se \"diluye\" con texto irrelevante en el mismo fragmento. O puede ser muy peque√±o y parte una frase importante.\n",
    "    * **Soluci√≥n**: Prueba a regenerar tu base de datos con un `chunk_size` m√°s peque√±o (ej. 1000) y un `chunk_overlap` mayor (ej. 250). Esto crea m√°s fragmentos, pero m√°s enfocados.\n",
    "\n",
    "2.  **Problema con la Extracci√≥n de Texto del PDF**:\n",
    "    * **Causa**: Algunos PDFs son en realidad im√°genes de texto (escaneados). `PyPDFLoader` no puede leer texto de im√°genes.\n",
    "    * **Soluci√≥n**: Verifica el contenido de tus documentos justo despu√©s de cargarlos (la variable `ml_papers` en tu script original). Si ves caracteres extra√±os o texto sin sentido, necesitas usar una herramienta de **OCR (Reconocimiento √ìptico de Caracteres)** para extraer el texto de esos PDFs antes de pasarlos a LangChain.\n",
    "\n",
    "3.  **Problema con el Modelo de Embeddings**:\n",
    "    * **Causa**: `text-embedding-ada-002` es un modelo m√°s antiguo. Puede que no est√© capturando el significado sem√°ntico de tu pregunta con la suficiente precisi√≥n.\n",
    "    * **Soluci√≥n**: Regenera tu base de datos usando un modelo m√°s moderno y potente como `\"text-embedding-3-small\"` (m√°s barato y eficiente) o `\"text-embedding-3-large\"` (m√°xima calidad). Tu propio c√≥digo ya tiene un comentario sugiriendo este cambio.\n",
    "\n",
    "Ejecuta este test y, seg√∫n el resultado, podremos enfocarnos en la soluci√≥n correcta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### üîÅ PREGUNTA 1: ¬øCu√°l es el n√∫mero de radicaci√≥n de la acci√≥n de tutela de Gersel Luis P√©rez Altamiranda?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "# --- CONFIGURACI√ìN DEL TEST ---\n",
    "# 1. Aseg√∫rate de que tu clave de API est√© configurada como variable de entorno\n",
    "#    os.environ[\"OPENAI_API_KEY\"] = \"tu_clave_aqui\"\n",
    "\n",
    "# 2. Define la pregunta y el contenido que esperas encontrar\n",
    "TEST_QUERY = \"¬øCu√°l es el n√∫mero de radicaci√≥n de la acci√≥n de tutela de Gersel Luis P√©rez Altamiranda?\"  # <--- CAMBIA ESTO por tu pregunta de prueba\n",
    "EXPECTED_KEYWORDS = [\"080013187005202500020-00\"] # <--- CAMBIA ESTO por las palabras clave que deben aparecer\n",
    "\n",
    "# 3. Define la ruta a tu base de datos vectorial\n",
    "PERSIST_DIRECTORY = \"chroma_db\"\n",
    "EMBEDDING_MODEL = \"text-embedding-3-small\" # Usa el mismo modelo con el que creaste la base\n",
    "\n",
    "# --- L√ìGICA DEL TEST ---\n",
    "\n",
    "print(\"üß™ Iniciando el Test de Recuperaci√≥n de Contexto...\")\n",
    "\n",
    "# 1. Validar configuraci√≥n\n",
    "api_key_environ = os.environ.get(\"OPENAI_API_KEY\")\n",
    "if not api_key_environ:\n",
    "    raise ValueError(\"La variable de entorno OPENAI_API_KEY no est√° configurada.\")\n",
    "\n",
    "if not os.path.exists(PERSIST_DIRECTORY):\n",
    "    raise FileNotFoundError(f\"El directorio de la base de datos '{PERSIST_DIRECTORY}' no existe. Aseg√∫rate de haber ejecutado el script principal primero.\")\n",
    "\n",
    "print(f\"Buscando en la base de datos en: '{PERSIST_DIRECTORY}'\")\n",
    "\n",
    "# 2. Cargar el retriever\n",
    "print(f\"Cargando embeddings con el modelo: '{EMBEDDING_MODEL}'...\")\n",
    "embeddings = OpenAIEmbeddings(model=EMBEDDING_MODEL)\n",
    "vectorstore = Chroma(\n",
    "    persist_directory=PERSIST_DIRECTORY,\n",
    "    embedding_function=embeddings\n",
    ")\n",
    "# Aumentamos 'k' para tener m√°s contexto que inspeccionar\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 5})\n",
    "\n",
    "# 3. Ejecutar el retriever de forma aislada\n",
    "print(f\"\\nüîç Ejecutando retriever con la pregunta: '{TEST_QUERY}'\")\n",
    "retrieved_docs = retriever.invoke(TEST_QUERY)\n",
    "\n",
    "# 4. Analizar los resultados\n",
    "print(\"\\nüìÑ --- Fragmentos Recuperados --- üìÑ\")\n",
    "if not retrieved_docs:\n",
    "    print(\"‚ùå ¬°ERROR! El retriever no devolvi√≥ ning√∫n documento.\")\n",
    "else:\n",
    "    for i, doc in enumerate(retrieved_docs):\n",
    "        source = doc.metadata.get(\"source\", \"desconocido\")\n",
    "        content = doc.page_content\n",
    "        print(f\"\\n--- Documento {i+1} (Fuente: {source}) ---\\n\")\n",
    "        print(content)\n",
    "        print(\"-\" * 40)\n",
    "\n",
    "# 5. Verificaci√≥n autom√°tica\n",
    "print(\"\\nüèÅ --- Verificaci√≥n de Palabras Clave --- üèÅ\")\n",
    "found_keywords_count = 0\n",
    "for doc in retrieved_docs:\n",
    "    for keyword in EXPECTED_KEYWORDS:\n",
    "        if keyword.lower() in doc.page_content.lower():\n",
    "            print(f\"‚úÖ Palabra clave encontrada: '{keyword}' en Fuente: {doc.metadata.get('source', 'N/A')}\")\n",
    "            found_keywords_count += 1\n",
    "\n",
    "print(\"\\n--- Veredicto del Test ---\")\n",
    "if found_keywords_count > 0:\n",
    "    print(\"‚úÖ √âXITO PARCIAL/TOTAL: Se encontraron uno o m√°s de los contenidos esperados en los fragmentos recuperados.\")\n",
    "else:\n",
    "    print(\"‚ùå FALLO: Ninguna de las palabras clave esperadas fue encontrada. El contexto relevante no se est√° recuperando.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### üîÅ PREGUNTA 2: ¬øQu√© resoluci√≥n distribuye el cobro de la Contribuci√≥n Nacional de Valorizaci√≥n para el proyecto Circunvalar de la Prosperidad?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "# --- CONFIGURACI√ìN DEL TEST ---\n",
    "# 1. Aseg√∫rate de que tu clave de API est√© configurada como variable de entorno\n",
    "#    os.environ[\"OPENAI_API_KEY\"] = \"tu_clave_aqui\"\n",
    "\n",
    "# 2. Define la pregunta y el contenido que esperas encontrar\n",
    "TEST_QUERY = \"¬øQu√© resoluci√≥n distribuye el cobro de la Contribuci√≥n Nacional de Valorizaci√≥n para el proyecto Circunvalar de la Prosperidad?\"  # <--- CAMBIA ESTO por tu pregunta de prueba\n",
    "EXPECTED_KEYWORDS = [\"Resoluci√≥n No. 3856\", \"distribuye el cobro\"] # <--- CAMBIA ESTO por las palabras clave que deben aparecer\n",
    "\n",
    "# 3. Define la ruta a tu base de datos vectorial\n",
    "PERSIST_DIRECTORY = \"chroma_db\"\n",
    "EMBEDDING_MODEL = \"text-embedding-3-small\" # Usa el mismo modelo con el que creaste la base\n",
    "\n",
    "# --- L√ìGICA DEL TEST ---\n",
    "\n",
    "print(\"üß™ Iniciando el Test de Recuperaci√≥n de Contexto...\")\n",
    "\n",
    "# 1. Validar configuraci√≥n\n",
    "api_key_environ = os.environ.get(\"OPENAI_API_KEY\")\n",
    "if not api_key_environ:\n",
    "    raise ValueError(\"La variable de entorno OPENAI_API_KEY no est√° configurada.\")\n",
    "\n",
    "if not os.path.exists(PERSIST_DIRECTORY):\n",
    "    raise FileNotFoundError(f\"El directorio de la base de datos '{PERSIST_DIRECTORY}' no existe. Aseg√∫rate de haber ejecutado el script principal primero.\")\n",
    "\n",
    "print(f\"Buscando en la base de datos en: '{PERSIST_DIRECTORY}'\")\n",
    "\n",
    "# 2. Cargar el retriever\n",
    "print(f\"Cargando embeddings con el modelo: '{EMBEDDING_MODEL}'...\")\n",
    "embeddings = OpenAIEmbeddings(model=EMBEDDING_MODEL)\n",
    "vectorstore = Chroma(\n",
    "    persist_directory=PERSIST_DIRECTORY,\n",
    "    embedding_function=embeddings\n",
    ")\n",
    "# Aumentamos 'k' para tener m√°s contexto que inspeccionar\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 5})\n",
    "\n",
    "# 3. Ejecutar el retriever de forma aislada\n",
    "print(f\"\\nüîç Ejecutando retriever con la pregunta: '{TEST_QUERY}'\")\n",
    "retrieved_docs = retriever.invoke(TEST_QUERY)\n",
    "\n",
    "# 4. Analizar los resultados\n",
    "print(\"\\nüìÑ --- Fragmentos Recuperados --- üìÑ\")\n",
    "if not retrieved_docs:\n",
    "    print(\"‚ùå ¬°ERROR! El retriever no devolvi√≥ ning√∫n documento.\")\n",
    "else:\n",
    "    for i, doc in enumerate(retrieved_docs):\n",
    "        source = doc.metadata.get(\"source\", \"desconocido\")\n",
    "        content = doc.page_content\n",
    "        print(f\"\\n--- Documento {i+1} (Fuente: {source}) ---\\n\")\n",
    "        print(content)\n",
    "        print(\"-\" * 40)\n",
    "\n",
    "# 5. Verificaci√≥n autom√°tica\n",
    "print(\"\\nüèÅ --- Verificaci√≥n de Palabras Clave --- üèÅ\")\n",
    "found_keywords_count = 0\n",
    "for doc in retrieved_docs:\n",
    "    for keyword in EXPECTED_KEYWORDS:\n",
    "        if keyword.lower() in doc.page_content.lower():\n",
    "            print(f\"‚úÖ Palabra clave encontrada: '{keyword}' en Fuente: {doc.metadata.get('source', 'N/A')}\")\n",
    "            found_keywords_count += 1\n",
    "\n",
    "print(\"\\n--- Veredicto del Test ---\")\n",
    "if found_keywords_count > 0:\n",
    "    print(\"‚úÖ √âXITO PARCIAL/TOTAL: Se encontraron uno o m√°s de los contenidos esperados en los fragmentos recuperados.\")\n",
    "else:\n",
    "    print(\"‚ùå FALLO: Ninguna de las palabras clave esperadas fue encontrada. El contexto relevante no se est√° recuperando.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### üîÅ PREGUNTA 3: ¬øBajo qu√© condici√≥n est√°n excluidas del cobro de valorizaci√≥n las tierras de grupos √©tnicos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "# --- CONFIGURACI√ìN DEL TEST ---\n",
    "# 1. Aseg√∫rate de que tu clave de API est√© configurada como variable de entorno\n",
    "#    os.environ[\"OPENAI_API_KEY\"] = \"tu_clave_aqui\"\n",
    "\n",
    "# 2. Define la pregunta y el contenido que esperas encontrar\n",
    "TEST_QUERY = \"¬øBajo qu√© condici√≥n est√°n excluidas del cobro de valorizaci√≥n las tierras de grupos √©tnicos?\"  # <--- CAMBIA ESTO por tu pregunta de prueba\n",
    "EXPECTED_KEYWORDS = [\"excluidos\", \"tierras comunales\", \"grupos √©tnicos\", \"titularidad radique en una entidad de derecho p√∫blico\"] # <--- CAMBIA ESTO por las palabras clave que deben aparecer\n",
    "\n",
    "# 3. Define la ruta a tu base de datos vectorial\n",
    "PERSIST_DIRECTORY = \"chroma_db\"\n",
    "EMBEDDING_MODEL = \"text-embedding-3-small\" # Usa el mismo modelo con el que creaste la base\n",
    "\n",
    "# --- L√ìGICA DEL TEST ---\n",
    "\n",
    "print(\"üß™ Iniciando el Test de Recuperaci√≥n de Contexto...\")\n",
    "\n",
    "# 1. Validar configuraci√≥n\n",
    "api_key_environ = os.environ.get(\"OPENAI_API_KEY\")\n",
    "if not api_key_environ:\n",
    "    raise ValueError(\"La variable de entorno OPENAI_API_KEY no est√° configurada.\")\n",
    "\n",
    "if not os.path.exists(PERSIST_DIRECTORY):\n",
    "    raise FileNotFoundError(f\"El directorio de la base de datos '{PERSIST_DIRECTORY}' no existe. Aseg√∫rate de haber ejecutado el script principal primero.\")\n",
    "\n",
    "print(f\"Buscando en la base de datos en: '{PERSIST_DIRECTORY}'\")\n",
    "\n",
    "# 2. Cargar el retriever\n",
    "print(f\"Cargando embeddings con el modelo: '{EMBEDDING_MODEL}'...\")\n",
    "embeddings = OpenAIEmbeddings(model=EMBEDDING_MODEL)\n",
    "vectorstore = Chroma(\n",
    "    persist_directory=PERSIST_DIRECTORY,\n",
    "    embedding_function=embeddings\n",
    ")\n",
    "# Aumentamos 'k' para tener m√°s contexto que inspeccionar\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 5})\n",
    "\n",
    "# 3. Ejecutar el retriever de forma aislada\n",
    "print(f\"\\nüîç Ejecutando retriever con la pregunta: '{TEST_QUERY}'\")\n",
    "retrieved_docs = retriever.invoke(TEST_QUERY)\n",
    "\n",
    "# 4. Analizar los resultados\n",
    "print(\"\\nüìÑ --- Fragmentos Recuperados --- üìÑ\")\n",
    "if not retrieved_docs:\n",
    "    print(\"‚ùå ¬°ERROR! El retriever no devolvi√≥ ning√∫n documento.\")\n",
    "else:\n",
    "    for i, doc in enumerate(retrieved_docs):\n",
    "        source = doc.metadata.get(\"source\", \"desconocido\")\n",
    "        content = doc.page_content\n",
    "        print(f\"\\n--- Documento {i+1} (Fuente: {source}) ---\\n\")\n",
    "        print(content)\n",
    "        print(\"-\" * 40)\n",
    "\n",
    "# 5. Verificaci√≥n autom√°tica\n",
    "print(\"\\nüèÅ --- Verificaci√≥n de Palabras Clave --- üèÅ\")\n",
    "found_keywords_count = 0\n",
    "for doc in retrieved_docs:\n",
    "    for keyword in EXPECTED_KEYWORDS:\n",
    "        if keyword.lower() in doc.page_content.lower():\n",
    "            print(f\"‚úÖ Palabra clave encontrada: '{keyword}' en Fuente: {doc.metadata.get('source', 'N/A')}\")\n",
    "            found_keywords_count += 1\n",
    "\n",
    "print(\"\\n--- Veredicto del Test ---\")\n",
    "if found_keywords_count > 0:\n",
    "    print(\"‚úÖ √âXITO PARCIAL/TOTAL: Se encontraron uno o m√°s de los contenidos esperados en los fragmentos recuperados.\")\n",
    "else:\n",
    "    print(\"‚ùå FALLO: Ninguna de las palabras clave esperadas fue encontrada. El contexto relevante no se est√° recuperando.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6.3.2.6. Objetivo del Test 2: Evaluar `de nuevo` al Retriever. Tres preguntas del PDF \"2024S-VBOG-059529.pdf\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### üîÅ PREGUNTA 1: \n",
    "- Pregunta de Prueba (TEST_QUERY): ¬øCu√°l es el valor actualizado del contrato de obra 0987 de 2021?\n",
    "\n",
    "- Contenido Esperado (EXPECTED_KEYWORDS): [\"0987 DE 2021\", \"Valor actualizado\", \"324,627,245,375.00\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Iniciando el Test de Recuperaci√≥n de Contexto...\n",
      "Buscando en la base de datos en: 'chroma_db'\n",
      "Cargando embeddings con el modelo: 'text-embedding-3-small'...\n",
      "\n",
      "üîç Ejecutando retriever con la pregunta: '¬øCu√°l es el valor actualizado del contrato de obra 0987 de 2021?'\n",
      "\n",
      "üìÑ --- Fragmentos Recuperados --- üìÑ\n",
      "\n",
      "--- Documento 1 (Fuente: ../../../assets/DG_docs/PDF_test_gradio/2024S-VBOG-082247.pdf) ---\n",
      "\n",
      "CONTRATO 964 DE 2021 VIGENCIA VALOR 2023 $27.072.000.000 2024 $54.144.000.000 2025 $ 63.168.000.000 2026 $ 72.192.000.000 2027 $ 67.680.000.000 2028 $ 63.168.000.000 2029 $ 54.144.000.000 2030 $ 94.752.000.000 Total $ 541.389.953.817 CONTRATO 1111 DE 2021 VIGENCIA VALOR 2021 $30.402.106.819 2022 $20.379.255.249 2023 $29.328.000.000 2024 $61.056.000.000 2025 $ 71.232.000.000 2026 $81.408.000.000 2027 $ 76.320.000.000 2028 $ 71.232.000.000 2029 $ 61.656.000.000 2030 $ 107.448.000.000 Total $ 610.461.362.068 De igual forma, se relacionan las modificaciones adelantadas en el marco de los contratos 964 de 2021 y 1111 de 2021: MODIFICACIONES CONTRACTUALES CONTRATO DE OBRA NO. 964 DE 2021 DOCUMENTO FECHA CONSIDERACIONES Modificaci√≥n al Contrato de Obra No.1 02/12/2021 Modificar la Cl√°usula Octava: Plazo del contrato principal n√∫mero 964 del 2021, en el sentido ampliar el plazo de la etapa de preconstrucci√≥n previsto en el numeral 4.1 del Anexo T√©cnico del Proceso de Selecci√≥n No. LP-DT-062-2020. Modificaci√≥n al Contrato de Obra No.2 08/09/2022 Modificar el Par√°grafo primero de la Cl√°usula Novena, en el sentido de modificar la informaci√≥n bancaria. Modificaci√≥n al Contrato de Obra No.3 04/10/2022 Modificar la Cl√°usula S√©ptima del contrato: Apropiaci√≥n Presupuestal. _____________________________________________________________________________________________________ INSTITUTO NACIONAL DE V√çAS P√°gina 4 | 6 Direcci√≥n: Calle 25G # 73B - 90, Bogot√° D.C., Colombia PBX: (+57) 601 377 0600\n",
      "----------------------------------------\n",
      "\n",
      "--- Documento 2 (Fuente: ../../../assets/DG_docs/PDF_test_gradio/2025S-VBOG-011288 -  Proposici√≥n 127-24.pdf) ---\n",
      "\n",
      "CONTRATO NO. FECHA PLAZO VALOR CONTRATO + IVA VALOR ACUMULADO 1179 de 2018 1/11/2018 14 meses $ 12.719.861.029,00 $ 12.719.861.029,00 Adicional 1 y Modificaci√≥n 1 1/01/2020 3 meses $ 352.518.939,00 $ 12.367.342.090,00 Modificaci√≥n 2 29/02/2020 $ 12.367.342.090,00 LOCALIZACI√ìN Y LONGITUD DE LA META F√çSICA EJECUTADA: ÔÇ∑ Ruta 45CS04: Mantenimiento y refuerzo del PR 0+000 al PR 3+500 longitud total: 3,5 Km. ÔÇ∑ Ruta 45CS04: Mantenimiento rutinario del PR 0+000 al PR 4+000 longitud total: 4,0 Km. ÔÇ∑ Ruta 7006: Mantenimiento y refuerzo PR 1+970 a PR 2+640, longitud 1,54 Km. ÔÇ∑ Ruta 7006: Rehabilitaci√≥n PR 2+640 a PR 3+430, longitud 0,79 Km. ÔÇ∑ Ruta 7006: Mantenimiento y refuerzo PR 3+430 al PR 4+974, longitud 1,54 Km. ÔÇ∑ Ruta 7006: Mejoramiento PR 5+000 a PR 7+530, longitud 2,53 Km. ÔÇ∑ Ruta 7006: Mantenimiento y refuerzo PR 11+400 a PR 12+850, longitud 1,45 Km. ÔÇ∑ Ruta 7006: Mantenimiento rutinario del PR 01+000 a PR 13+500, longitud 12,5 Km. VALOR TOTAL EJECUTADO DEL CONTRATO DE OBRA: ÔÇ∑ Valor b√°sico ejecutado del contrato: $11.807.382.250,80. ÔÇ∑ Valor IVA: $159.576.962,71. ÔÇ∑ Valor total ejecutado del contrato: $11.966.959.213,51. A continuaci√≥n, se presenta el resumen financiero del contrato de obra: ACTA DE OBRA NO. MES VALOR B√ÅSICO AJUSTES DEFINIT. VALOR IVA VALOR TOTAL 1 nov-18 $ 5.932.290,00 $ 0,00 $ 42.695,00 $ 5.974.985,00 2 dic-18 $ 51.715.486,00 $ 235.958,00 $ 2.058.700,00 $ 54.010.144,00 3 ene-19 $ 280.483.152,00 $ 1.372.885,00 $ 17.813.197,00 $ 299.669.234,00 4 feb-19 $\n",
      "----------------------------------------\n",
      "\n",
      "--- Documento 3 (Fuente: ../../../assets/DG_docs/PDF_test_gradio/2024S-VBOG-030188  - proposici√≥n 46.pdf) ---\n",
      "\n",
      "Plazo inicial Hasta 31/07/2022 Pr√≥rroga 1 Hasta 31/12/2022 Pr√≥rroga 2 Hasta 31/01/2023 Pr√≥rroga 3 Hasta 31/07/2023 Pr√≥rroga 4 Hasta 30/11/2023 Pr√≥rroga 5 Hasta 31/12/2023 Pr√≥rroga 6 Hasta 30/04/2024 Pr√≥rroga 7 Hasta 30/09/2024 ÔÇ∑ RUTA DE LOS LIBERTADORES A la fecha no se han tenido actas de suspensi√≥n para el Contrato de obra 978 de 2021. ÔÇ∑ CORREDOR DE LA SOBERANIA El contrato de obra N¬∞988 de 2021 no ha tenido suspensiones en el desarrollo del plazo contractual. ÔÇ∑ CORREDOR DUITAMA ‚Äì CHARALA ‚Äì SAN GIL A la fecha no se han tenido actas de suspensi√≥n para el Contrato de este corredor. ÔÇ∑ VADO HONDO ‚Äì LABRANZAGRANDE A la fecha no se han tenido actas de suspensi√≥n para el Contrato de este corredor. 8. Teniendo como base los valores iniciales de los contratos de obra, s√≠rvase discriminar por cada uno: En cu√°nto vari√≥ el valor del proyecto y a que se debi√≥ dicha variaci√≥n. En caso de presentarse incrementos en los contratos de obra ¬øse tienen identificadas las nuevas fuentes de financiaci√≥n? Respuesta: ÔÇ∑ TRANSVERSAL DE BOYAC√Å El contrato de obra N¬∞973 de 2021 a la fecha ha tenido 2 adiciones de recursos como se evidencia en el siguiente cuadro: DESCRIPCI√ìN VALOR FUENTE FINANCIACI√ìN Valor inicial: $358.871.764.334 M/CTE, incluido IVA Adici√≥n N¬∞1 $28.823.323.054 M/CTE, incluido IVA Naci√≥n Adici√≥n N¬∞2 $19.272.000.000 M/CTE incluido IVA Propios Valor acumulado del contrato: $ 406.967.087.388 M/CTE incluido IVA\n",
      "----------------------------------------\n",
      "\n",
      "--- Documento 4 (Fuente: ../../../assets/DG_docs/PDF_test_gradio/2025S-VBOG-033748-Proposicion 25.pdf) ---\n",
      "\n",
      "del corredor y la seguridad de los usuarios de la v√≠a. De acuerdo con lo establecido en el contrato el valor inicial de la vigencia en el 2021 es de $2.449.482.208, valor que era insuficiente para atender los sitios cr√≠ticos como lo eran el restablecimiento del paso en el puente Bojab√° y atenci√≥n de los sitios cr√≠ticos del PR 105, PR 85, PR 30+200 y atenci√≥n del Puente Zambrano 34+000 No. 3 del 31/08/2022 Adicionar el valor del contrato en la suma de $5.000.000.000 2.1. Teniendo en cuenta lo establecido en el contrato 988-2021 el cual en su clausula CL√ÅUSULA D√âCIMA PRIMERA: OBLIGACIONES GENERALES DEL CONTRATISTA. Informa: ‚ÄúAdem√°s de las derivadas de la esencia y naturaleza del presente Contrato, la ley, las obligaciones y condiciones se√±aladas en el Pliego de Condiciones y dem√°s Documentos del Proceso de Selecci√≥n, durante la ejecuci√≥n del contrato, EL CONTRATISTA se obliga a: 1. Cumplir con las condiciones establecidas en los Documentos De acuerdo con las actividades de ejecuci√≥n de obra programadas para el a√±o 2022, la atenci√≥n de las emergencias presentadas en dentro de la ejecuci√≥n del contrato y estabilizaci√≥n de taludes entre el PR8+200 y el PR11+200, tramo priorizado por el INV√çAS para trabajos de\n",
      "----------------------------------------\n",
      "\n",
      "--- Documento 5 (Fuente: ../../../assets/DG_docs/PDF_test_gradio/2024S-VBOG-082247.pdf) ---\n",
      "\n",
      "MODIFICACIONES CONTRACTUALES CONTRATO DE OBRA NO.1111 DE 2021 DOCUMENTO FECHA CONSIDERACIONES Modificaci√≥n al Contrato de Obra No.1 02/11/2021 MODIFICAR la Cl√°usula Octava: Plazo del Contrato Principal N√∫mero 1111 del 2021, en el sentido de incluir PAR√ÅGRAFO PRIMERO fijando como fecha m√°xima para la entrega de las actividades contenidas en el numeral 4.1. Etapa de preconstrucci√≥n del anexo t√©cnico, el d√≠a 02 de diciembre de 2021. Modificaci√≥n al Contrato de Obra No.2 08/09/2022 MODIFICAR el Par√°grafo Primero de la Cl√°usula Novena, en el sentido de modificar la informaci√≥n bancaria. Modificaci√≥n al Contrato de Obra No.3 18/11/2022 Modificar la Cl√°usula S√©ptima del Contrato: Apropiaci√≥n Presupuestal. Modificaci√≥n al Contrato de Obra No.4 28/11/2023 MODIFICAR el Par√°grafo Segundo de la Cl√°usula Tercera, en el sentido de trasladar la suma de MIL DOSCIENTOS MILLONES DE PESOS M/CTE ($ 1.200.000.000 M/CTE) IVA INCLUIDO. de la vigencia 2023 a las vigencias 2029 y 2030 Aclaraci√≥n No.1 a la modificaci√≥n No.4 05/12/2023 ACLARAR la CL√ÅUSULA PRIMERA del Modificatorio No 4: - MODIFICAR el Par√°grafo Segundo de la Cl√°usula Tercera del Contrato de obra n√∫mero 1111 de 2021, en el sentido de trasladar la suma de MIL DOSCIENTOS MILLONES DE PESOS M/CTE ($ 1.200.000.000 M/CTE) IVA INCLUIDO. de la vigencia 2023 a las vigencias 2029 y 2030 Es importante precisar que las distintas modificaciones realizadas en los contratos N¬∞1111 de 2021 y N¬∞964 de 2021, no han afectado ni el valor total asignado a\n",
      "----------------------------------------\n",
      "\n",
      "üèÅ --- Verificaci√≥n de Palabras Clave --- üèÅ\n",
      "\n",
      "--- Veredicto del Test ---\n",
      "‚ùå FALLO: Ninguna de las palabras clave esperadas fue encontrada. El contexto relevante no se est√° recuperando.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created dataset file at: .gradio\\flagged\\dataset1.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "# --- CONFIGURACI√ìN DEL TEST ---\n",
    "# 1. Aseg√∫rate de que tu clave de API est√© configurada como variable de entorno\n",
    "#    os.environ[\"OPENAI_API_KEY\"] = \"tu_clave_aqui\"\n",
    "\n",
    "# 2. Define la pregunta y el contenido que esperas encontrar\n",
    "TEST_QUERY = \"¬øCu√°l es el valor actualizado del contrato de obra 0987 de 2021?\"  # <--- CAMBIA ESTO por tu pregunta de prueba\n",
    "EXPECTED_KEYWORDS = [\"0987 DE 2021\", \"Valor actualizado\", \"324,627,245,375.00\"] # <--- CAMBIA ESTO por las palabras clave que deben aparecer\n",
    "\n",
    "# 3. Define la ruta a tu base de datos vectorial\n",
    "PERSIST_DIRECTORY = \"chroma_db\"\n",
    "EMBEDDING_MODEL = \"text-embedding-3-small\" # Usa el mismo modelo con el que creaste la base\n",
    "\n",
    "# --- L√ìGICA DEL TEST ---\n",
    "\n",
    "print(\"üß™ Iniciando el Test de Recuperaci√≥n de Contexto...\")\n",
    "\n",
    "# 1. Validar configuraci√≥n\n",
    "api_key_environ = os.environ.get(\"OPENAI_API_KEY\")\n",
    "if not api_key_environ:\n",
    "    raise ValueError(\"La variable de entorno OPENAI_API_KEY no est√° configurada.\")\n",
    "\n",
    "if not os.path.exists(PERSIST_DIRECTORY):\n",
    "    raise FileNotFoundError(f\"El directorio de la base de datos '{PERSIST_DIRECTORY}' no existe. Aseg√∫rate de haber ejecutado el script principal primero.\")\n",
    "\n",
    "print(f\"Buscando en la base de datos en: '{PERSIST_DIRECTORY}'\")\n",
    "\n",
    "# 2. Cargar el retriever\n",
    "print(f\"Cargando embeddings con el modelo: '{EMBEDDING_MODEL}'...\")\n",
    "embeddings = OpenAIEmbeddings(model=EMBEDDING_MODEL)\n",
    "vectorstore = Chroma(\n",
    "    persist_directory=PERSIST_DIRECTORY,\n",
    "    embedding_function=embeddings\n",
    ")\n",
    "# Aumentamos 'k' para tener m√°s contexto que inspeccionar\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 5})\n",
    "\n",
    "# 3. Ejecutar el retriever de forma aislada\n",
    "print(f\"\\nüîç Ejecutando retriever con la pregunta: '{TEST_QUERY}'\")\n",
    "retrieved_docs = retriever.invoke(TEST_QUERY)\n",
    "\n",
    "# 4. Analizar los resultados\n",
    "print(\"\\nüìÑ --- Fragmentos Recuperados --- üìÑ\")\n",
    "if not retrieved_docs:\n",
    "    print(\"‚ùå ¬°ERROR! El retriever no devolvi√≥ ning√∫n documento.\")\n",
    "else:\n",
    "    for i, doc in enumerate(retrieved_docs):\n",
    "        source = doc.metadata.get(\"source\", \"desconocido\")\n",
    "        content = doc.page_content\n",
    "        print(f\"\\n--- Documento {i+1} (Fuente: {source}) ---\\n\")\n",
    "        print(content)\n",
    "        print(\"-\" * 40)\n",
    "\n",
    "# 5. Verificaci√≥n autom√°tica\n",
    "print(\"\\nüèÅ --- Verificaci√≥n de Palabras Clave --- üèÅ\")\n",
    "found_keywords_count = 0\n",
    "for doc in retrieved_docs:\n",
    "    for keyword in EXPECTED_KEYWORDS:\n",
    "        if keyword.lower() in doc.page_content.lower():\n",
    "            print(f\"‚úÖ Palabra clave encontrada: '{keyword}' en Fuente: {doc.metadata.get('source', 'N/A')}\")\n",
    "            found_keywords_count += 1\n",
    "\n",
    "print(\"\\n--- Veredicto del Test ---\")\n",
    "if found_keywords_count > 0:\n",
    "    print(\"‚úÖ √âXITO PARCIAL/TOTAL: Se encontraron uno o m√°s de los contenidos esperados en los fragmentos recuperados.\")\n",
    "else:\n",
    "    print(\"‚ùå FALLO: Ninguna de las palabras clave esperadas fue encontrada. El contexto relevante no se est√° recuperando.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### üîÅ PREGUNTA 2: \n",
    "\n",
    "- Pregunta de Prueba (Test Query): ¬øQu√© inversi√≥n ha realizado INV√çAS para cumplir la acci√≥n popular en el corredor Curos-M√°laga?\n",
    "\n",
    "- Contenido Esperado (Expected Keywords): [\"acci√≥n popular\", \"68001-23-33-000-2015-00847\", \"invierte\", \"316.664.639.074\", \"contrato de obra No. 1042 de 2021\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "# --- CONFIGURACI√ìN DEL TEST ---\n",
    "# 1. Aseg√∫rate de que tu clave de API est√© configurada como variable de entorno\n",
    "#    os.environ[\"OPENAI_API_KEY\"] = \"tu_clave_aqui\"\n",
    "\n",
    "# 2. Define la pregunta y el contenido que esperas encontrar\n",
    "TEST_QUERY = \"¬øQu√© inversi√≥n ha realizado INV√çAS para cumplir la acci√≥n popular en el corredor Curos-M√°laga?\"  # <--- CAMBIA ESTO por tu pregunta de prueba\n",
    "EXPECTED_KEYWORDS = [\"acci√≥n popular\", \"68001-23-33-000-2015-00847\", \"invierte\", \"316.664.639.074\", \"contrato de obra No. 1042 de 2021\"] # <--- CAMBIA ESTO por las palabras clave que deben aparecer\n",
    "\n",
    "# 3. Define la ruta a tu base de datos vectorial\n",
    "PERSIST_DIRECTORY = \"chroma_db\"\n",
    "EMBEDDING_MODEL = \"text-embedding-3-small\" # Usa el mismo modelo con el que creaste la base\n",
    "\n",
    "# --- L√ìGICA DEL TEST ---\n",
    "\n",
    "print(\"üß™ Iniciando el Test de Recuperaci√≥n de Contexto...\")\n",
    "\n",
    "# 1. Validar configuraci√≥n\n",
    "api_key_environ = os.environ.get(\"OPENAI_API_KEY\")\n",
    "if not api_key_environ:\n",
    "    raise ValueError(\"La variable de entorno OPENAI_API_KEY no est√° configurada.\")\n",
    "\n",
    "if not os.path.exists(PERSIST_DIRECTORY):\n",
    "    raise FileNotFoundError(f\"El directorio de la base de datos '{PERSIST_DIRECTORY}' no existe. Aseg√∫rate de haber ejecutado el script principal primero.\")\n",
    "\n",
    "print(f\"Buscando en la base de datos en: '{PERSIST_DIRECTORY}'\")\n",
    "\n",
    "# 2. Cargar el retriever\n",
    "print(f\"Cargando embeddings con el modelo: '{EMBEDDING_MODEL}'...\")\n",
    "embeddings = OpenAIEmbeddings(model=EMBEDDING_MODEL)\n",
    "vectorstore = Chroma(\n",
    "    persist_directory=PERSIST_DIRECTORY,\n",
    "    embedding_function=embeddings\n",
    ")\n",
    "# Aumentamos 'k' para tener m√°s contexto que inspeccionar\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 5})\n",
    "\n",
    "# 3. Ejecutar el retriever de forma aislada\n",
    "print(f\"\\nüîç Ejecutando retriever con la pregunta: '{TEST_QUERY}'\")\n",
    "retrieved_docs = retriever.invoke(TEST_QUERY)\n",
    "\n",
    "# 4. Analizar los resultados\n",
    "print(\"\\nüìÑ --- Fragmentos Recuperados --- üìÑ\")\n",
    "if not retrieved_docs:\n",
    "    print(\"‚ùå ¬°ERROR! El retriever no devolvi√≥ ning√∫n documento.\")\n",
    "else:\n",
    "    for i, doc in enumerate(retrieved_docs):\n",
    "        source = doc.metadata.get(\"source\", \"desconocido\")\n",
    "        content = doc.page_content\n",
    "        print(f\"\\n--- Documento {i+1} (Fuente: {source}) ---\\n\")\n",
    "        print(content)\n",
    "        print(\"-\" * 40)\n",
    "\n",
    "# 5. Verificaci√≥n autom√°tica\n",
    "print(\"\\nüèÅ --- Verificaci√≥n de Palabras Clave --- üèÅ\")\n",
    "found_keywords_count = 0\n",
    "for doc in retrieved_docs:\n",
    "    for keyword in EXPECTED_KEYWORDS:\n",
    "        if keyword.lower() in doc.page_content.lower():\n",
    "            print(f\"‚úÖ Palabra clave encontrada: '{keyword}' en Fuente: {doc.metadata.get('source', 'N/A')}\")\n",
    "            found_keywords_count += 1\n",
    "\n",
    "print(\"\\n--- Veredicto del Test ---\")\n",
    "if found_keywords_count > 0:\n",
    "    print(\"‚úÖ √âXITO PARCIAL/TOTAL: Se encontraron uno o m√°s de los contenidos esperados en los fragmentos recuperados.\")\n",
    "else:\n",
    "    print(\"‚ùå FALLO: Ninguna de las palabras clave esperadas fue encontrada. El contexto relevante no se est√° recuperando.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### üîÅ PREGUNTA 3: \n",
    "\n",
    "Pregunta de Prueba (Test Query): ¬øCu√°l es el avance f√≠sico y financiero del proyecto de la Variante de San Gil?\n",
    "\n",
    "Contenido Esperado (Expected Keywords): [\"Variante de San Gil\", \"avance f√≠sico\", \"96.69%\", \"avance financiero\", \"95.19%\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "# --- CONFIGURACI√ìN DEL TEST ---\n",
    "# 1. Aseg√∫rate de que tu clave de API est√© configurada como variable de entorno\n",
    "#    os.environ[\"OPENAI_API_KEY\"] = \"tu_clave_aqui\"\n",
    "\n",
    "# 2. Define la pregunta y el contenido que esperas encontrar\n",
    "TEST_QUERY = \"¬ø¬øCu√°l es el avance f√≠sico y financiero del proyecto de la Variante de San Gil?\"  # <--- CAMBIA ESTO por tu pregunta de prueba\n",
    "EXPECTED_KEYWORDS = [\"Variante de San Gil\", \"avance f√≠sico\", \"96.69%\", \"avance financiero\", \"95.19%\"] # <--- CAMBIA ESTO por las palabras clave que deben aparecer\n",
    "\n",
    "# 3. Define la ruta a tu base de datos vectorial\n",
    "PERSIST_DIRECTORY = \"chroma_db\"\n",
    "EMBEDDING_MODEL = \"text-embedding-3-small\" # Usa el mismo modelo con el que creaste la base\n",
    "\n",
    "# --- L√ìGICA DEL TEST ---\n",
    "\n",
    "print(\"üß™ Iniciando el Test de Recuperaci√≥n de Contexto...\")\n",
    "\n",
    "# 1. Validar configuraci√≥n\n",
    "api_key_environ = os.environ.get(\"OPENAI_API_KEY\")\n",
    "if not api_key_environ:\n",
    "    raise ValueError(\"La variable de entorno OPENAI_API_KEY no est√° configurada.\")\n",
    "\n",
    "if not os.path.exists(PERSIST_DIRECTORY):\n",
    "    raise FileNotFoundError(f\"El directorio de la base de datos '{PERSIST_DIRECTORY}' no existe. Aseg√∫rate de haber ejecutado el script principal primero.\")\n",
    "\n",
    "print(f\"Buscando en la base de datos en: '{PERSIST_DIRECTORY}'\")\n",
    "\n",
    "# 2. Cargar el retriever\n",
    "print(f\"Cargando embeddings con el modelo: '{EMBEDDING_MODEL}'...\")\n",
    "embeddings = OpenAIEmbeddings(model=EMBEDDING_MODEL)\n",
    "vectorstore = Chroma(\n",
    "    persist_directory=PERSIST_DIRECTORY,\n",
    "    embedding_function=embeddings\n",
    ")\n",
    "# Aumentamos 'k' para tener m√°s contexto que inspeccionar\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 5})\n",
    "\n",
    "# 3. Ejecutar el retriever de forma aislada\n",
    "print(f\"\\nüîç Ejecutando retriever con la pregunta: '{TEST_QUERY}'\")\n",
    "retrieved_docs = retriever.invoke(TEST_QUERY)\n",
    "\n",
    "# 4. Analizar los resultados\n",
    "print(\"\\nüìÑ --- Fragmentos Recuperados --- üìÑ\")\n",
    "if not retrieved_docs:\n",
    "    print(\"‚ùå ¬°ERROR! El retriever no devolvi√≥ ning√∫n documento.\")\n",
    "else:\n",
    "    for i, doc in enumerate(retrieved_docs):\n",
    "        source = doc.metadata.get(\"source\", \"desconocido\")\n",
    "        content = doc.page_content\n",
    "        print(f\"\\n--- Documento {i+1} (Fuente: {source}) ---\\n\")\n",
    "        print(content)\n",
    "        print(\"-\" * 40)\n",
    "\n",
    "# 5. Verificaci√≥n autom√°tica\n",
    "print(\"\\nüèÅ --- Verificaci√≥n de Palabras Clave --- üèÅ\")\n",
    "found_keywords_count = 0\n",
    "for doc in retrieved_docs:\n",
    "    for keyword in EXPECTED_KEYWORDS:\n",
    "        if keyword.lower() in doc.page_content.lower():\n",
    "            print(f\"‚úÖ Palabra clave encontrada: '{keyword}' en Fuente: {doc.metadata.get('source', 'N/A')}\")\n",
    "            found_keywords_count += 1\n",
    "\n",
    "print(\"\\n--- Veredicto del Test ---\")\n",
    "if found_keywords_count > 0:\n",
    "    print(\"‚úÖ √âXITO PARCIAL/TOTAL: Se encontraron uno o m√°s de los contenidos esperados en los fragmentos recuperados.\")\n",
    "else:\n",
    "    print(\"‚ùå FALLO: Ninguna de las palabras clave esperadas fue encontrada. El contexto relevante no se est√° recuperando.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4. Con memoria ‚Äì El sistema conserva el contexto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "\n",
    "qa_chain = ConversationalRetrievalChain.from_llm(\n",
    "    llm=ChatOpenAI(temperature=0),\n",
    "    retriever=vectorstore.as_retriever(),\n",
    "    memory=memory\n",
    ")\n",
    "\n",
    "# Simulaci√≥n de una conversaci√≥n con contexto\n",
    "chat_history = []\n",
    "\n",
    "# Primera pregunta\n",
    "response_1 = qa_chain({\"question\": \"¬øQu√© entidad est√° a cargo del contrato de la v√≠a Oca√±a-C√∫cuta?\"})\n",
    "print(\"Respuesta 1:\", response_1['answer'])\n",
    "\n",
    "# Segunda pregunta que se apoya en la anterior\n",
    "response_2 = qa_chain({\"question\": \"¬øCu√°l es el plazo de entrega del contrato?\"})\n",
    "print(\"Respuesta 2:\", response_2['answer'])\n",
    "# Aqu√≠, la segunda pregunta s√≠ aprovecha el contexto anterior, gracias a la memoria."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. LangChain para INVIAS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1. Descripci√≥n del c√≥digo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El archivo `langc_v01.ipynb` es un **notebook de Jupyter** dise√±ado para mostrar paso a paso c√≥mo construir un **sistema de consulta de informaci√≥n basado en documentos PDF usando LangChain y modelos de lenguaje de OpenAI**. \n",
    "\n",
    "#### Prop√≥sito del archivo `langc_v01.ipynb`\n",
    "\n",
    "Implementar un **chatbot inteligente** que pueda:\n",
    "\n",
    "1. **Leer documentos PDF** institucionales.\n",
    "2. **Convertirlos en embeddings sem√°nticos** usando OpenAI.\n",
    "3. **Almacenarlos en una base vectorial persistente** (Chroma).\n",
    "4. **Responder preguntas** formuladas en lenguaje natural usando LLMs.\n",
    "\n",
    "#### Estructura del notebook\n",
    "\n",
    "1. **Carga y lectura de documentos PDF**\n",
    "\n",
    "   * Usa loaders como `PyPDFLoader`.\n",
    "   * Fragmenta el contenido en chunks con metadatos.\n",
    "   * Prepara los datos para el embedding.\n",
    "\n",
    "2. **Generaci√≥n de embeddings y base vectorial**\n",
    "\n",
    "   * Usa `OpenAIEmbeddings` (`text-embedding-3-small`).\n",
    "   * Crea y guarda una base en Chroma (`chroma_db`).\n",
    "   * Permite que la b√∫squeda de contexto sea sem√°ntica, no solo por palabras clave.\n",
    "\n",
    "3. **Creaci√≥n del `retriever`**\n",
    "\n",
    "   * Define cu√°ntos documentos relevantes recuperar (`k=3` o `k=5`).\n",
    "   * Es el n√∫cleo del sistema RAG (Retrieval-Augmented Generation).\n",
    "\n",
    "4. **Construcci√≥n de la cadena de QA (`RetrievalQA`)**\n",
    "\n",
    "   * Conecta el `retriever` con un modelo de lenguaje (`ChatOpenAI`).\n",
    "   * Puede configurarse para devolver solo la respuesta, o tambi√©n las fuentes.\n",
    "\n",
    "5. **Ejecuci√≥n de consultas**\n",
    "\n",
    "   * Env√≠a preguntas como `\"¬øQu√© es CCPT?\"` o `\"¬øQu√© acciones tom√≥ el INV√çAS en El Tarrita?\"`.\n",
    "   * El sistema responde bas√°ndose en los documentos cargados.\n",
    "\n",
    "> Este codigo viene de [langc_v01.ipynb](../../../Platzi_codes/langc/v01/langc_v01.ipynb). Este c√≥digo desarrollo tiene [Code Explanation](../../../AI_Queries/code_explanation/).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2. Test del c√≥digo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [QA_01.md](others/QA_01.md)\n",
    "- [QA_02.md](others/QA_02.md)\n",
    "- [QA_03.md](others/QA_03.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3. Hallazgos üö©"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. No cita las fuentes de donde extrae la informaci√≥n.\n",
    "2. Solo para una pregunta. Si uso LangChain con un `ConversationalRetrievalChain`, se puede hacer varias preguntas en la misma sesi√≥n\n",
    "3. Sin memoria ‚Äì Cada pregunta se responde de forma aislada"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "1fm4uYP20LHFFkWTsxHRGaaL-p1bVLvG6",
     "timestamp": 1688058575617
    }
   ]
  },
  "kernelspec": {
   "display_name": "UNAD-dBjyLoWd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
