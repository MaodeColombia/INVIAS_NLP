{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X11QtSmiMV9e"
   },
   "source": [
    "# LangChain para INVIAS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "drFyYyIWMavB"
   },
   "source": [
    "## üîí 1. Instalaci√≥n de librer√≠as"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîì  \n",
    "\n",
    "Solo ejecutar este script si no se han instalado los paquetes para desarrollar el c√≥digo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5901,
     "status": "ok",
     "timestamp": 1688165628049,
     "user": {
      "displayName": "Omar Espejel",
      "userId": "05134704829153205181"
     },
     "user_tz": 360
    },
    "id": "LofnVb23dSxe"
   },
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Lista de los paquetes a instalar:\n",
    "\n",
    "    upgrade:\n",
    "        pip\n",
    "        setuptools\n",
    "        wheel\n",
    "    Packages:\n",
    "        langchain \n",
    "        pypdf \n",
    "        openai \n",
    "        chromadb \n",
    "        tiktoken\n",
    "        langchain-community\n",
    "\"\"\"\n",
    "import subprocess\n",
    "\n",
    "comandos = [\n",
    "    [\"pip\", \"install\", \"--upgrade\", \"pip\", \"setuptools\", \"wheel\"],\n",
    "    [\"pip\", \"install\", \"langchain\", \"pypdf\", \"openai\", \"chromadb\", \"tiktoken\"],\n",
    "    [\"pip\", \"install\", \"-U\", \"langchain-community\"],\n",
    "    [\"python\", \"-m\", \"pip\", \"install\", \"--upgrade\", \"pip\"]\n",
    "]\n",
    "\n",
    "log_path = \"instalacion_log.txt\"\n",
    "\n",
    "with open(log_path, \"w\", encoding=\"utf-8\") as log_file:\n",
    "    for i, cmd in enumerate(comandos, start=1):\n",
    "        log_file.write(f\"\\nüîß Ejecutando comando {i}: {' '.join(cmd)}\\n\")\n",
    "        result = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "        \n",
    "        log_file.write(\"‚úÖ STDOUT:\\n\")\n",
    "        log_file.write(result.stdout + \"\\n\")\n",
    "        \n",
    "        if result.stderr:\n",
    "            log_file.write(\"‚ö†Ô∏è STDERR:\\n\")\n",
    "            log_file.write(result.stderr + \"\\n\")\n",
    "\n",
    "print(f\"‚úÖ Resultado guardado en {log_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuraci√≥n de API Key de OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8057,
     "status": "ok",
     "timestamp": 1688165818015,
     "user": {
      "displayName": "Omar Espejel",
      "userId": "05134704829153205181"
     },
     "user_tz": 360
    },
    "id": "dHG9AVJkh3Dz",
    "outputId": "616af93a-257b-4cba-81d9-2d2797414792"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¬°Cliente de OpenAI inicializado correctamente!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "# Recuperar la clave API de la variable de entorno\n",
    "api_key_environ = os.environ.get(\"OPENAI_API_KEY\")\n",
    " \n",
    "# Verificar que la clave API est√© disponible\n",
    "if not api_key_environ:\n",
    "    raise ValueError(\"La variable de entorno OPENAI_API_KEY no est√° configurada o est√° vac√≠a.\")\n",
    " \n",
    "# Inicializar el cliente de OpenAI con la clave API\n",
    "client = OpenAI(api_key=api_key_environ)\n",
    " \n",
    "# Usar el cliente para tus tareas\n",
    "print(\"¬°Cliente de OpenAI inicializado correctamente!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Z_Xi-GvMf8E"
   },
   "source": [
    "## üîí 3. Carga de documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîì  \n",
    "\n",
    "Solo ejecutar este script si no se ha hecho el proceso de embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 57463,
     "status": "ok",
     "timestamp": 1688165880499,
     "user": {
      "displayName": "Omar Espejel",
      "userId": "05134704829153205181"
     },
     "user_tz": 360
    },
    "id": "W_6B2k3Vcfxt",
    "outputId": "862c3d28-9656-41cc-ecde-31daec5f7a6e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÑ Cargando 2024S-VBOG-054699.pdf\n",
      "üìÑ Cargando 2024S-VBOG-056838.pdf\n",
      "üìÑ Cargando 2024S-VBOG-056839.pdf\n",
      "üìÑ Cargando 2024S-VBOG-056844.pdf\n",
      "üìÑ Cargando 2024S-VBOG-056845.pdf\n",
      "Esto es todo el contenido de `ml_papers:`\n",
      "\n",
      "üÜó Todos los documentos estan cargados en ml_papers.\n",
      "‚ûñ Total de fragmentos: 31\n",
      "‚ûñ Los fragmentos son cada una de las hojas de cada uno de los 5 archivos en la carpeta ../../../assets/DG_docs/PDFs_test/\n",
      "‚ûñ Este script se ejecuta desde c:\\Users\\devel\\UNAD\\INVIAS\\INVIAS_NLP\\MMO_codes\\langc\\v01\n",
      "‚ûñ Este es el contenido de la √∫ltima hoja cargada page_content='d. Las tasas de peajes ser√°n diferenciales, es decir, se fijar√°n en proporci√≥n a las\n",
      "distancias recorridas, las caracter√≠sticas vehiculares y sus respectivos costos de\n",
      "operaci√≥n. \n",
      "e. Para la determinaci√≥n del valor del peaje y de las tasas de valorizaci√≥n, en las\n",
      "v√≠as nacionales, se tendr√° en cuenta un criterio de equidad fiscal‚Äù.\n",
      "4. S√≠rvase dar a conocer cu√°les son los servicios que por normativa est√°n\n",
      "obligados a brindar las concesiones  a la ciudadan√≠a (rescate, asistencia,\n",
      "etc.) de forma permanente. \n",
      "Tal y como se inform√≥ previamente, la red vial concesionada se encuentra a cargo de la\n",
      "Agencia Nacional  de  Infraestructura, Entidad  que  incluyen  dentro de las obligaciones\n",
      "contractuales de la concesi√≥n la prestaci√≥n de este tipo de servicios a la ciudadan√≠a, tales\n",
      "como, ambulancias, carro talleres y gr√∫as; en raz√≥n a esto, mediante oficio 2024S-VBOG-\n",
      "054509 se le dio traslado por competencia.\n",
      "De otra parte, la red vial a cargo del INV√çAS no es concesionada; adicionalmente, no\n",
      "existe norma alguna que especifique la prestaci√≥n de servicios asociados al usuario de la\n",
      "v√≠a, en raz√≥n a lo anterior, el INV√çAS no desarrolla los proyectos con alcance de atenci√≥n\n",
      "con ambulancias, carro talleres y gr√∫as, que est√©n asociados al pago de la tasa de peaje,\n",
      "toda vez que la misma tiene su origen en el uso de la infraestructura vial.\n",
      "5. S√≠rvase dar a conocer si por parte de su entidad se tiene planeado establecer\n",
      "un peaje entre Bogot√° y Soacha para la financiaci√≥n del proyecto Avenida\n",
      "Longitudinal de Occidente tramo SUR ‚Äì ALO SUR.\n",
      "Por tratarse la ALO SUR de un proyecto de concesi√≥n a cargo de la Agencia Nacional de\n",
      "Infraestructura ‚Äì ANI, el Instituto Nacional de V√≠as ‚Äì INV√çAS no tiene relaci√≥n con la\n",
      "instalaci√≥n de peajes en el corredor Bogot√° ‚Äì Soacha, por lo anterior mediante oficio\n",
      "2024S-VBOG-054509 se dio traslado por competencia a la ANI.\n",
      "Atentamente, \n",
      "JUAN CARLOS MONTENEGRO ARJONA\n",
      "DIRECTOR GENERAL\n",
      "Proyectado Por: EDNA SAMANTHA RODRIGUEZ PINZON\n",
      "Revisado Por:  ANNY YIRLESA ARIAS SALAZAR, JOSE MANUEL GOMEZ DUQUE, LAURA GERALDINE SANDOVAL\n",
      "BARRERA, MAURICIO HERNAN CESPEDES SOLANO, RUBY AMPARO  MALAVER MONTA√ëA\n",
      "Aprobado Por: LAURA GERALDINE SANDOVAL BARRERA, MAURICIO HERNAN CESPEDES SOLANO, RUBY AMPARO\n",
      " MALAVER MONTA√ëA\n",
      "Copia Interna a: MARISOL ANDRADE MARTINEZ (1000000)\n",
      "Copia Externa a: JUAN DAVID GARZON BAHAMON (MINISTERIO DE TRANSPORTE), GRUPO ENLACE CONGRESO\n",
      "MINTRANSPORTE  (MINISTERIO  DE  TRANSPORTE),  ASUNTOS  LEGISLATIVOS  ANI  (AGENCIA  NACIONAL  DE\n",
      "INFRAESTRUCTURA ANI)\n",
      "_____________________________________________________________________________________________________\n",
      "INSTITUTO NACIONAL DE V√çAS P√°gina 4 | 4\n",
      "Direcci√≥n: Calle 25G # 73B - 90, Bogot√° D.C., Colombia\n",
      "PBX: (+57) 601 377 0600 L√≠nea gratuita: 018000117844\n",
      "Correo institucional: atencionciudadano@invias.gov.co\n",
      "http://www.invias.gov.co' metadata={'producer': 'LibreOffice 5.2', 'creator': 'Writer', 'creationdate': '2024-08-17T01:39:05+00:00', 'author': 'Neiffeth Julieth Vargas Vargas', 'source': '../../../assets/DG_docs/PDFs_test/2024S-VBOG-056845.pdf', 'total_pages': 4, 'page': 3, 'page_label': '4'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "import os\n",
    "\n",
    "relative_pdf_path = \"../../../assets/DG_docs/PDFs_test/\"\n",
    "\n",
    "ml_papers = []\n",
    "\n",
    "for i, file_name in enumerate(os.listdir(relative_pdf_path)):\n",
    "    if file_name.lower().endswith(\".pdf\"):\n",
    "        full_pdf_path = os.path.join(relative_pdf_path,file_name)\n",
    "        print(f\"üìÑ Cargando {file_name}\")\n",
    "\n",
    "        loader = PyPDFLoader(full_pdf_path)\n",
    "        data = loader.load() # AI_Queries\\code_explanation\\ai_query-langc_v01-PyPDFLoader(filename).loader.load()_usage.md\n",
    "        ml_papers.extend(data) # AI_Queries\\code_explanation\\ai_query-langc_v01-.extend_usage.md\n",
    "        # print (ml_papers) # AI_Queries/code_explanation/ai_query-langc_v01-list_start_end_usage.md\n",
    "# Utiliza la lista ml_papers para acceder a los elementos de todos los documentos descargados\n",
    "print('Esto es todo el contenido de `ml_papers:`')\n",
    "print(f\"\"\"\n",
    "üÜó Todos los documentos estan cargados en ml_papers.\n",
    "‚ûñ Total de fragmentos: {len(ml_papers)}\n",
    "‚ûñ Los fragmentos son cada una de las hojas de cada uno de los {len(os.listdir(relative_pdf_path))} archivos en la carpeta {relative_pdf_path}\n",
    "‚ûñ Este script se ejecuta desde {os.getcwd()}\n",
    "‚ûñ Este es el contenido de la √∫ltima hoja cargada {ml_papers[-1]}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WJYjDA_GMi0Z"
   },
   "source": [
    "## üîí 4. Split de documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîì\n",
    "\n",
    "Solo ejecutar este script para desarrollar el proceso de embedding; este script depende del script anterior "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1688165880500,
     "user": {
      "displayName": "Omar Espejel",
      "userId": "05134704829153205181"
     },
     "user_tz": 360
    },
    "id": "4caTdNe-hk7w"
   },
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1500, \n",
    "    # AI_Queries\\code_explanation\\ai_query-langc_v01-chunk_usage.md \n",
    "    # AI_Queries\\code_explanation\\ai_query-langc_v01-max_tokens_Chatgptmodels.md \n",
    "    # AI_Queries\\code_explanation\\ai_query-langc_v01-meaning_inputpromptandanswer.md \n",
    "    # AI_Queries\\code_explanation\\ai_query-langc_v01-retrieval_meaning.md\n",
    "    \n",
    "    chunk_overlap=200,\n",
    "    length_function=len\n",
    "    )\n",
    "\n",
    "documents = text_splitter.split_documents(ml_papers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1688165880500,
     "user": {
      "displayName": "Omar Espejel",
      "userId": "05134704829153205181"
     },
     "user_tz": 360
    },
    "id": "koi4gwzthsGh",
    "outputId": "6ed35c64-9026-4222-b86a-379809bfb6dc"
   },
   "outputs": [],
   "source": [
    "len(documents), documents[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîí 5. Embeddings e ingesta a base de datos vectorial \n",
    "\n",
    "‚ö†Ô∏è advertencia de uso de esta secci√≥n ‚ö†Ô∏è"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîì 5.1.\n",
    "\n",
    "Solo ejecutar este script para desarrolla el proceso de embedding; este script depende del script anterior\n",
    "\n",
    "**Aqu√≠ se consume recurso de la API de OpenAI**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6756,
     "status": "ok",
     "timestamp": 1688165966034,
     "user": {
      "displayName": "Omar Espejel",
      "userId": "05134704829153205181"
     },
     "user_tz": 360
    },
    "id": "iZ-ZFWgRh9aV"
   },
   "outputs": [],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "# AI_Queries\\code_explanation\\ai_query-langc_v01-Embeddings_and_Vector_Store_Ingestion.md\n",
    "\n",
    "# 1. Crear embeddings con el modelo oficial de OpenAI\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
    "\n",
    "# 2. Definir carpeta para almacenar la base de datos vectorial\n",
    "persist_directory = \"chroma_db\" #\n",
    "\n",
    "# 3. Crear la base desde documentos y embeddings\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=documents,\n",
    "    embedding=embeddings,\n",
    "    persist_directory=persist_directory\n",
    ")\n",
    "\n",
    "# 4. Guardar la base en disco\n",
    "vectorstore.persist()\n",
    "print(\"‚úÖ Base de datos Chroma guardada en:\", persist_directory)\n",
    "\n",
    "\n",
    "# 5. Cargar la base vectorial guardada en disco\n",
    "vectorstore = Chroma(\n",
    "    embedding_function=embeddings,\n",
    "    persist_directory=\"chroma_db\"\n",
    ")\n",
    "\n",
    "# 6. Usar como retriever\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_kwargs={\"k\": 3}\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.\n",
    "\n",
    "Fue necesario crear copia de las lineas \"*# 1. Crear embeddings con el modelo oficial de OpenAI*\", \"*# 5. Cargar la base vectorial guardada en disco*\" y \"*# 6. Usar como retriever*\" para **solamente hacer uso de la Based de Datos de embeddings `chroma_db` ya creada y evitar recalcularla**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\devel\\AppData\\Local\\Temp\\ipykernel_184\\3507217838.py:5: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
      "  embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
      "C:\\Users\\devel\\AppData\\Local\\Temp\\ipykernel_184\\3507217838.py:8: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  vectorstore = Chroma(\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "# 1. Modelo de embeddings (debe ser el mismo usado al crear la base)\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
    "\n",
    "# 5. Cargar la base vectorial guardada en disco\n",
    "vectorstore = Chroma(\n",
    "    embedding_function=embeddings,\n",
    "    persist_directory=\"chroma_db\"\n",
    ")\n",
    "\n",
    "# 6. Usar como retriever\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_kwargs={\"k\": 5}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sBbAhkFKMrDC"
   },
   "source": [
    "## 6. Modelos de chat y cadenas para consulta de informaci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1688165966035,
     "user": {
      "displayName": "Omar Espejel",
      "userId": "05134704829153205181"
     },
     "user_tz": 360
    },
    "id": "fxjg2e6RiTqO"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\devel\\AppData\\Local\\Temp\\ipykernel_184\\171208245.py:6: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  chat = ChatOpenAI(\n"
     ]
    }
   ],
   "source": [
    "#AI_Queries/code_explanation/ai_query-langc_v01-Chat_Models_and_Retrieval_Chains_for_Information_Querying.md\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    openai_api_key=api_key_environ,\n",
    "    model_name='gpt-3.5-turbo',\n",
    "    temperature=0.0\n",
    ")\n",
    "\n",
    "# AI_Queries/code_explanation/ai_query-langc_v01-RetrievalQA.from_chain_type_usage.md\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=chat,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "executionInfo": {
     "elapsed": 6199,
     "status": "ok",
     "timestamp": 1688165977030,
     "user": {
      "displayName": "Omar Espejel",
      "userId": "05134704829153205181"
     },
     "user_tz": 360
    },
    "id": "qgDyf-lOimCT",
    "outputId": "18f9ce42-2c78-4540-e6d3-ec5f01223cbb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CCPT se refiere al Programa Caminos Comunitarios para la Paz Total. Es un programa orientado a la identificaci√≥n de necesidades en la red vial regional del pa√≠s, donde cualquier Organismo de Acci√≥n Comunal, comunidad √©tnica o entidad sin √°nimo de lucro puede presentar sus necesidades para la planeaci√≥n y estructuraci√≥n de los tramos a intervenir, con la participaci√≥n activa de la comunidad.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# AI_Queries/code_explanation/ai_query-langc_v01-qa_chain.run()_usage.md\n",
    "\n",
    "query = \"qu√© es CCPT?\"\n",
    "qa_chain.run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 157
    },
    "executionInfo": {
     "elapsed": 14230,
     "status": "ok",
     "timestamp": 1688165991258,
     "user": {
      "displayName": "Omar Espejel",
      "userId": "05134704829153205181"
     },
     "user_tz": 360
    },
    "id": "rfTiF52Bni8D",
    "outputId": "8e6cbcf0-998e-4cad-e11e-7c51fcb12f4e"
   },
   "outputs": [],
   "source": [
    "query = \"qu√© hace complicado entrenar un modelo como el fingpt?\"\n",
    "qa_chain.run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "executionInfo": {
     "elapsed": 5426,
     "status": "ok",
     "timestamp": 1688165996681,
     "user": {
      "displayName": "Omar Espejel",
      "userId": "05134704829153205181"
     },
     "user_tz": 360
    },
    "id": "MmjAbVyUtLCF",
    "outputId": "d40b5c05-ebf2-4eea-e11a-721c9ad9e6e7"
   },
   "outputs": [],
   "source": [
    "query = \"qu√© es fast segment?\"\n",
    "qa_chain.run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "executionInfo": {
     "elapsed": 7353,
     "status": "ok",
     "timestamp": 1688166004032,
     "user": {
      "displayName": "Omar Espejel",
      "userId": "05134704829153205181"
     },
     "user_tz": 360
    },
    "id": "4qfwxnkAt_Q8",
    "outputId": "5ffc4795-48de-4010-c763-da8abaf94c0b"
   },
   "outputs": [],
   "source": [
    "query = \"cu√°l es la diferencia entre fast sam y mobile sam?\"\n",
    "qa_chain.run(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. LangChain para INVIAS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1. Descripci√≥n del c√≥digo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El archivo `langc_v01.ipynb` es un **notebook de Jupyter** dise√±ado para mostrar paso a paso c√≥mo construir un **sistema de consulta de informaci√≥n basado en documentos PDF usando LangChain y modelos de lenguaje de OpenAI**. \n",
    "\n",
    "#### Prop√≥sito del archivo `langc_v01.ipynb`\n",
    "\n",
    "Implementar un **chatbot inteligente** que pueda:\n",
    "\n",
    "1. **Leer documentos PDF** institucionales.\n",
    "2. **Convertirlos en embeddings sem√°nticos** usando OpenAI.\n",
    "3. **Almacenarlos en una base vectorial persistente** (Chroma).\n",
    "4. **Responder preguntas** formuladas en lenguaje natural usando LLMs.\n",
    "\n",
    "#### Estructura del notebook\n",
    "\n",
    "1. **Carga y lectura de documentos PDF**\n",
    "\n",
    "   * Usa loaders como `PyPDFLoader`.\n",
    "   * Fragmenta el contenido en chunks con metadatos.\n",
    "   * Prepara los datos para el embedding.\n",
    "\n",
    "2. **Generaci√≥n de embeddings y base vectorial**\n",
    "\n",
    "   * Usa `OpenAIEmbeddings` (`text-embedding-ada-002`).\n",
    "   * Crea y guarda una base en Chroma (`chroma_db`).\n",
    "   * Permite que la b√∫squeda de contexto sea sem√°ntica, no solo por palabras clave.\n",
    "\n",
    "3. **Creaci√≥n del `retriever`**\n",
    "\n",
    "   * Define cu√°ntos documentos relevantes recuperar (`k=3` o `k=5`).\n",
    "   * Es el n√∫cleo del sistema RAG (Retrieval-Augmented Generation).\n",
    "\n",
    "4. **Construcci√≥n de la cadena de QA (`RetrievalQA`)**\n",
    "\n",
    "   * Conecta el `retriever` con un modelo de lenguaje (`ChatOpenAI`).\n",
    "   * Puede configurarse para devolver solo la respuesta, o tambi√©n las fuentes.\n",
    "\n",
    "5. **Ejecuci√≥n de consultas**\n",
    "\n",
    "   * Env√≠a preguntas como `\"¬øQu√© es CCPT?\"` o `\"¬øQu√© acciones tom√≥ el INV√çAS en El Tarrita?\"`.\n",
    "   * El sistema responde bas√°ndose en los documentos cargados.\n",
    "\n",
    "> Este codigo viene de [langc_v01.ipynb](../../../Platzi_codes/langc/v01/langc_v01.ipynb). Este c√≥digo desarrollo tiene [Code Explanation](../../../AI_Queries/code_explanation/).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2. Hallazgos üö©"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. No cita las fuentes de donde extrae la informaci√≥n."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "1fm4uYP20LHFFkWTsxHRGaaL-p1bVLvG6",
     "timestamp": 1688058575617
    }
   ]
  },
  "kernelspec": {
   "display_name": "UNAD-dBjyLoWd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
