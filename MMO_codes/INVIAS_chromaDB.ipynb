{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "from openai import OpenAI\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ~~FUNCIÓN: Carga de todos los JSON en un DataFrame para su visualización~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def crear_dataframe_json(json_path):\n",
    "#     with open(json_path, 'r', encoding='utf-8') as file:\n",
    "#         data = json.load(file)\n",
    "    \n",
    "#     nombre = data.get(\"name\", \"Desconocido\")\n",
    "#     texto = data.get(\"text\", [])\n",
    "    \n",
    "#     # Crear diccionario base\n",
    "#     df_data = {\"name\": [nombre]}\n",
    "    \n",
    "#     # Procesar páginas\n",
    "#     for entry in texto:\n",
    "#         page_num = entry.get(\"page\", 0)\n",
    "#         content = entry.get(\"content\", \"\")\n",
    "#         embedding = entry.get(\"OpenAI_embedding\", [])\n",
    "        \n",
    "#         df_data[f\"page_{page_num}\"] = [page_num]\n",
    "#         df_data[f\"content_{page_num}\"] = [content]\n",
    "#         df_data[f\"embedding_{page_num}\"] = [embedding]\n",
    "    \n",
    "#     # Crear DataFrame\n",
    "#     df = pd.DataFrame(df_data)\n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "def crear_dataframe_json(folder_path):\n",
    "    '''\n",
    "    Esta función crea un DataFrame a partir de archivos JSON ubicados en un directorio específico.\n",
    "    \n",
    "    Cada JSON representa información extraída de un PDF, estructurada de la siguiente manera:\n",
    "    \n",
    "    1. Contiene un nombre de archivo que identifica el documento.\n",
    "    2. Incluye una lista de páginas con:\n",
    "        - Número de página (`page`)\n",
    "        - Contenido de la página (`content`)\n",
    "        - Representación numérica del contenido generada por OpenAI (`OpenAI_embedding`)\n",
    "\n",
    "    La función recorrerá todos los archivos JSON dentro del `folder_path`, extraerá la información de cada uno,\n",
    "    y generará un DataFrame donde cada fila representa un documento con sus respectivas páginas indexadas.\n",
    "    '''\n",
    "\n",
    "    all_data = []  # Lista para almacenar los datos procesados\n",
    "\n",
    "    # Itera sobre los archivos en la carpeta proporcionada\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".json\"):  # Filtra solo archivos JSON\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                data = json.load(file)  # Carga el contenido del JSON\n",
    "            \n",
    "            # Obtiene el nombre del documento (por defecto, usa el nombre del archivo)\n",
    "            nombre = data.get(\"pdf_filename\", filename)\n",
    "            texto = data.get(\"text\", [])  # Lista de páginas con su contenido\n",
    "            \n",
    "            df_data = {\"name\": nombre}  # Diccionario base para almacenar los datos del documento\n",
    "            # Procesa cada página del JSON\n",
    "            for entry in texto:\n",
    "                page_num = entry.get(\"page\", 0)  # Obtiene el número de página\n",
    "                df_data[f\"page_{page_num}\"] = page_num  # Almacena el número de página\n",
    "                df_data[f\"content_{page_num}\"] = entry.get(\"content\", \"\")  # Almacena el texto de la página\n",
    "                df_data[f\"embedding_{page_num}\"] = entry.get(\"OpenAI_embedding\", [])  # Almacena el embedding si está disponible\n",
    "            \n",
    "            all_data.append(df_data)  # Agrega la información procesada a la lista\n",
    "    \n",
    "    df = pd.DataFrame(all_data)  # Convierte la lista en un DataFrame\n",
    "    return df  # Devuelve el DataFrame resultante\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ejemplo de uso\n",
    "path = \"../assets/DG_docs/jsonembedding_pdf/\"\n",
    "df = crear_dataframe_json(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(3)\n",
    "#df.style.set_sticky()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Del DataFrame anterior, selecciono las primeras 4 columnas que representan la \"página1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset = df[['name', 'page_1','content_1','embedding_1']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Del DataFrame anterio, se eliminan los `nan`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AVERIGUAR POR QUÉ HAY nan DENTRO DE LOS EMBEDDINGS\n",
    "df_cleaned = df_subset.dropna(subset=[\"embedding_1\"]).copy()\n",
    "\n",
    "display(type(df_cleaned['embedding_1'][0]),len(df_cleaned['embedding_1'][0]))\n",
    "\n",
    "df_cleaned['ids'] = df_cleaned.index.astype(str)\n",
    "df_cleaned[\"embedding_1\"] = df_cleaned[\"embedding_1\"].astype(str)\n",
    "\n",
    "#df_cleaned = df.dropna(subset=[\"embedding_1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def save_df_to_csv(df, filename='output.csv', index=False):\n",
    "#     \"\"\"\n",
    "#     Guarda un DataFrame como un archivo CSV.\n",
    "    \n",
    "#     :param df: DataFrame de Pandas a guardar.\n",
    "#     :param filename: Nombre del archivo CSV de salida (por defecto 'output.csv').\n",
    "#     :param index: Si se debe incluir el índice en el archivo CSV (por defecto False).\n",
    "#     \"\"\"\n",
    "#     try:\n",
    "#         df.to_csv(filename, index=index, encoding='utf-8')\n",
    "#         print(f\"DataFrame guardado correctamente en {filename}\")\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error al guardar el DataFrame: {e}\")\n",
    "\n",
    "\n",
    "# save_df_to_csv(df, 'datos.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentence_transformer_ef = embedding_functions.SentenceTransformerEmbeddingFunction(model_name = 'all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_cleaned['embedding_1'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display(type(df_cleaned['embedding_1'][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. FUNCIÓN:  Genera un embedding del texto usando OpenAI\n",
    "ESTÁ MAL COMENTADA LA FUNCIÓN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generar_embedding(texto: str) -> list:\n",
    "    \"\"\"\n",
    "    Genera un embedding del texto usando OpenAI.\n",
    "\n",
    "    WARNING:\n",
    "        \n",
    "    Packages:\n",
    "        from openai import OpenAI\n",
    "        import os\n",
    "        import json\n",
    "\n",
    "    Args:\n",
    "        texto: Texto a procesar para obtener su embedding.\n",
    "\n",
    "    Returns:\n",
    "        dict: Un diccionario con el embedding generado y la cantidad de tokens procesados.\n",
    "\n",
    "    Example:\n",
    "        generar_embedding(\"Este es un texto de prueba\")\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        # Llama a la API de OpenAI para obtener embeddings\n",
    "        client = OpenAI()\n",
    "        respuesta = client.embeddings.create(\n",
    "            input=texto[:8191],  # OpenAI limita a 8192 tokens por entrada\n",
    "            # EL COMENTARIO ANTERIOR ESTA MAL ENFORACADO PORQUE SE RECORTA EL TEXTO A 8191 Y LO QUE SE DEBE RECORTAR ES HASTA 8191 TOKENS\n",
    "            model=\"text-embedding-3-small\"  # Modelo optimizado para embeddings\n",
    "        )\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error generando embedding: {e}\")\n",
    "        return None\n",
    "    \n",
    "    return respuesta.data[0].embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ~~Uso de ChromDB de forma local~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import ast\n",
    "# import chromadb\n",
    "# from chromadb.utils import embedding_functions\n",
    "\n",
    "# openai_ef = embedding_functions.OpenAIEmbeddingFunction(\n",
    "#     api_key = os.environ.get(\"OPENAI_API_KEY\"),\n",
    "#     model_name = \"text-embedding-3-small\"\n",
    "#     )\n",
    "\n",
    "# # Inicializar el cliente de ChromaDB con almacenamiento persistente\n",
    "# chroma_client_persistent = chromadb.PersistentClient(path=\"./chroma_db\")\n",
    "\n",
    "# # Crear o recuperar la colección\n",
    "# collection = chroma_client_persistent.get_or_create_collection(name=\"documentos\", embedding_function=openai_ef)\n",
    "\n",
    "# # Procesar los datos y agregarlos a la colección de ChromaDB\n",
    "# ids = df_cleaned['ids'].astype(str).tolist()\n",
    "# #documents = df_cleaned['content_1'].tolist() #esto se coloca cuando no se tiene los embedings, sedcoloca `documents`\n",
    "# embeddings = [ast.literal_eval(e) for e in df_cleaned[\"embedding_1\"].astype(str)]\n",
    "# metadatas = df_cleaned[[\"name\", \"page_1\"]].to_dict(\"records\")  #tipo diccionario\n",
    "\n",
    "# display(ids)\n",
    "\n",
    "\n",
    "# # Agregar los datos a la colección en ChromaDB\n",
    "# collection.add(ids=ids, embeddings=embeddings, metadatas=metadatas)\n",
    "\n",
    "# # Confirmación\n",
    "# f\"Se han agregado {len(ids)} documentos a ChromaDB.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La idea de esta prueba es cambiar la seccion anterior\n",
    "## ~~PRUEBA O.K.: Almacenamiento de la información en ChromaDB (modo servidor) PERO usa la data de un DataFrame no del JSON directamente~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```powershell\n",
    "PS C:\\Users\\devel\\UNAD\\INVIAS\\INVIAS_NLP> curl http://localhost:8000\n",
    "curl: (7) Failed to connect to localhost port 8000 after 2235 ms: Couldn't connect to server\n",
    "```\n",
    "\n",
    "```powershell\n",
    "PS C:\\Users\\devel\\UNAD\\INVIAS\\INVIAS_NLP chroma run --path ./assets/DG_docs/chroma_db\n",
    "```\n",
    "\n",
    "```powershell\n",
    "PS C:\\Users\\devel\\UNAD\\INVIAS\\INVIAS_NLP> netstat -ano | findstr :8000\n",
    "  TCP    127.0.0.1:8000         0.0.0.0:0              LISTENING       16144\n",
    "  TCP    [::1]:8000             [::]:0                 LISTENING       16144\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !chroma run --path ./assets/DG_docs/chroma_db\n",
    "# 4️⃣ (Opcional) Ejecutar en segundo plano\n",
    "# Si quieres que el servidor siga corriendo después de cerrar la terminal, usa:\n",
    "\n",
    "# nohup chromadb run --path /var/lib/chroma_db/ > chroma.log 2>&1 &\n",
    "\n",
    "# Esto mantendrá el proceso activo y guardará los logs en chroma.log.\n",
    "\n",
    "#chromadb run --path=\"./assets/DG_docs/chroma_db\" --host=0.0.0.0 --port=8000\n",
    "\n",
    "# !netstat -ano | findstr :8000 \n",
    "# !taskkill /PID 568 /F\n",
    "# !curl http://localhost:8000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import ast\n",
    "# import chromadb\n",
    "# from chromadb.utils import embedding_functions\n",
    "\n",
    "# # Configurar la función de embeddings de OpenAI\n",
    "# openai_ef = embedding_functions.OpenAIEmbeddingFunction(\n",
    "#     api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    "#     model_name=\"text-embedding-3-small\"\n",
    "# )\n",
    "\n",
    "# # Conectar al servidor de ChromaDB (ya no se usa PersistentClient ni Settings)\n",
    "# chroma_http_client = chromadb.HttpClient(host=\"localhost\", port=8000)\n",
    "\n",
    "# # Crear o recuperar la colección\n",
    "# collection = chroma_http_client.get_or_create_collection(\n",
    "#     name=\"pdf_document\",\n",
    "#     embedding_function=openai_ef\n",
    "# )\n",
    "\n",
    "# # Procesar los datos\n",
    "# ids = df_cleaned['ids'].astype(str).tolist()\n",
    "# embeddings = [ast.literal_eval(e) for e in df_cleaned[\"embedding_1\"].astype(str)]\n",
    "# metadatas = df_cleaned[[\"name\", \"page_1\"]].to_dict(\"records\")\n",
    "\n",
    "# # Agregar los datos a la colección\n",
    "# collection.upsert(ids=ids, embeddings=embeddings, metadatas=metadatas)\n",
    "\n",
    "# # Confirmación\n",
    "# print(f\"Se han agregado {len(ids)} documentos a ChromaDB.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chroma_http_client.list_collections()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## borra la coleccion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import chromadb\n",
    "\n",
    "# # Conexión al servidor de ChromaDB\n",
    "# chroma_http_client = chromadb.HttpClient(host=\"localhost\", port=8000)\n",
    "\n",
    "# collection_name = \"pdf_document\"\n",
    "\n",
    "# # Obtener la lista de nombres de colecciones (directamente)\n",
    "# collections = chroma_http_client.list_collections()  # Ya devuelve solo nombres\n",
    "\n",
    "# if collection_name in collections:\n",
    "#     chroma_http_client.delete_collection(collection_name)\n",
    "#     print(f\"✅ La colección '{collection_name}' ha sido eliminada.\")\n",
    "# else:\n",
    "#     print(f\"⚠️ La colección '{collection_name}' no existe.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ~~PRUEBA OK: Almacenamiento de los JSON directamente a ChromaDB de _todas las hojas de un PDF_; a diferencia de la anterior que almacena en ChromaDB a partir de DataFrame~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```powershell\n",
    "PS C:\\Users\\devel\\UNAD\\INVIAS\\INVIAS_NLP> curl http://localhost:8000\n",
    "curl: (7) Failed to connect to localhost port 8000 after 2235 ms: Couldn't connect to server\n",
    "```\n",
    "\n",
    "```powershell\n",
    "PS C:\\Users\\devel\\UNAD\\INVIAS\\INVIAS_NLP chroma run --path ./assets/DG_docs/chroma_db\n",
    "```\n",
    "\n",
    "```powershell\n",
    "PS C:\\Users\\devel\\UNAD\\INVIAS\\INVIAS_NLP> netstat -ano | findstr :8000\n",
    "  TCP    127.0.0.1:8000         0.0.0.0:0              LISTENING       16144\n",
    "  TCP    [::1]:8000             [::]:0                 LISTENING       16144\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import chromadb\n",
    "from chromadb.utils.embedding_functions import OpenAIEmbeddingFunction\n",
    "from chromadb.utils import embedding_functions\n",
    "import ast\n",
    "\n",
    "\n",
    "# Cargar el archivo JSON\n",
    "def load_json(file_path):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "# Guardar en ChromaDB\n",
    "def store_in_chromadb(json_data, collection_name=\"pdf_document\"):\n",
    "    # Inicializar el cliente de ChromaDB\n",
    "    chroma_http_client = chromadb.HttpClient(host=\"localhost\", port=8000)\n",
    "    \n",
    "    # Configurar la función de embeddings de OpenAI\n",
    "    openai_ef = embedding_functions.OpenAIEmbeddingFunction(\n",
    "        api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    "        model_name=\"text-embedding-3-small\"\n",
    "    )\n",
    "\n",
    "    # Crear o recuperar la colección\n",
    "    collection = chroma_http_client.get_or_create_collection(\n",
    "        name                = collection_name,\n",
    "        embedding_function  = openai_ef\n",
    "    )\n",
    "    \n",
    "    pdf_filename = json_data[\"pdf_filename\"]\n",
    "    pages = json_data[\"text\"]\n",
    "    \n",
    "    for page_data in pages:\n",
    "        page_number = page_data[\"page\"]\n",
    "        content = page_data[\"content\"]\n",
    "        \n",
    "        embedding = page_data[\"OpenAI_embedding\"]\n",
    "\n",
    "        #embedding = ast.literal_eval(e) for e in page_data[\"OpenAI_embedding\"]\n",
    "        \n",
    "        collection.add(\n",
    "            ids=[f\"{pdf_filename}_page_{page_number}\"],\n",
    "            metadatas=[{\"pdf_filename\": pdf_filename, \"page\": page_number}],\n",
    "            embeddings=[embedding],\n",
    "            documents=[content]\n",
    "        )\n",
    "\n",
    "\n",
    "        # # Procesar los datos\n",
    "        # ids = df_cleaned['ids'].astype(str).tolist()\n",
    "        # embeddings = [ast.literal_eval(e) for e in df_cleaned[\"embedding_1\"].astype(str)]\n",
    "        # metadatas = df_cleaned[[\"name\", \"page_1\"]].to_dict(\"records\")\n",
    "\n",
    "        # # Agregar los datos a la colección\n",
    "        # collection.upsert(ids=ids, embeddings=embeddings, metadatas=metadatas)\n",
    "\n",
    "    \n",
    "    print(f\"Documento '{pdf_filename}' almacenado con {len(pages)} páginas en ChromaDB.\")\n",
    "\n",
    "    # display(\"display(collection.peek(8), collection.count())\",display(collection.peek(8), collection.count()) )\n",
    "\n",
    "   \n",
    "\n",
    "    # # Extraer y mostrar los IDs o metadatas o embeddings o documents\n",
    "    \n",
    "    # print(collection.get().keys())\n",
    "    # display(collection.count())\n",
    "\n",
    "    # display(collection.get()['ids'])\n",
    "    # display(collection.get()['metadatas'])\n",
    "    \n",
    "\n",
    "    #display(collection.peek(1))\n",
    "    #display(collection.peek(1)['embeddings'].shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documento '2024S-VBOG-004040 (1).pdf' almacenado con 11 páginas en ChromaDB.\n"
     ]
    }
   ],
   "source": [
    "# ejemplo de uso\n",
    "json_path = \"../assets/DG_docs/jsonembedding_pdf/2024S-VBOG-004040 (1).json\"\n",
    "\n",
    "df = store_in_chromadb(load_json(json_path))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Queries a ChromaDB (modo servidor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_chromadb_remote(query_text, collection_name=\"pdf_document\", top_k=3, host=\"localhost\", port=8000):\n",
    "    \"\"\"\n",
    "    Realiza una consulta en ChromaDB alojado en un servidor remoto.\n",
    "    \n",
    "    :param query_text: Texto de la consulta.\n",
    "    :param collection_name: Nombre de la colección en ChromaDB.\n",
    "    :param top_k: Número de resultados más relevantes a recuperar.\n",
    "    :param host: Dirección del servidor remoto de ChromaDB.\n",
    "    :param port: Puerto del servidor ChromaDB (por defecto 8000).\n",
    "    :return: Resultados de la consulta.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Conectar al servidor de ChromaDB (ya no se usa PersistentClient ni Settings)\n",
    "    chroma_http_client = chromadb.HttpClient(host=host, port=port)\n",
    "    \n",
    "    # Configurar la función de embeddings de OpenAI\n",
    "    openai_ef = embedding_functions.OpenAIEmbeddingFunction(\n",
    "        api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    "        model_name=\"text-embedding-3-small\"\n",
    "    )\n",
    "    \n",
    "    \n",
    "    collection = chroma_http_client.get_collection(name = collection_name, embedding_function = openai_ef)\n",
    "    \n",
    "    results = collection.query(\n",
    "        query_texts=[query_text],\n",
    "        n_results=top_k\n",
    "        # where={\"metadata_field\": \"is_equal_to_this\"},\n",
    "        # where_document={\"$contains\":\"search_string\"} # \"$not_contains\": \"search_string\"\n",
    "    )\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "    # n_results=10,\n",
    "    # where={\"metadata_field\": \"is_equal_to_this\"},\n",
    "    # where_document={\"$contains\":\"search_string\"} # \"$not_contains\": \"search_string\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ¿Cuál es el presupuesto del programa Caminos Comunitarios de la Paz Total?\n",
    "\n",
    "query_chromadb_remote(\"¿Cuál es el presupuesto del programa Caminos Comunitarios de la Paz Total?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OTROS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chromadb.config import Settings\n",
    "print(Settings.__annotations__)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "UNAD-dBjyLoWd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
