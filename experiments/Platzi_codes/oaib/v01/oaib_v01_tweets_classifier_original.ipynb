{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "13877tD3TxCN"
   },
   "source": [
    "## Instalar librer√≠a de OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5504,
     "status": "ok",
     "timestamp": 1701190045705,
     "user": {
      "displayName": "Miguel Torres",
      "userId": "00890993134474397422"
     },
     "user_tz": 360
    },
    "id": "Xky3yk53SGXQ",
    "outputId": "c78d3f51-2e33-425e-a85f-d35b77e057d1"
   },
   "outputs": [],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-chXGqykT19o"
   },
   "source": [
    "## Importar librer√≠as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1701190045705,
     "user": {
      "displayName": "Miguel Torres",
      "userId": "00890993134474397422"
     },
     "user_tz": 360
    },
    "id": "Yda6XTJ2Tiz7"
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rlk32AjFT6KU"
   },
   "source": [
    "## Cargar API Key de OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 352,
     "status": "ok",
     "timestamp": 1701190112114,
     "user": {
      "displayName": "Miguel Torres",
      "userId": "00890993134474397422"
     },
     "user_tz": 360
    },
    "id": "sHehHPGPT_iS"
   },
   "outputs": [],
   "source": [
    "# ------------------------------CAMBIO DE SISTEMA DE INGRESO DE api_key POR INSERSION DIRECTA A INGRESO POR VARIABLE DE ENTORNO---------------------------\n",
    "# openai = OpenAI(api_key='Ingresa aqu√≠ tu API Key de OpenAI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¬°Cliente de OpenAI inicializado correctamente!\n"
     ]
    }
   ],
   "source": [
    "# AI_Queries/code_explanation/oaib/v01-script01.md\n",
    "#   AI_Queries/code_explanation/oaib/v01-script01_Tipos_de_modelos_de_OpenAI.md\n",
    "#   AI_Queries/code_explanation/oaib/v01-script01_diferencias‚ÄúModelos_de_Chat‚Äùy‚ÄúModelos_de_Completions‚Äù.md\n",
    "\n",
    "import os\n",
    "from openai import OpenAI\n",
    "# Recuperar la clave API de la variable de entorno\n",
    "api_key_environ = os.environ.get(\"OPENAI_API_KEY\")\n",
    " \n",
    "# Verificar que la clave API est√© disponible\n",
    "if not api_key_environ:\n",
    "    raise ValueError(\"La variable de entorno OPENAI_API_KEY no est√° configurada o est√° vac√≠a.\")\n",
    " \n",
    "# Inicializar el cliente de OpenAI con la clave API\n",
    "client_openai = OpenAI(api_key=api_key_environ)\n",
    " \n",
    "# Usar el cliente para tus tareas\n",
    "print(\"¬°Cliente de OpenAI inicializado correctamente!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fuKoxVYtUEVE"
   },
   "source": [
    "## Clasificador de Tweets con Completion API (Legacy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 2009,
     "status": "ok",
     "timestamp": 1701190082750,
     "user": {
      "displayName": "Miguel Torres",
      "userId": "00890993134474397422"
     },
     "user_tz": 360
    },
    "id": "rAydwHmcRcfn"
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------------DEPRICATED---------------------------------------------\n",
    "# response = openai.completions.create(\n",
    "#   model=\"gpt-3.5-turbo-instruct\",\n",
    "#   prompt=\"Decide si el sentimiento de un Tweet es positivo, neutral, o negativo. \\\n",
    "#   \\n\\nTweet: \\\"#LoNuevoEnPlatzi es el Platzibot ü§ñ. Un asistente creado con Inteligencia Artificial para acompa√±arte en tu proceso de aprendizaje.\\\n",
    "#   \\\"\\nSentiment:\",\n",
    "#   temperature=0,\n",
    "#   max_tokens=60,\n",
    "#   top_p=1.0,\n",
    "#   frequency_penalty=0.5,\n",
    "#   presence_penalty=0.0\n",
    "# )\n",
    "\n",
    "\n",
    "# Cambia la configuraci√≥n al siguiente script basado en la siguiente teoria \n",
    "\n",
    "# - [Qu√© tipos de modelos maneja openai actualmente?](v01-script01_Tipos_de_modelos_de_OpenAI.md)\n",
    "#   - [Qu√© diferencias principales hay entre los ‚ÄúModelos de Chat‚Äù y los ‚ÄúModelos de Completions‚Äù?](v01-script01_diferencias‚ÄúModelos_de_Chat‚Äùy‚ÄúModelos_de_Completions‚Äù.md)\n",
    "\n",
    "# - [Principales familias de modelos de OpenAI, un modelo representativo, y sus precios vigentes (junio de 2025)](v01-script01_familias_modelos_OpenAI.md)\n",
    "\n",
    "# - [Desarrollo m√°s profundo de la teor√≠a detr√°s de top_p (tambi√©n conocido como nucleus sampling) y su interacci√≥n con otros par√°metros de generaci√≥n como temperature](v01-script01_temperature,top_p,frequency_penalty,presence_penalty.md)\n",
    "\n",
    "#   - [Tabla con los principales par√°metros de generaci√≥n de texto en la API de OpenAI y sus rangos de valores permitidos (vigentes a junio de 2025)](v01-script01_rangos-temperature,top_p,frequency_penalty,presence_penalty.md)\n",
    "\n",
    "response = client_openai.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"Eres un asistente que clasifica sentimientos.\"},\n",
    "    {\"role\": \"user\",   \"content\": \"Decide si el sentimiento de este Tweet es positivo, neutral o negativo:\\n\\\"#LoNuevoEnPlatzi es el Platzibot ü§ñ...\\\"\\nSentimiento:\"}\n",
    "  ],\n",
    "  temperature=0,\n",
    "  max_tokens=60,\n",
    "  top_p=1.0,\n",
    "  frequency_penalty=0.5,\n",
    "  presence_penalty=0.0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HZsHLJOyUL4Q"
   },
   "source": [
    "## Imprimir respuesta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 329,
     "status": "ok",
     "timestamp": 1701190100544,
     "user": {
      "displayName": "Miguel Torres",
      "userId": "00890993134474397422"
     },
     "user_tz": 360
    },
    "id": "VhB5V2k_SgIR",
    "outputId": "c317d8db-0bef-4db2-a488-506aa06ce8db"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'El sentimiento de este Tweet es positivo.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#--------DEBIDO AL CAMBIO DEL SCRIPT ANTERIOR SE DEBIO CAMBIAR ES SCRIPT POSTERIOR---------------------\n",
    "# No se usa response.choices[0].text, porque esa sintaxis corresponde al endpoint antiguo de ‚ÄúCompletions‚Äù (p. ej. openai.Completion.create(...)), no al de ‚ÄúChat Completions‚Äù.\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-BfX9ppy1lbrjvK1VBqWO6a1jLnuBf', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='El sentimiento de este Tweet es positivo.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None, annotations=[]))], created=1749238605, model='gpt-3.5-turbo-0125', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=10, prompt_tokens=60, total_tokens=70, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n"
     ]
    }
   ],
   "source": [
    "print(response) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chatcmpl-BfX9ppy1lbrjvK1VBqWO6a1jLnuBf\n",
      "chat.completion\n",
      "1749238605\n",
      "gpt-3.5-turbo-0125\n",
      "60\n",
      "10\n",
      "70\n"
     ]
    }
   ],
   "source": [
    "print(response.id)             # \"chatcmpl-XXXXXXXX\"\n",
    "print(response.object)         # \"chat.completion\"\n",
    "print(response.created)        # 1611234567\n",
    "print(response.model)          # \"gpt-3.5-turbo\"\n",
    "\n",
    "print(response.usage.prompt_tokens)      # 15\n",
    "print(response.usage.completion_tokens)  # 20\n",
    "print(response.usage.total_tokens)       # 35\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "assistant\n",
      "El sentimiento de este Tweet es positivo.\n",
      "stop\n"
     ]
    }
   ],
   "source": [
    "for choice in response.choices:\n",
    "    print(choice.index)                    # 0, 1, ...\n",
    "    print(choice.message.role)             # \"assistant\"\n",
    "    print(choice.message.content)          # texto generado\n",
    "    print(choice.finish_reason)            # \"stop\", \"length\", etc.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "NLP_Congreso",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
