{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X11QtSmiMV9e"
   },
   "source": [
    "# Hola, mundo en LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "drFyYyIWMavB"
   },
   "source": [
    "## Instalar librerías principales y configuración de API Key de OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5901,
     "status": "ok",
     "timestamp": 1688165628049,
     "user": {
      "displayName": "Omar Espejel",
      "userId": "05134704829153205181"
     },
     "user_tz": 360
    },
    "id": "LofnVb23dSxe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (25.1.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (75.8.0)\n",
      "Collecting setuptools\n",
      "  Using cached setuptools-80.8.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting wheel\n",
      "  Using cached wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "Using cached setuptools-80.8.0-py3-none-any.whl (1.2 MB)\n",
      "Using cached wheel-0.45.1-py3-none-any.whl (72 kB)\n",
      "Installing collected packages: wheel, setuptools\n",
      "\n",
      "   ---------------------------------------- 0/2 [wheel]\n",
      "  Attempting uninstall: setuptools\n",
      "   ---------------------------------------- 0/2 [wheel]\n",
      "    Found existing installation: setuptools 75.8.0\n",
      "   ---------------------------------------- 0/2 [wheel]\n",
      "   -------------------- ------------------- 1/2 [setuptools]\n",
      "    Uninstalling setuptools-75.8.0:\n",
      "   -------------------- ------------------- 1/2 [setuptools]\n",
      "   -------------------- ------------------- 1/2 [setuptools]\n",
      "   -------------------- ------------------- 1/2 [setuptools]\n",
      "   -------------------- ------------------- 1/2 [setuptools]\n",
      "   -------------------- ------------------- 1/2 [setuptools]\n",
      "   -------------------- ------------------- 1/2 [setuptools]\n",
      "   -------------------- ------------------- 1/2 [setuptools]\n",
      "   -------------------- ------------------- 1/2 [setuptools]\n",
      "   -------------------- ------------------- 1/2 [setuptools]\n",
      "   -------------------- ------------------- 1/2 [setuptools]\n",
      "   -------------------- ------------------- 1/2 [setuptools]\n",
      "   -------------------- ------------------- 1/2 [setuptools]\n",
      "   -------------------- ------------------- 1/2 [setuptools]\n",
      "   -------------------- ------------------- 1/2 [setuptools]\n",
      "   -------------------- ------------------- 1/2 [setuptools]\n",
      "   -------------------- ------------------- 1/2 [setuptools]\n",
      "   -------------------- ------------------- 1/2 [setuptools]\n",
      "      Successfully uninstalled setuptools-75.8.0\n",
      "   -------------------- ------------------- 1/2 [setuptools]\n",
      "   -------------------- ------------------- 1/2 [setuptools]\n",
      "   -------------------- ------------------- 1/2 [setuptools]\n",
      "   -------------------- ------------------- 1/2 [setuptools]\n",
      "   -------------------- ------------------- 1/2 [setuptools]\n",
      "   -------------------- ------------------- 1/2 [setuptools]\n",
      "   -------------------- ------------------- 1/2 [setuptools]\n",
      "   -------------------- ------------------- 1/2 [setuptools]\n",
      "   -------------------- ------------------- 1/2 [setuptools]\n",
      "   -------------------- ------------------- 1/2 [setuptools]\n",
      "   -------------------- ------------------- 1/2 [setuptools]\n",
      "   -------------------- ------------------- 1/2 [setuptools]\n",
      "   -------------------- ------------------- 1/2 [setuptools]\n",
      "   -------------------- ------------------- 1/2 [setuptools]\n",
      "   -------------------- ------------------- 1/2 [setuptools]\n",
      "   -------------------- ------------------- 1/2 [setuptools]\n",
      "   -------------------- ------------------- 1/2 [setuptools]\n",
      "   -------------------- ------------------- 1/2 [setuptools]\n",
      "   -------------------- ------------------- 1/2 [setuptools]\n",
      "   ---------------------------------------- 2/2 [setuptools]\n",
      "\n",
      "Successfully installed setuptools-80.8.0 wheel-0.45.1\n",
      "Requirement already satisfied: langchain in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (0.3.25)\n",
      "Requirement already satisfied: pypdf in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (5.1.0)\n",
      "Requirement already satisfied: openai in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (1.60.0)\n",
      "Requirement already satisfied: chromadb in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (0.6.3)\n",
      "Requirement already satisfied: tiktoken in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (0.8.0)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.58 in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (from langchain) (0.3.61)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (from langchain) (0.3.8)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (from langchain) (0.2.11)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (from langchain) (2.10.5)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (from langchain) (2.0.37)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (9.0.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (4.12.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.58->langchain) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.14)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (4.8.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (2024.12.14)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.7)\n",
      "Requirement already satisfied: idna in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (from requests<3,>=2->langchain) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (from requests<3,>=2->langchain) (2.3.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (from openai) (0.8.2)\n",
      "Requirement already satisfied: sniffio in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: build>=1.0.3 in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (from chromadb) (1.2.2.post1)\n",
      "Requirement already satisfied: chroma-hnswlib==0.7.6 in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (from chromadb) (0.7.6)\n",
      "Requirement already satisfied: fastapi>=0.95.2 in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (from chromadb) (0.115.6)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.34.0)\n",
      "Requirement already satisfied: numpy>=1.22.5 in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (from chromadb) (1.26.4)\n",
      "Requirement already satisfied: posthog>=2.4.0 in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (from chromadb) (3.8.3)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (from chromadb) (1.20.1)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (from chromadb) (1.29.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (from chromadb) (1.29.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (from chromadb) (0.50b0)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (from chromadb) (1.29.0)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (from chromadb) (0.21.0)\n",
      "Requirement already satisfied: pypika>=0.48.9 in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (from chromadb) (0.48.9)\n",
      "Requirement already satisfied: overrides>=7.3.1 in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (from chromadb) (7.7.0)\n",
      "Requirement already satisfied: importlib-resources in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (from chromadb) (6.5.2)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (from chromadb) (1.69.0)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (from chromadb) (4.2.1)\n",
      "Requirement already satisfied: typer>=0.9.0 in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (from chromadb) (0.15.1)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (from chromadb) (31.0.0)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (from chromadb) (5.0.1)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (from chromadb) (13.9.4)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (from tiktoken) (2024.11.6)\n",
      "Requirement already satisfied: pyproject_hooks in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (from build>=1.0.3->chromadb) (0.4.6)\n",
      "Requirement already satisfied: starlette<0.42.0,>=0.40.0 in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (from fastapi>=0.95.2->chromadb) (0.41.0)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.37.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
      "Requirement already satisfied: requests-oauthlib in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
      "Requirement already satisfied: durationpy>=0.7 in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (0.9)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (from rsa<5,>=3.1.4->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n",
      "Requirement already satisfied: coloredlogs in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (24.12.23)\n",
      "Requirement already satisfied: protobuf in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (5.29.3)\n",
      "Requirement already satisfied: sympy in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (1.13.1)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.15)\n",
      "Requirement already satisfied: importlib-metadata<=8.5.0,>=6.0 in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (from opentelemetry-api>=1.2.0->chromadb) (8.5.0)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.21.0)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (from deprecated>=1.2.6->opentelemetry-api>=1.2.0->chromadb) (1.17.2)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.66.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.29.0 in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.29.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.29.0 in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.29.0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.50b0 in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (from opentelemetry-sdk>=1.2.0->chromadb) (0.50b0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.50b0 in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.50b0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation==0.50b0 in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.50b0)\n",
      "Requirement already satisfied: opentelemetry-util-http==0.50b0 in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.50b0)\n",
      "Requirement already satisfied: asgiref~=3.0 in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (from opentelemetry-instrumentation-asgi==0.50b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (3.8.1)\n",
      "Requirement already satisfied: monotonic>=1.5 in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
      "Requirement already satisfied: backoff>=1.10.0 in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (from rich>=10.11.0->chromadb) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (from rich>=10.11.0->chromadb) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (from tokenizers>=0.13.2->chromadb) (0.27.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2024.9.0)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (from typer>=0.9.0->chromadb) (8.1.8)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
      "Requirement already satisfied: httptools>=0.6.3 in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.4)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.1)\n",
      "Requirement already satisfied: watchfiles>=0.13 in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.4)\n",
      "Requirement already satisfied: websockets>=10.4 in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (14.1)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
      "Requirement already satisfied: pyreadline3 in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.14.1->chromadb) (3.5.4)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
      "Requirement already satisfied: langchain-community in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (0.3.24)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.59 in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (from langchain-community) (0.3.61)\n",
      "Requirement already satisfied: langchain<1.0.0,>=0.3.25 in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (from langchain-community) (0.3.25)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (from langchain-community) (2.0.37)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (from langchain-community) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (from langchain-community) (6.0.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (from langchain-community) (3.11.11)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (from langchain-community) (9.0.0)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (from langchain-community) (2.7.1)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (from langchain-community) (0.2.11)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (from langchain-community) (0.4.0)\n",
      "Requirement already satisfied: numpy>=1.26.2 in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (from langchain-community) (1.26.4)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.18.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.25.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (from langchain<1.0.0,>=0.3.25->langchain-community) (0.3.8)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (from langchain<1.0.0,>=0.3.25->langchain-community) (2.10.5)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.59->langchain-community) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.59->langchain-community) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.59->langchain-community) (4.12.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.59->langchain-community) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-community) (3.10.14)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (4.8.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (2024.12.14)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.0.7)\n",
      "Requirement already satisfied: idna in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.25->langchain-community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.25->langchain-community) (2.27.2)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (from requests<3,>=2->langchain-community) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (from requests<3,>=2->langchain-community) (2.3.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.1.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.3.1)\n",
      "Requirement already satisfied: pip in c:\\users\\mmartinezo\\.virtualenvs\\nlp_congreso\\lib\\site-packages (25.1.1)\n"
     ]
    }
   ],
   "source": [
    "# El sigueinte comando se usa cuando instalas paquetes y no quieres llenar la pantalla con mensajes de instalación.\n",
    "#%%capture captura \n",
    "#!pip install --upgrade pip setuptools wheel\n",
    "#!pip install langchain pypdf openai chromadb tiktoken\n",
    "#!pip install -U langchain-community\n",
    "#!python.exe -m pip install --upgrade pip\n",
    "\n",
    "\n",
    "# Acceso directo al stdout capturado\n",
    "#print(captura.stdout)\n",
    "\n",
    "# Acceso directo al stderr capturado (si lo hubiera)\n",
    "#print(captura.stderr)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8057,
     "status": "ok",
     "timestamp": 1688165818015,
     "user": {
      "displayName": "Omar Espejel",
      "userId": "05134704829153205181"
     },
     "user_tz": 360
    },
    "id": "dHG9AVJkh3Dz",
    "outputId": "616af93a-257b-4cba-81d9-2d2797414792"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¡Cliente de OpenAI inicializado correctamente!\n"
     ]
    }
   ],
   "source": [
    "# from getpass import getpass\n",
    "# import os\n",
    "\n",
    "# OPENAI_API_KEY = getpass('Enter the secret value: ')\n",
    "# os.environ['OPENAI_API_KEY'] = OPENAI_API_KEY\n",
    "\n",
    "\n",
    "import os\n",
    "from openai import OpenAI\n",
    "# Recuperar la clave API de la variable de entorno\n",
    "api_key_environ = os.environ.get(\"OPENAI_API_KEY\")\n",
    " \n",
    "# Verificar que la clave API esté disponible\n",
    "if not api_key_environ:\n",
    "    raise ValueError(\"La variable de entorno OPENAI_API_KEY no está configurada o está vacía.\")\n",
    " \n",
    "# Inicializar el cliente de OpenAI con la clave API\n",
    "client = OpenAI(api_key=api_key_environ)\n",
    " \n",
    "# Usar el cliente para tus tareas\n",
    "print(\"¡Cliente de OpenAI inicializado correctamente!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from langchain.document_loaders import PyPDFLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Z_Xi-GvMf8E"
   },
   "source": [
    "## Carga de documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 57463,
     "status": "ok",
     "timestamp": 1688165880499,
     "user": {
      "displayName": "Omar Espejel",
      "userId": "05134704829153205181"
     },
     "user_tz": 360
    },
    "id": "W_6B2k3Vcfxt",
    "outputId": "862c3d28-9656-41cc-ecde-31daec5f7a6e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descarga exitosa.\n",
      "application/pdf\n",
      "Descargado paper1.pdf\n",
      "Descarga exitosa.\n",
      "application/pdf\n",
      "Descargado paper2.pdf\n",
      "Descarga exitosa.\n",
      "application/pdf\n",
      "Descargado paper3.pdf\n",
      "Descarga exitosa.\n",
      "application/pdf\n",
      "Descargado paper4.pdf\n",
      "Descarga exitosa.\n",
      "application/pdf\n",
      "Descargado paper5.pdf\n",
      "Contenido de ml_papers:\n",
      "\n",
      "c:\\Users\\mmartinezo\\INVIAS_NLP\\Platzi_codes\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "urls = [\n",
    "    'https://arxiv.org/pdf/2306.06031v1.pdf',\n",
    "    'https://arxiv.org/pdf/2306.12156v1.pdf',\n",
    "    'https://arxiv.org/pdf/2306.14289v1.pdf',\n",
    "    'https://arxiv.org/pdf/2305.10973v1.pdf',\n",
    "    'https://arxiv.org/pdf/2306.13643v1.pdf'\n",
    "]\n",
    "\n",
    "ml_papers = []\n",
    "\n",
    "for i, url in enumerate(urls):\n",
    "    response = requests.get(url)\n",
    "    \n",
    "\n",
    "    if response.status_code == 200:\n",
    "        with open(\"archivo.pdf\", \"wb\") as f:\n",
    "            f.write(response.content)\n",
    "        print(\"Descarga exitosa.\")\n",
    "    else:\n",
    "        print(\"Error al descargar:\", response.status_code)\n",
    "    \n",
    "    print(response.headers.get(\"Content-Type\"))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    filename = f'paper{i+1}.pdf'\n",
    "    with open(filename, 'wb') as f:\n",
    "        f.write(response.content)\n",
    "        print(f'Descargado {filename}')\n",
    "\n",
    "        loader = PyPDFLoader(filename)\n",
    "        data = loader.load()\n",
    "        ml_papers.extend(data)\n",
    "\n",
    "# Utiliza la lista ml_papers para acceder a los elementos de todos los documentos descargados\n",
    "print('Contenido de ml_papers:')\n",
    "print()\n",
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1688165880500,
     "user": {
      "displayName": "Omar Espejel",
      "userId": "05134704829153205181"
     },
     "user_tz": 360
    },
    "id": "UgT_gejveKq7",
    "outputId": "2d4161bd-1cb0-4bf2-a038-b685912c000c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(list,\n",
       " 57,\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-06-12T00:32:18+00:00', 'author': '', 'keywords': '', 'moddate': '2023-06-12T00:32:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'templateversion': 'IJCAI.2023.0', 'title': '', 'trapped': '/False', 'source': 'paper1.pdf', 'total_pages': 7, 'page': 3, 'page_label': '4'}, page_content='Figure 1: FinGPT Framework.\\n4.1 Data Sources\\nThe first stage of the FinGPT pipeline involves the collec-\\ntion of extensive financial data from a wide array of online\\nsources. These include, but are not limited to:\\n• Financial news: Websites such as Reuters, CNBC, Yahoo\\nFinance, among others, are rich sources of financial news\\nand market updates. These sites provide valuable informa-\\ntion on market trends, company earnings, macroeconomic\\nindicators, and other financial events.\\n• Social media: Platforms such as Twitter, Facebook, Red-\\ndit, Weibo, and others, offer a wealth of information in\\nterms of public sentiment, trending topics, and immediate\\nreactions to financial news and events.\\n• Filings: Websites of financial regulatory authorities, such\\nas the SEC in the United States, offer access to company\\nfilings. These filings include annual reports, quarterly earn-\\nings, insider trading reports, and other important company-\\nspecific information. Official websites of stock exchanges\\n(NYSE, NASDAQ, Shanghai Stock Exchange, etc.) pro-\\nvide crucial data on stock prices, trading volumes, company\\nlistings, historical data, and other related information.\\n• Trends: Websites like Seeking Alpha, Google Trends, and\\nother finance-focused blogs and forums provide access to\\nanalysts’ opinions, market predictions, the movement of\\nspecific securities or market segments and investment ad-\\nvice.\\n• Academic datasets: Research-based datasets that offer cu-\\nrated and verified information for sophisticated financial\\nanalysis.\\nTo harness the wealth of information from these diverse\\nsources, FinGPT incorporates data acquisition tools capable\\nof scraping structured and unstructured data, including APIs,\\nweb scraping tools, and direct database access where avail-\\nable. Moreover, the system is designed to respect the terms\\nof service of these platforms, ensuring data collection is ethi-\\ncal and legal.\\nData APIs: In the FinGPT framework, APIs are used not\\nonly for initial data collection but also for real-time data up-\\ndates, ensuring the model is trained on the most current data.\\nAdditionally, error handling and rate-limiting strategies are\\nimplemented to respect API usage limits and avoid disrup-\\ntions in the data flow.\\n4.2 Real-Time Data Engineering Pipeline for\\nFinancial NLP\\nFinancial markets operate in real-time and are highly sensi-\\ntive to news and sentiment. Prices of securities can change\\nrapidly in response to new information, and delays in pro-\\ncessing that information can result in missed opportunities or\\nincreased risk. As a result, real-time processing is essential in\\nfinancial NLP.\\nThe primary challenge with a real-time NLP pipeline is\\nmanaging and processing the continuous inflow of data ef-\\nficiently. The first step in the pipeline is to set up a system to'))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(ml_papers), len(ml_papers), ml_papers[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WJYjDA_GMi0Z"
   },
   "source": [
    "## Split de documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1688165880500,
     "user": {
      "displayName": "Omar Espejel",
      "userId": "05134704829153205181"
     },
     "user_tz": 360
    },
    "id": "4caTdNe-hk7w"
   },
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1500,\n",
    "    chunk_overlap=200,\n",
    "    length_function=len\n",
    "    )\n",
    "\n",
    "documents = text_splitter.split_documents(ml_papers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1688165880500,
     "user": {
      "displayName": "Omar Espejel",
      "userId": "05134704829153205181"
     },
     "user_tz": 360
    },
    "id": "koi4gwzthsGh",
    "outputId": "6ed35c64-9026-4222-b86a-379809bfb6dc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(211,\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-06-12T00:32:18+00:00', 'author': '', 'keywords': '', 'moddate': '2023-06-12T00:32:18+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'templateversion': 'IJCAI.2023.0', 'title': '', 'trapped': '/False', 'source': 'paper1.pdf', 'total_pages': 7, 'page': 2, 'page_label': '3'}, page_content='highly volatile, changing rapidly in response to news events\\nor market movements.\\nTrends, often observable through websites like Seeking\\nAlpha, Google Trends, and other finance-oriented blogs and\\nforums, offer critical insights into market movements and in-\\nvestment strategies. They feature:\\n• Analyst perspectives: These platforms provide access to\\nmarket predictions and investment advice from seasoned\\nfinancial analysts and experts.\\n• Market sentiment: The discourse on these platforms can\\nreflect the collective sentiment about specific securities,\\nsectors, or the overall market, providing valuable insights\\ninto the prevailing market mood.\\n• Broad coverage: Trends data spans diverse securities and\\nmarket segments, offering comprehensive market coverage.\\nEach of these data sources provides unique insights into\\nthe financial world. By integrating these diverse data types,\\nfinancial language models like FinGPT can facilitate a com-\\nprehensive understanding of financial markets and enable ef-\\nfective financial decision-making.\\n3.2 Challenges in Handling Financial Data\\nWe summarize three major challenges for handling financial\\ndata as follows:\\n• High temporal sensitivity : Financial data are character-\\nized by their time-sensitive nature. Market-moving news or\\nupdates, once released, provide a narrow window of oppor-\\ntunity for investors to maximize their alpha (the measure of\\nan investment’s relative return).\\n• High dynamism : The financial landscape is perpetually'))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents), documents[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VuGSuQV6MmOA"
   },
   "source": [
    "## Embeddings e ingesta a base de datos vectorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 6756,
     "status": "ok",
     "timestamp": 1688165966034,
     "user": {
      "displayName": "Omar Espejel",
      "userId": "05134704829153205181"
     },
     "user_tz": 360
    },
    "id": "iZ-ZFWgRh9aV"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mmartinezo\\AppData\\Local\\Temp\\ipykernel_14076\\4060812394.py:5: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
      "  embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
    "\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=documents,\n",
    "    embedding=embeddings\n",
    ")\n",
    "\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_kwargs={\"k\": 3}\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sBbAhkFKMrDC"
   },
   "source": [
    "## Modelos de chat y cadenas para consulta de información"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1688165966035,
     "user": {
      "displayName": "Omar Espejel",
      "userId": "05134704829153205181"
     },
     "user_tz": 360
    },
    "id": "fxjg2e6RiTqO"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mmartinezo\\AppData\\Local\\Temp\\ipykernel_14076\\2930648323.py:4: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  chat = ChatOpenAI(\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    openai_api_key=api_key_environ,\n",
    "    model_name='gpt-3.5-turbo',\n",
    "    temperature=0.0\n",
    ")\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=chat,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "executionInfo": {
     "elapsed": 6199,
     "status": "ok",
     "timestamp": 1688165977030,
     "user": {
      "displayName": "Omar Espejel",
      "userId": "05134704829153205181"
     },
     "user_tz": 360
    },
    "id": "qgDyf-lOimCT",
    "outputId": "18f9ce42-2c78-4540-e6d3-ec5f01223cbb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mmartinezo\\AppData\\Local\\Temp\\ipykernel_14076\\3867275115.py:2: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  qa_chain.run(query)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'FinGPT es un modelo de lenguaje de código abierto diseñado para el procesamiento de lenguaje natural en el ámbito financiero. Adopta un enfoque centrado en los datos y cuenta con un marco de trabajo de extremo a extremo con cuatro capas. Su objetivo es estimular la innovación, democratizar los modelos de lenguaje financiero y desbloquear nuevas oportunidades en finanzas abiertas. Además, ofrece tutoriales prácticos y demostraciones de aplicaciones financieras para mostrar su aplicabilidad en tareas como servicios de asesoramiento robótico, trading cuantitativo y desarrollo de bajo código.'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"qué es fingpt?\"\n",
    "qa_chain.run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 157
    },
    "executionInfo": {
     "elapsed": 14230,
     "status": "ok",
     "timestamp": 1688165991258,
     "user": {
      "displayName": "Omar Espejel",
      "userId": "05134704829153205181"
     },
     "user_tz": 360
    },
    "id": "rfTiF52Bni8D",
    "outputId": "8e6cbcf0-998e-4cad-e11e-7c51fcb12f4e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Entrenar un modelo como FinGPT puede ser complicado debido a la intensiva exigencia computacional que conlleva. Por ejemplo, BloombergGPT utilizó aproximadamente 1.3 millones de horas de GPU para su entrenamiento, lo que, al calcularse con la tarifa de $2.3 de la nube de AWS, se traduce en un costo impresionante de alrededor de $3 millones por entrenamiento. En contraste con el alto costo computacional de modelos como BloombergGPT, FinGPT presenta una solución más accesible al enfocarse en la adaptación ligera de los principales LLM de código abierto. El costo de adaptación disminuye significativamente, estimado en menos de $300 por entrenamiento.'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"qué hace complicado entrenar un modelo como el fingpt?\"\n",
    "qa_chain.run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "executionInfo": {
     "elapsed": 5426,
     "status": "ok",
     "timestamp": 1688165996681,
     "user": {
      "displayName": "Omar Espejel",
      "userId": "05134704829153205181"
     },
     "user_tz": 360
    },
    "id": "MmjAbVyUtLCF",
    "outputId": "d40b5c05-ebf2-4eea-e11a-721c9ad9e6e7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Fast Segment, también conocido como FastSAM, es un modelo ligero diseñado para aplicaciones móviles que se basa en el modelo Segment Anything (SAM). FastSAM reemplaza el codificador de imágenes pesado de SAM con uno más ligero para hacerlo más adecuado para dispositivos móviles con recursos limitados. A través de un proceso de destilación desacoplada, FastSAM logra un rendimiento satisfactorio al segmentar objetos de interés en imágenes, como se describe en el documento de investigación proporcionado.'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"qué es fast segment?\"\n",
    "qa_chain.run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "executionInfo": {
     "elapsed": 7353,
     "status": "ok",
     "timestamp": 1688166004032,
     "user": {
      "displayName": "Omar Espejel",
      "userId": "05134704829153205181"
     },
     "user_tz": 360
    },
    "id": "4qfwxnkAt_Q8",
    "outputId": "5ffc4795-48de-4010-c763-da8abaf94c0b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'La diferencia principal entre FastSAM y MobileSAM es que MobileSAM es más rápido y más pequeño en tamaño en comparación con FastSAM. MobileSAM tiene menos parámetros (10M frente a 68M) y es cuatro veces más rápido en el procesamiento de imágenes (10ms frente a 40ms). Además, MobileSAM tiene un rendimiento superior en términos de mIoU (0.73 en comparación con 0.27 para FastSAM), lo que sugiere que la predicción de máscaras de MobileSAM es más cercana a la del SAM original que la de FastSAM.'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"cuál es la diferencia entre fast sam y mobile sam?\"\n",
    "qa_chain.run(query)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "1fm4uYP20LHFFkWTsxHRGaaL-p1bVLvG6",
     "timestamp": 1688058575617
    }
   ]
  },
  "kernelspec": {
   "display_name": "NLP_Congreso",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
